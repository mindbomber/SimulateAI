const __vite__mapDeps=(i,m=__vite__mapDeps,d=(m.f||(m.f=["./visual-engine-CPXCswte.js","./core-Bu-3NiyB.js","./ui-D3JF1NtD.js"])))=>i.map(i=>d[i]);
var Ue=Object.defineProperty;var Fe=(l,e,t)=>e in l?Ue(l,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):l[e]=t;var ne=(l,e,t)=>Fe(l,typeof e!="symbol"?e+"":e,t);import{l as o,s as A,T as re,B as Ce,P as F,u as Ne,a as K,b as ce,A as ze,E as je}from"./core-Bu-3NiyB.js";import{A as Ge}from"./ui-D3JF1NtD.js";import{H as U}from"./utils-BNgYPo66.js";(function(){const e=document.createElement("link").relList;if(e&&e.supports&&e.supports("modulepreload"))return;for(const n of document.querySelectorAll('link[rel="modulepreload"]'))i(n);new MutationObserver(n=>{for(const s of n)if(s.type==="childList")for(const a of s.addedNodes)a.tagName==="LINK"&&a.rel==="modulepreload"&&i(a)}).observe(document,{childList:!0,subtree:!0});function t(n){const s={};return n.integrity&&(s.integrity=n.integrity),n.referrerPolicy&&(s.referrerPolicy=n.referrerPolicy),n.crossOrigin==="use-credentials"?s.credentials="include":n.crossOrigin==="anonymous"?s.credentials="omit":s.credentials="same-origin",s}function i(n){if(n.ep)return;n.ep=!0;const s=t(n);fetch(n.href,s)}})();const b={DURATIONS:{DEFAULT:5e3,ERROR:8e3,ANNOUNCEMENT_CLEAR:1e3},ANIMATION:{HIDE_DELAY:300},ID_GENERATION:{BASE:36,SUBSTRING_START:2,SUBSTRING_LENGTH:9},TYPES:{SUCCESS:"success",ERROR:"error",WARNING:"warning",INFO:"info"},PROGRESS:{FULL_WIDTH:"100%",EMPTY_WIDTH:"0%"}};class We{constructor(){this.container=null,this.toasts=new Map,this.init()}init(){this.container=document.createElement("div"),this.container.className="toast-container",this.container.setAttribute("aria-live","polite"),this.container.setAttribute("aria-label","Notifications"),document.body.appendChild(this.container)}show(e={}){const{type:t=b.TYPES.INFO,title:i="",message:n="",duration:s=b.DURATIONS.DEFAULT,closable:a=!0,onClose:r=null}=e,c=this.generateId(),d=this.createToast(c,t,i,n,a);return this.toasts.set(c,{element:d,duration:s,onClose:r,timeoutId:null}),this.container.appendChild(d),requestAnimationFrame(()=>{d.classList.add("show")}),s>0&&this.setAutoDismiss(c,s),this.announceToast(i,n),c}createToast(e,t,i,n,s){const a=document.createElement("div");a.className=`toast ${t}`,a.setAttribute("data-toast-id",e),a.setAttribute("role","alert"),a.setAttribute("aria-live","assertive");const r=this.getIcon(t);return a.innerHTML=`
            <div class="toast-icon" aria-hidden="true">${r}</div>
            <div class="toast-content">
                ${i?`<div class="toast-title">${this.escapeHtml(i)}</div>`:""}
                ${n?`<div class="toast-message">${this.escapeHtml(n)}</div>`:""}
            </div>
            ${s?`
                <button class="toast-close" type="button" aria-label="Close notification">
                    ×
                </button>
            `:""}
            <div class="toast-progress">
                <div class="toast-progress-bar" style="width: ${b.PROGRESS.FULL_WIDTH}"></div>
            </div>
        `,s&&a.querySelector(".toast-close").addEventListener("click",()=>this.dismiss(e)),a}getIcon(e){const t={[b.TYPES.SUCCESS]:"✓",[b.TYPES.ERROR]:"!",[b.TYPES.WARNING]:"⚠",[b.TYPES.INFO]:"i"};return t[e]||t[b.TYPES.INFO]}setAutoDismiss(e,t){const i=this.toasts.get(e);if(!i)return;const n=i.element.querySelector(".toast-progress-bar");n&&(n.style.transition=`width ${t}ms linear`,n.style.width=b.PROGRESS.EMPTY_WIDTH),i.timeoutId=setTimeout(()=>{this.dismiss(e)},t)}dismiss(e){const t=this.toasts.get(e);if(!t)return;const{element:i,timeoutId:n,onClose:s}=t;n&&clearTimeout(n),i.classList.add("hide"),i.classList.remove("show"),setTimeout(()=>{i.parentNode&&i.parentNode.removeChild(i),this.toasts.delete(e),s&&typeof s=="function"&&s(e)},b.ANIMATION.HIDE_DELAY)}dismissAll(){Array.from(this.toasts.keys()).forEach(t=>this.dismiss(t))}update(e,t={}){const i=this.toasts.get(e);if(!i)return;const{title:n,message:s,type:a}=t,{element:r}=i;if(a&&a!==this.getCurrentType(r)){r.className=`toast ${a} show`;const c=r.querySelector(".toast-icon");c&&(c.textContent=this.getIcon(a))}if(n!==void 0){const c=r.querySelector(".toast-title");if(c)c.textContent=n;else if(n){const d=r.querySelector(".toast-content"),u=document.createElement("div");u.className="toast-title",u.textContent=n,d.insertBefore(u,d.firstChild)}}if(s!==void 0){const c=r.querySelector(".toast-message");if(c)c.textContent=s;else if(s){const d=r.querySelector(".toast-content"),u=document.createElement("div");u.className="toast-message",u.textContent=s,d.appendChild(u)}}}getCurrentType(e){return e.className.split(" ").find(i=>[b.TYPES.SUCCESS,b.TYPES.ERROR,b.TYPES.WARNING,b.TYPES.INFO].includes(i))||b.TYPES.INFO}announceToast(e,t){const i=[e,t].filter(Boolean).join(": ");if(i){const n=document.getElementById("aria-live-polite");n&&(n.textContent=i,setTimeout(()=>{n.textContent=""},b.DURATIONS.ANNOUNCEMENT_CLEAR))}}generateId(){return`toast-${Date.now()}-${Math.random().toString(b.ID_GENERATION.BASE).substr(b.ID_GENERATION.SUBSTRING_START,b.ID_GENERATION.SUBSTRING_LENGTH)}`}escapeHtml(e){const t=document.createElement("div");return t.textContent=e,t.innerHTML}success(e,t,i={}){return this.show({...i,type:b.TYPES.SUCCESS,title:e,message:t})}error(e,t,i={}){return this.show({...i,type:b.TYPES.ERROR,title:e,message:t,duration:i.duration||b.DURATIONS.ERROR})}warning(e,t,i={}){return this.show({...i,type:b.TYPES.WARNING,title:e,message:t})}info(e,t,i={}){return this.show({...i,type:b.TYPES.INFO,title:e,message:t})}}window.NotificationToast=new We;class W{constructor({title:e="",content:t="",footer:i="",onClose:n=null,closeOnBackdrop:s=!0,closeOnEscape:a=!0}={}){this.title=e,this.content=t,this.footer=i,this.onClose=n,this.closeOnBackdrop=s,this.closeOnEscape=a,this.isOpen=!1,this.element=null;const r=36,c=9;this.id=`modal-${Date.now()}-${Math.random().toString(r).substring(2,c+2)}`,this._build(),this._setupEventListeners()}_build(){this.element=document.createElement("div"),this.element.id=this.id,this.element.className="modal-backdrop",this.element.setAttribute("role","dialog"),this.element.setAttribute("aria-modal","true"),this.element.setAttribute("aria-labelledby",`${this.id}-title`),this.element.style.display="none",this.element.inert=!0,this.element.innerHTML=`
            <div class="modal-dialog">
                <div class="modal-header">
                    <h2 id="${this.id}-title" class="modal-title">${this.title}</h2>
                    <button class="modal-close" aria-label="Close modal" type="button">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    ${this.content}
                </div>
                ${this.footer?`
                    <div class="modal-footer">
                        ${this.footer}
                    </div>
                `:""}
            </div>
        `,document.body.appendChild(this.element)}_setupEventListeners(){const e=this.element.querySelector(".modal-close");e&&e.addEventListener("click",()=>this.close()),this.closeOnBackdrop&&this.element.addEventListener("click",t=>{t.target===this.element&&this.close()}),this.closeOnEscape&&(this._escapeHandler=t=>{t.key==="Escape"&&this.isOpen&&this.close()},document.addEventListener("keydown",this._escapeHandler))}open(){if(this.isOpen)return;if(this.isOpen=!0,this.element.inert=!1,this.element.style.display="flex",document.body.classList.contains("onboarding-active")){this.element.style.pointerEvents="none";const t=this.element.querySelector(".modal-dialog");t&&(t.style.pointerEvents="auto")}this._setPageInert(!0),requestAnimationFrame(()=>{this.element.classList.add("visible")}),setTimeout(()=>{const t=this.element.querySelector('button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])');t&&t.focus()},100),document.body.style.overflow="hidden"}close(){if(!this.isOpen)return;this.isOpen=!1,this.element.classList.remove("visible"),this.element.inert=!0,this.element.style.pointerEvents="";const e=this.element.querySelector(".modal-dialog");e&&(e.style.pointerEvents=""),this._setPageInert(!1),setTimeout(()=>{this.isOpen||(this.element.style.display="none")},300),document.body.style.overflow="",this.onClose&&typeof this.onClose=="function"&&this.onClose()}_setPageInert(e){Array.from(document.body.children).forEach(i=>{i!==this.element&&!i.classList.contains("onboarding-overlay")&&!i.classList.contains("onboarding-spotlight")&&!i.classList.contains("onboarding-coach-mark")&&(i.inert=e)})}destroy(){this.close(),this._escapeHandler&&document.removeEventListener("keydown",this._escapeHandler),this.element&&this.element.parentNode&&this.element.parentNode.removeChild(this.element),this.element=null}static cleanupOrphanedModals(){document.querySelectorAll('[id^="modal-"]:not([style*="display: flex"])').forEach(a=>{(a.style.display==="none"||!a.classList.contains("visible"))&&(a.remove(),o.info("ModalUtility","Cleaned up orphaned modal:",a.id))}),document.querySelectorAll(".modal-backdrop").forEach(a=>{const r=a.querySelector(".modal-dialog .modal-body *:not(:empty)"),c=a.closest('[id^="modal-"]')||a.querySelector('[id^="modal-"]');!r&&!c&&(a.remove(),o.info("ModalUtility","Cleaned up orphaned modal backdrop"))});const i=document.getElementById("simulation-modal");i&&(i.style.display==="flex"||i.classList.contains("show")||i.classList.contains("visible")||(i.remove(),o.info("ModalUtility","Cleaned up orphaned simulation modal"))),document.querySelectorAll(".modal-dialog:not(.modal-backdrop .modal-dialog)").forEach(a=>{!a.closest(".modal-backdrop")&&!a.closest('[id^="modal-"]')&&(a.remove(),o.info("ModalUtility","Cleaned up orphaned modal dialog"))}),document.querySelectorAll(".modal-body:not(.modal-dialog .modal-body)").forEach(a=>{!a.closest(".modal-dialog")&&!a.closest('[id^="modal-"]')&&(a.remove(),o.info("ModalUtility","Cleaned up orphaned modal body"))})}static destroyModalById(e){const t=document.getElementById(e);return t?(t.remove(),o.info("ModalUtility","Force destroyed modal:",e),!0):!1}static aggressiveModalCleanup(){o.info("ModalUtility","Starting aggressive modal cleanup"),document.querySelectorAll(".modal-backdrop").forEach(a=>{a.style.display==="flex"||a.classList.contains("show")||a.classList.contains("visible")||(a.remove(),o.info("ModalUtility","Aggressively removed modal backdrop"))});const t=document.getElementById("simulation-modal");t&&(t.style.display==="flex"||t.classList.contains("show")||t.classList.contains("visible")||(t.remove(),o.info("ModalUtility","Aggressively removed simulation modal"))),document.querySelectorAll(".modal-dialog").forEach(a=>{a.closest('.modal-backdrop[style*="display: flex"]')||a.closest('[id^="modal-"][style*="display: flex"]')||a.closest(".show")||a.closest(".visible")||(a.remove(),o.info("ModalUtility","Aggressively removed modal dialog"))}),document.querySelectorAll(".modal-body").forEach(a=>{a.closest(".modal-dialog")||a.closest('.modal-backdrop[style*="display: flex"]')||a.closest('[id^="modal-"][style*="display: flex"]')||a.closest(".show")||a.closest(".visible")||(a.remove(),o.info("ModalUtility","Aggressively removed modal body"))}),document.querySelectorAll('[id^="modal-"]').forEach(a=>{a.style.display==="flex"||a.classList.contains("show")||a.classList.contains("visible")||(a.remove(),o.info("ModalUtility","Aggressively removed generated modal:",a.id))}),o.info("ModalUtility","Aggressive modal cleanup completed")}setTitle(e){this.title=e;const t=this.element.querySelector(".modal-title");t&&(t.textContent=e)}setContent(e){this.content=e;const t=this.element.querySelector(".modal-body");t&&(t.innerHTML=e)}setFooter(e){this.footer=e;let t=this.element.querySelector(".modal-footer");e?(t||(t=document.createElement("div"),t.className="modal-footer",this.element.querySelector(".modal-dialog").appendChild(t)),t.innerHTML=e):t&&t.remove()}}typeof window<"u"&&(window.ModalUtility=W);const Ye="modulepreload",Ke=function(l,e){return new URL(l,e).href},ke={},x=function(e,t,i){let n=Promise.resolve();if(t&&t.length>0){const a=document.getElementsByTagName("link"),r=document.querySelector("meta[property=csp-nonce]"),c=r?.nonce||r?.getAttribute("nonce");n=Promise.allSettled(t.map(d=>{if(d=Ke(d,i),d in ke)return;ke[d]=!0;const u=d.endsWith(".css"),h=u?'[rel="stylesheet"]':"";if(!!i)for(let y=a.length-1;y>=0;y--){const m=a[y];if(m.href===d&&(!u||m.rel==="stylesheet"))return}else if(document.querySelector(`link[href="${d}"]${h}`))return;const g=document.createElement("link");if(g.rel=u?"stylesheet":Ye,u||(g.as="script"),g.crossOrigin="",g.href=d,c&&g.setAttribute("nonce",c),document.head.appendChild(g),u)return new Promise((y,m)=>{g.addEventListener("load",y),g.addEventListener("error",()=>m(new Error(`Unable to preload CSS for ${d}`)))})}))}function s(a){const r=new Event("vite:preloadError",{cancelable:!0});if(r.payload=a,window.dispatchEvent(r),!r.defaultPrevented)throw a}return n.then(a=>{for(const r of a||[])r.status==="rejected"&&s(r.reason);return e().catch(s)})},J={WARMUP_DURATION:5,INTRODUCTION_DURATION:10,CLOSURE_DURATION:10,DEFAULT_LESSON_DURATION:50,OVERHEAD_TIME:25};class Ve{constructor(){this.curriculumStandards=new Map,this.assessmentTools=new Map,this.classroomActivities=new Map,this.progressTracking=new Map,this.initializeStandards(),this.setupAssessmentTools(),this.createClassroomActivities()}initializeStandards(){this.curriculumStandards.set("csta",{name:"Computer Science Teachers Association Standards",grades:{"K-2":["1A-IC-16","1A-IC-17","1A-IC-18"],"3-5":["1B-IC-18","1B-IC-19","1B-IC-20"],"6-8":["2-IC-20","2-IC-21","2-IC-22","2-IC-23"],"9-12":["3A-IC-24","3A-IC-25","3A-IC-26","3A-IC-27"]},alignment:{"1A-IC-16":"Bias and Fairness Explorer - Basic concepts","2-IC-21":"AI decision-making consequences","3A-IC-25":"Ethical implications of AI systems"}}),this.curriculumStandards.set("ngss",{name:"Next Generation Science Standards",practices:["Asking Questions and Defining Problems","Developing and Using Models","Planning and Carrying Out Investigations","Analyzing and Interpreting Data","Using Mathematics and Computational Thinking","Constructing Explanations","Engaging in Argument from Evidence","Obtaining, Evaluating, and Communicating Information"]}),this.curriculumStandards.set("ncss",{name:"National Council for Social Studies",themes:["Power, Authority, and Governance","Science, Technology, and Society","Civic Ideals and Practices","Individual Development and Identity"]})}setupAssessmentTools(){this.assessmentTools.set("reflection-prompts",{type:"formative",name:"Reflection Prompts",tools:[{id:"ethical-dilemma-journal",name:"Ethical Dilemma Journal",description:"Students maintain ongoing reflections on AI ethics scenarios",rubric:this.createReflectionRubric(),templates:this.getJournalTemplates()},{id:"stakeholder-analysis",name:"Stakeholder Impact Analysis",description:"Students analyze how AI decisions affect different groups",framework:this.getStakeholderFramework()},{id:"decision-tree-mapping",name:"Decision Tree Mapping",description:"Visual mapping of decision paths and consequences",tools:["Flowchart templates","Digital mapping tools","Collaborative boards"]}]}),this.assessmentTools.set("project-assessments",{type:"summative",name:"Project-Based Assessments",projects:[{id:"ai-system-design",name:"Ethical AI System Design Challenge",description:"Students design an AI system with built-in ethical safeguards",duration:"2-3 weeks",deliverables:["Design proposal","Ethics analysis","Stakeholder presentation"],rubric:this.createDesignRubric()},{id:"bias-investigation",name:"Real-World Bias Investigation",description:"Research and present on actual AI bias cases",duration:"1-2 weeks",skills:["Research","Critical analysis","Communication"],rubric:this.createInvestigationRubric()}]}),this.assessmentTools.set("collaborative",{type:"peer",name:"Collaborative Assessment",activities:[{id:"ethics-debate",name:"Structured Ethics Debates",format:"Teams argue different sides of AI ethics issues",roles:["Researcher","Presenter","Rebuttal specialist","Fact-checker"],rubric:this.createDebateRubric()},{id:"solution-critique",name:"Peer Solution Critique",format:"Students review and provide constructive feedback on peers' AI solutions",guidelines:this.getPeerReviewGuidelines()}]})}createClassroomActivities(){this.classroomActivities.set("individual",[{id:"scenario-explorer",name:"Personal AI Ethics Explorer",description:"Students work through scenarios individually, documenting their reasoning",time:"20-30 minutes",materials:["Computer/tablet","Reflection worksheet"],adaptations:{elementary:"Simplified scenarios with visual aids",middle:"Standard scenarios with guided questions",high:"Complex scenarios with open-ended analysis",college:"Real-world case studies with policy implications"}},{id:"bias-detective",name:"AI Bias Detective Challenge",description:"Students identify and analyze bias in various AI applications",time:"15-25 minutes",skills:["Pattern recognition","Critical thinking","Data analysis"]}]),this.classroomActivities.set("small-group",[{id:"stakeholder-roleplay",name:"Multi-Stakeholder Roleplay",description:"Groups represent different stakeholders in AI ethics scenarios",time:"30-45 minutes",groupSize:"3-5 students",roles:["AI Developer","End User","Affected Community","Regulator","Ethicist"],process:["Assign roles and provide stakeholder profiles","Give groups time to develop their position","Facilitate cross-stakeholder discussions","Debrief on different perspectives"]},{id:"solution-design-teams",name:"Collaborative Solution Design",description:"Teams design ethical AI solutions to real-world problems",time:"45-60 minutes",methodology:"Design thinking process",deliverables:["Problem definition","Solution prototype","Ethics checklist"]}]),this.classroomActivities.set("whole-class",[{id:"ethics-town-hall",name:"AI Ethics Town Hall",description:"Class-wide discussion on AI policy and regulation",time:"50-90 minutes",format:"Modified town hall with student moderators",roles:["Moderator","Panelists","Community members","Media"],topics:["AI in hiring","Algorithmic content curation","Autonomous vehicles"]},{id:"living-algorithm",name:"Human Algorithm Simulation",description:"Students act as parts of an AI system to understand decision-making",time:"30-40 minutes",setup:"Students represent different algorithm components",learning:"How bias enters systems and compounds"}]),this.classroomActivities.set("cross-curricular",[{id:"math-bias-analysis",subject:"Mathematics",name:"Statistical Bias Analysis",description:"Use math skills to identify and measure bias in datasets",skills:["Statistics","Data visualization","Probability"],tools:["Spreadsheet software","Graphing tools","Statistical calculators"]},{id:"english-ethics-essays",subject:"English Language Arts",name:"Persuasive Ethics Essays",description:"Write persuasive essays on AI ethics topics",skills:["Argumentation","Research","Citation","Persuasive writing"],genres:["Opinion essays","Research papers","Policy proposals"]},{id:"social-studies-policy",subject:"Social Studies",name:"AI Policy Development",description:"Research and propose AI governance policies",skills:["Research","Policy analysis","Civic engagement","Critical thinking"],culmination:"Present to local government or school board"}])}generateLessonPlan(e={}){const{subject:t="Computer Science",gradeLevel:i="9-12",duration:n=J.DEFAULT_LESSON_DURATION,scenario:s="bias-fairness",activity:a="scenario-explorer",standards:r=["csta"]}=e;return{title:`AI Ethics: ${this.getScenarioTitle(s)}`,subject:t,gradeLevel:i,duration:`${n} minutes`,objectives:this.getLearningObjectives(s,i),standards:this.getStandardsAlignment(r,i),structure:{warmUp:this.getWarmUpActivity(s,J.WARMUP_DURATION),introduction:this.getIntroduction(s,J.INTRODUCTION_DURATION),mainActivity:this.getMainActivity(a,n-J.OVERHEAD_TIME),closure:this.getClosureActivity(s,J.CLOSURE_DURATION)},materials:this.getMaterials(a),resources:this.getAdditionalResources(s),assessment:{formative:this.getFormativeAssessment(a),summative:this.getSummativeAssessment(s),rubric:this.getAssessmentRubric(a)},differentiation:this.getDifferentiation(i),extensions:this.getExtensionActivities(s),reflection:this.getReflectionQuestions(s,i)}}getScenarioTitle(e){return{"bias-fairness":"Algorithmic Bias and Fairness","privacy-security":"Privacy and Data Security","autonomous-systems":"Autonomous Decision Making","social-impact":"AI Social Impact Assessment",transparency:"AI Transparency and Explainability",accountability:"AI Accountability and Governance"}[e]||"AI Ethics Exploration"}getStandardsAlignment(e,t){return e.map(i=>{const n=this.curriculumStandards.get(i);return n&&n.grades[t]?{standard:i,codes:n.grades[t],description:n.description}:{standard:i,codes:[],description:"No alignment found"}})}getWarmUpActivity(e,t){return{"bias-fairness":`Quick Poll (${t} min): "Have you ever experienced or witnessed unfair treatment by a computer system or app?" Students share briefly to activate prior knowledge.`,"privacy-security":`Think-Pair-Share (${t} min): "What personal information do you share online daily?" Students reflect and discuss data sharing habits.`,"autonomous-systems":`Scenario Quickwrite (${t} min): "If a self-driving car had to choose between hitting one person or three people, what should it do?" Students write their initial response.`,"social-impact":`Media Gallery Walk (${t} min): Display news headlines about AI impact. Students identify positive and negative impacts they observe.`,transparency:`Black Box Activity (${t} min): Present a "mystery algorithm" output and ask students to guess how it works to highlight the importance of transparency.`,accountability:`Responsibility Web (${t} min): Students brainstorm who should be responsible when AI makes mistakes (developers, users, companies, etc.).`}[e]||`Reflection Prompt (${t} min): Students consider their current understanding of AI ethics and share one question they have.`}getIntroduction(e,t){return`Introduction to ${this.getScenarioTitle(e)} (${t} min): Present key concepts and real-world examples to establish context for the main activity.`}getMainActivity(e,t){return{"scenario-explorer":`Interactive Scenario Exploration (${t} min): Students work through AI ethics scenarios using the SimulateAI platform, documenting their decision-making process and reasoning.`,"stakeholder-roleplay":`Multi-Stakeholder Roleplay (${t} min): Students represent different stakeholders affected by AI decisions and negotiate solutions that consider all perspectives.`,"bias-detective":`AI Bias Investigation (${t} min): Students analyze real AI systems for potential bias, using provided datasets and tools to identify patterns and propose solutions.`,"solution-design":`Ethical AI Design Challenge (${t} min): Teams design AI systems with built-in ethical safeguards, presenting their solutions to the class for feedback.`,"policy-debate":`Structured Policy Debate (${t} min): Students research and debate different approaches to AI regulation and governance.`}[e]||`Hands-on AI Ethics Activity (${t} min): Students engage with interactive simulations and case studies to explore ethical implications of AI decisions.`}getClosureActivity(e,t){return{"bias-fairness":`Exit Ticket (${t} min): "What is one way you could check for bias in an AI system?" Students submit their response before leaving.`,"privacy-security":`Commitment Cards (${t} min): Students write one privacy protection action they will take this week and share with a partner.`,"autonomous-systems":`Ethical Principles Summary (${t} min): Students identify the top 3 ethical principles that should guide autonomous AI systems.`,"social-impact":`Solution Brainstorm (${t} min): Students propose one actionable solution to address a negative AI impact they learned about.`,transparency:`Transparency Checklist (${t} min): Students create a 5-point checklist for evaluating AI system transparency.`,accountability:`Accountability Framework (${t} min): Students outline who should be responsible for different types of AI decisions and why.`}[e]||`Reflection and Next Steps (${t} min): Students summarize key insights and identify areas for further exploration.`}getMaterials(e){return{"scenario-explorer":["Computers/tablets","Internet access","SimulateAI platform","Reflection worksheets","Sticky notes"],"stakeholder-roleplay":["Role cards","Scenario descriptions","Flip chart paper","Markers","Timer"],"bias-detective":["Sample datasets","Analysis worksheets","Calculators/spreadsheet software","Highlighters"],"solution-design":["Design thinking templates","Presentation materials","Post-it notes","Flip chart paper"],"policy-debate":["Research materials","Debate format guidelines","Timer","Evaluation rubrics"]}[e]||["Computers/tablets","Internet access","Worksheets","Writing materials"]}getAdditionalResources(e){return{"bias-fairness":["Algorithm Watch bias database","MIT Technology Review AI bias articles","Fairness in Machine Learning course materials","Joy Buolamwini's research on algorithmic bias"],"privacy-security":["Electronic Frontier Foundation privacy guides","GDPR educational materials","Data privacy case studies","Privacy policy analysis tools"],"autonomous-systems":["MIT Moral Machine Experiment","Autonomous vehicle ethics papers","Trolley problem variations","IEEE standards for autonomous systems"],"social-impact":["AI Now Institute reports","Partnership on AI case studies","Social impact assessment frameworks","Community engagement best practices"],transparency:["Explainable AI research papers","LIME and SHAP explanation tools","Algorithmic transparency guidelines","Right to explanation regulations"],accountability:["AI governance frameworks","Accountability in AI systems reports","Liability in automated decision-making","Professional ethics codes for AI"]}[e]||["General AI ethics resources","Academic papers","News articles","Case studies"]}getFormativeAssessment(e){return{"scenario-explorer":["Real-time decision tracking","Reasoning documentation","Peer discussion observations","Self-reflection prompts"],"stakeholder-roleplay":["Role authenticity rubric","Collaboration observation","Solution quality assessment","Perspective-taking evaluation"],"bias-detective":["Analysis accuracy check","Evidence identification","Pattern recognition skills","Hypothesis formation"],"solution-design":["Design process documentation","Ethical consideration checklist","Peer feedback collection","Iteration tracking"],"policy-debate":["Argument quality assessment","Evidence usage evaluation","Listening and response skills","Position development"]}[e]||["Observation checklist","Exit tickets","Peer feedback","Self-assessment"]}getSummativeAssessment(e){return{"bias-fairness":"Portfolio of bias analysis across multiple AI systems with recommendations for improvement","privacy-security":"Privacy policy audit and improvement proposal for a real organization","autonomous-systems":"Ethical framework development for autonomous decision-making in a specific domain","social-impact":"Community impact assessment for a proposed AI implementation",transparency:"Explainable AI system design with user-friendly explanations",accountability:"AI governance policy proposal with implementation plan"}[e]||"Comprehensive project demonstrating understanding of AI ethics principles"}getAssessmentRubric(e){return{"scenario-explorer":{"Ethical Reasoning":["Identifies ethical issues","Analyzes consequences","Considers multiple perspectives","Justifies decisions"],"Critical Thinking":["Asks relevant questions","Evaluates evidence","Recognizes assumptions","Draws logical conclusions"],Communication:["Clearly explains reasoning","Uses appropriate terminology","Responds to others respectfully","Presents ideas effectively"]},"stakeholder-roleplay":{"Role Authenticity":["Accurately represents stakeholder","Maintains perspective","Uses appropriate arguments","Demonstrates understanding"],Collaboration:["Listens actively","Builds on others' ideas","Manages disagreement constructively","Contributes equitably"],"Problem Solving":["Identifies core issues","Proposes viable solutions","Considers trade-offs","Adapts to new information"]}}[e]||{Understanding:["Demonstrates basic concepts","Makes connections","Applies knowledge","Explains reasoning"],Engagement:["Participates actively","Asks questions","Helps others","Stays focused"],Communication:["Expresses ideas clearly","Uses evidence","Listens respectfully","Provides feedback"]}}getDifferentiation(e){const t={"K-2":{Content:["Simplified vocabulary","Visual representations","Concrete examples","Story-based scenarios"],Process:["Partner work","Hands-on activities","Movement integration","Shorter time segments"],Product:["Drawings","Simple presentations","Choice boards","Multimedia options"]},"3-5":{Content:["Grade-appropriate examples","Scaffolded complexity","Multiple entry points","Connection to students' lives"],Process:["Flexible grouping","Learning stations","Graphic organizers","Think-pair-share"],Product:["Various formats","Rubric choices","Technology integration","Peer sharing"]},"6-8":{Content:["Real-world connections","Current events integration","Multiple perspectives","Increasing complexity"],Process:["Independent research","Collaborative projects","Problem-based learning","Socratic seminars"],Product:["Research projects","Presentations","Digital portfolios","Peer evaluation"]},"9-12":{Content:["Advanced concepts","Policy implications","Career connections","Global perspectives"],Process:["Student-led discussions","Independent investigation","Debate and argumentation","Mentoring opportunities"],Product:["Formal presentations","Research papers","Policy proposals","Community engagement"]}};return t[e]||t["6-8"]}getExtensionActivities(e){return{"bias-fairness":["Conduct a bias audit of your school's technology systems","Interview community members about their experiences with AI bias","Create a public awareness campaign about algorithmic fairness","Develop a bias detection tool for a specific AI application"],"privacy-security":["Analyze privacy policies of popular apps and services","Create a digital privacy guide for your school community","Research data breach cases and their impacts","Design a privacy-preserving AI system"],"autonomous-systems":["Research autonomous vehicle policies in different countries","Design ethical guidelines for autonomous healthcare systems","Create a decision-making framework for autonomous weapons","Analyze the ethics of autonomous hiring systems"],"social-impact":["Conduct a community impact assessment for a local AI implementation","Create a social impact measurement framework for AI projects","Research AI's impact on your chosen career field","Develop community engagement strategies for AI deployment"],transparency:["Create user-friendly explanations for complex AI decisions",'Research "right to explanation" laws in different jurisdictions',"Design an AI transparency dashboard for consumers","Develop transparency standards for AI in education"],accountability:["Research AI liability laws and propose improvements","Create an AI accountability framework for businesses","Analyze professional ethics codes for AI practitioners","Design a public AI accountability system"]}[e]||["Research current AI ethics developments","Create educational materials for younger students","Engage with local policymakers about AI regulation","Develop an AI ethics toolkit for your community"]}getReflectionQuestions(e,t){const n={"bias-fairness":["How might your own biases influence AI systems you help create?",'What would a "fair" AI system look like in practice?',"How can we balance efficiency with fairness in AI decisions?","What role should affected communities play in AI development?"],"privacy-security":["How do you balance convenience with privacy in your daily life?","What privacy rights should be non-negotiable in AI systems?","How can we ensure AI systems protect vulnerable populations?","What would you want to know about AI systems that affect you?"],"autonomous-systems":["How comfortable are you with AI making decisions that affect you?","What decisions should never be fully automated?","How can we ensure human oversight of autonomous systems?","What ethical principles should guide autonomous AI behavior?"],"social-impact":["How has AI already changed your community?","What positive changes could AI bring to society?","How can we prevent AI from increasing inequality?","What role should the public play in AI development?"],transparency:["How much do you understand about the AI systems you use?","What would you want to know about AI decisions that affect you?","How can we make AI explanations accessible to everyone?","What are the limits of explainable AI?"],accountability:["Who should be responsible when AI systems cause harm?","How can we ensure AI developers take responsibility?","What role should government play in AI accountability?","How can individuals hold AI systems accountable?"]}[e]||["What surprised you most about AI ethics?","How will this learning change your relationship with AI?","What questions do you still have about AI ethics?","How can you apply these insights in your daily life?"];return t==="K-2"||t==="3-5"?n.map(s=>s.replace(/How might|What would|How can we/g,"Why is it important to").replace(/\?$/,"?")):n}createReflectionRubric(){return{criteria:[{name:"Ethical Reasoning",levels:{4:"Demonstrates sophisticated understanding of ethical principles and their application",3:"Shows clear understanding of ethical reasoning with good application",2:"Basic understanding of ethical concepts with some application",1:"Limited understanding of ethical reasoning"}},{name:"Stakeholder Analysis",levels:{4:"Identifies and analyzes multiple stakeholders with nuanced understanding of impacts",3:"Identifies key stakeholders and analyzes most impacts",2:"Identifies some stakeholders with basic impact analysis",1:"Limited identification of stakeholders or impacts"}},{name:"Critical Thinking",levels:{4:"Evaluates multiple perspectives and synthesizes complex ideas",3:"Considers different perspectives and makes connections",2:"Shows some critical analysis with basic connections",1:"Limited critical thinking or analysis"}},{name:"Communication",levels:{4:"Clear, compelling communication with sophisticated use of evidence",3:"Clear communication with good use of evidence",2:"Generally clear communication with some evidence",1:"Unclear communication or limited evidence"}}]}}createProgressTracker(){return{individualProgress:{scenariosCompleted:0,reflectionDepth:"basic",collaborationSkills:"developing",ethicalReasoningGrowth:[],timeEngaged:0,questionsAsked:0,perspectivesConsidered:[]},classProgress:{averageEngagement:0,scenarioCompletionRates:new Map,commonMisconceptions:[],emergingInsights:[],collaborationQuality:"good",discussionDepth:"moderate"},curriculumAlignment:{standardsCovered:[],learningObjectivesMet:[],skillsDeveloped:[],crossCurricularConnections:[]}}}generateEducatorPackage(e){return{overview:this.getScenarioOverview(e),lessonPlans:this.generateMultipleLessonPlans(e),activities:this.getScenarioActivities(e),assessments:this.getScenarioAssessments(e),resources:{backgroundReading:this.getBackgroundReading(e),additionalCases:this.getAdditionalCases(e),expertInterviews:this.getExpertResources(e),currentEvents:this.getCurrentEventConnections(e)},parentCommunication:{overview:this.getParentOverview(e),homeExtensions:this.getHomeExtensions(e),discussionStarters:this.getFamilyDiscussionStarters(e)}}}setScenarioGenerator(e){this.scenarioGenerator=e}getCurriculumAlignment(e){const t=[];for(const i of e)switch(i.toLowerCase()){case"ethics":case"fairness":t.push({standard:"CSTA",code:"3A-IC-25",description:"Evaluate the ways computing impacts personal, ethical, social, economic, and cultural practices"});break;case"bias":t.push({standard:"CSTA",code:"2-IC-21",description:"Discuss issues of bias and accessibility in the design of existing technologies"});break;case"education":t.push({standard:"NGSS",practice:"Engaging in Argument from Evidence",description:"Use evidence to construct and support arguments about ethical implications"});break}return t.length>0?t:null}getAssessmentTools(e){const t=[];switch(e){case"beginner":t.push(this.assessmentTools.get("reflection-prompts"),this.classroomActivities.get("individual"));break;case"intermediate":t.push(this.assessmentTools.get("reflection-prompts"),this.assessmentTools.get("collaborative"),this.classroomActivities.get("small-group"));break;case"advanced":t.push(this.assessmentTools.get("project-assessments"),this.assessmentTools.get("collaborative"),this.classroomActivities.get("cross-curricular"));break}return t.length>0?t:null}getLearningObjectives(e,t){const i={"bias-fairness":["Identify different types of bias in AI systems","Analyze the impact of biased AI on various stakeholders","Evaluate strategies for reducing bias in AI applications","Communicate ethical concerns effectively"]};return this.adaptObjectivesForGrade(i[e]||[],t)}adaptObjectivesForGrade(e,t){const n={"K-2":s=>s.replace(/analyze|evaluate/gi,"identify").replace(/communicate/gi,"share"),"3-5":s=>s.replace(/evaluate/gi,"compare"),"6-8":s=>s,"9-12":s=>s.replace(/identify/gi,"critically analyze"),college:s=>`${s} with consideration of policy implications`}[t]||(s=>s);return e.map(n)}getJournalTemplates(){return{elementary:{title:"My AI Ethics Journal (Elementary)",prompts:["What did the AI do in today's scenario?","How did it make people feel?","What would you tell the AI to do differently?","Draw a picture of what happened."],format:"guided-questions"},middle:{title:"AI Ethics Reflection Journal (Middle School)",prompts:["Describe the ethical dilemma presented in the scenario.","What were the different choices available?","Who would be affected by each choice?","What values or principles guided your decision?","How might this apply to real-world situations?"],format:"structured-reflection"},high:{title:"AI Ethics Analysis Journal (High School)",prompts:["Analyze the competing ethical frameworks present in this scenario.","Evaluate the long-term societal implications of different approaches.","Consider how cultural contexts might influence ethical judgments.","Propose policy recommendations based on your analysis.","Reflect on how this scenario connects to current AI developments."],format:"analytical-essay"}}}getStakeholderFramework(){return{categories:[{name:"Primary Stakeholders",description:"Directly affected by AI decisions",examples:["Users","Customers","Employees"],analysisQuestions:["How are they directly impacted?","What are their primary concerns?","What power do they have to influence outcomes?"]},{name:"Secondary Stakeholders",description:"Indirectly affected by AI decisions",examples:["Communities","Industry competitors","Regulatory bodies"],analysisQuestions:["What indirect effects might they experience?","How might they respond to changes?","What interests do they represent?"]},{name:"Future Stakeholders",description:"Those who may be affected in the future",examples:["Future generations","Emerging user groups","Society at large"],analysisQuestions:["What long-term impacts should we consider?","Who might be affected as technology evolves?","What precedents are we setting?"]}],process:["Identify all relevant stakeholders","Categorize by level of impact","Analyze interests and concerns","Evaluate power dynamics","Consider potential conflicts","Develop inclusive solutions"]}}createDesignRubric(){return{criteria:[{name:"Problem Definition",levels:{4:"Clearly defines complex problems with multiple stakeholder perspectives",3:"Defines problems with good understanding of context",2:"Basic problem definition with some context",1:"Limited problem understanding"}},{name:"Solution Development",levels:{4:"Develops innovative, ethical solutions considering multiple constraints",3:"Creates practical solutions with ethical considerations",2:"Basic solutions with some ethical awareness",1:"Limited solution development"}}]}}createInvestigationRubric(){return{criteria:[{name:"Research Quality",levels:{4:"Uses multiple credible sources with critical evaluation",3:"Uses credible sources with good analysis",2:"Uses some credible sources with basic analysis",1:"Limited or unreliable sources"}},{name:"Evidence Synthesis",levels:{4:"Synthesizes evidence to build compelling arguments",3:"Connects evidence to support conclusions",2:"Basic use of evidence",1:"Minimal evidence integration"}}]}}createDebateRubric(){return{criteria:[{name:"Argument Quality",levels:{4:"Presents sophisticated, well-reasoned arguments",3:"Clear arguments with good support",2:"Basic arguments with some support",1:"Weak or unsupported arguments"}},{name:"Ethical Reasoning",levels:{4:"Demonstrates nuanced understanding of ethical principles",3:"Shows clear ethical reasoning",2:"Basic ethical considerations",1:"Limited ethical awareness"}}]}}getPeerReviewGuidelines(){return{structure:["Read the work carefully and completely","Focus on constructive feedback","Consider ethical implications discussed","Suggest specific improvements","Acknowledge strengths"],questions:["Are the ethical issues clearly identified?","Are different stakeholder perspectives considered?","Is the reasoning logical and well-supported?","Are potential consequences explored?","What questions remain unanswered?"],etiquette:["Be respectful and constructive","Focus on ideas, not personal qualities","Provide specific examples","Balance criticism with encouragement","Ask clarifying questions"]}}}const E={DURATIONS:{SHORT_SESSION:"20 minutes",MEDIUM_SESSION:"30 minutes",LONG_SESSION:"40 minutes",EXTENDED_SESSION:"45-60 minutes",FULL_LAB_SESSION:"90-120 minutes",PRESENTATION_TIME:"10-minute presentation"},EXPERIMENT_STEPS:{STEP_1:1,STEP_2:2,STEP_3:3,STEP_4:4},ASSESSMENT_WEIGHTS:{UNDERSTANDING:.3,CRITICAL_THINKING:.25,COLLABORATION:.25,COMMUNICATION:.2},PROJECT_TIMELINE:{WEEK_DURATION:"1 week"},ARRAY_THRESHOLDS:{EMPTY_LENGTH:0}};class Qe{constructor(){this.labStations=new Map,this.experiments=new Map,this.collaborationTools=new Map,this.assessmentMethods=new Map,this.initializeLab()}initializeLab(){this.createLabStations(),this.setupExperiments(),this.configureCollaboration(),this.establishAssessment()}createLabStations(){this.labStations.set("bias-analysis",{name:"Bias Detection & Analysis Lab",purpose:"Investigate how bias enters and affects AI systems",tools:["Data Visualization Dashboard","Statistical Analysis Tools","Bias Measurement Instruments","Case Study Database"],experiments:["dataset-bias-detection","algorithmic-fairness-testing","outcome-disparity-analysis"],learningOutcomes:["Identify sources of bias in training data","Measure fairness across different groups","Propose bias mitigation strategies"]}),this.labStations.set("ethics-decision",{name:"Ethical Decision-Making Laboratory",purpose:"Explore ethical frameworks and their application to AI",tools:["Ethics Framework Simulator","Stakeholder Impact Visualizer","Decision Tree Builder","Consequence Predictor"],experiments:["trolley-problem-variants","utilitarian-vs-deontological","stakeholder-conflict-resolution"],learningOutcomes:["Apply different ethical frameworks","Analyze stakeholder perspectives","Navigate ethical trade-offs"]}),this.labStations.set("impact-analysis",{name:"Real-World Impact Analysis Center",purpose:"Study actual consequences of AI systems in society",tools:["Case Study Explorer","Impact Measurement Tools","Timeline Visualizer","News Analysis Platform"],experiments:["hiring-algorithm-outcomes","criminal-justice-ai-effects","healthcare-ai-disparities"],learningOutcomes:["Connect theory to real-world outcomes","Evaluate long-term consequences","Identify pattern across domains"]}),this.labStations.set("solution-design",{name:"Ethical AI Design Workshop",purpose:"Create and test ethical AI solutions",tools:["AI System Designer","Ethics Checklist Generator","Prototype Testing Environment","Peer Review Platform"],experiments:["ethical-hiring-system-design","fair-lending-algorithm","inclusive-healthcare-ai"],learningOutcomes:["Design ethical AI systems","Implement fairness measures","Test and iterate solutions"]})}setupExperiments(){this.experiments.set("dataset-bias-detection",{title:"Uncovering Hidden Bias in Training Data",difficulty:"intermediate",duration:E.DURATIONS.EXTENDED_SESSION,materials:["Simulated datasets","Analysis tools","Bias detection algorithms"],procedure:[{step:E.EXPERIMENT_STEPS.STEP_1,title:"Data Exploration",description:"Examine the composition of different datasets",activity:"Use visualization tools to explore demographic distributions",questions:["What groups are represented in this data?","Are all groups equally represented?","What might be missing from this dataset?"]},{step:E.EXPERIMENT_STEPS.STEP_2,title:"Bias Identification",description:"Apply bias detection techniques",activity:"Run automated bias detection algorithms",questions:["Where do the algorithms identify potential bias?","What types of bias are most common?","How confident should we be in these results?"]},{step:E.EXPERIMENT_STEPS.STEP_3,title:"Impact Analysis",description:"Predict real-world consequences",activity:"Model outcomes for different groups",questions:["How would this bias affect hiring decisions?","Which groups would benefit or be harmed?","What are the long-term societal implications?"]},{step:E.EXPERIMENT_STEPS.STEP_4,title:"Mitigation Strategies",description:"Develop approaches to reduce bias",activity:"Test different bias reduction techniques",questions:["Which mitigation strategies are most effective?","What are the trade-offs of each approach?","How do we measure success in bias reduction?"]}],assessment:{formative:["Lab notebook observations","Peer discussion participation","Question responses"],summative:["Bias analysis report","Mitigation strategy proposal","Reflection essay"]},extensions:["Research real-world bias cases","Interview data scientists about bias challenges","Propose policy solutions for algorithmic accountability"]}),this.experiments.set("stakeholder-impact-simulation",{title:"Multi-Stakeholder AI Impact Simulation",difficulty:"advanced",duration:E.DURATIONS.FULL_LAB_SESSION,materials:["Role-playing cards","Impact simulation software","Decision matrices"],setup:{scenario:"AI-powered content recommendation system for social media",stakeholders:[{role:"Platform Users",concerns:["Privacy","Content diversity","Mental health"]},{role:"Content Creators",concerns:["Visibility","Revenue","Creative freedom"]},{role:"Platform Company",concerns:["Engagement","Revenue","Legal compliance"]},{role:"Advertisers",concerns:["Target accuracy","Brand safety","ROI"]},{role:"Society/Public",concerns:["Misinformation","Social cohesion","Democratic discourse"]},{role:"Regulators",concerns:["Consumer protection","Competition","National security"]}]},phases:[{phase:"Stakeholder Research",duration:E.DURATIONS.SHORT_SESSION,activity:"Each group researches their stakeholder perspective",deliverable:"Stakeholder profile and key concerns"},{phase:"System Design Proposals",duration:E.DURATIONS.MEDIUM_SESSION,activity:"Groups propose AI system designs that benefit their stakeholder",deliverable:"Design proposal with justification"},{phase:"Cross-Stakeholder Negotiation",duration:E.DURATIONS.LONG_SESSION,activity:"Facilitated negotiation to find acceptable compromise",deliverable:"Negotiated system design"},{phase:"Impact Evaluation",duration:E.DURATIONS.SHORT_SESSION,activity:"Evaluate final design against all stakeholder needs",deliverable:"Impact assessment matrix"}]})}configureCollaboration(){this.collaborationTools.set("digital-whiteboard",{name:"Collaborative Ethics Mapping",purpose:"Visual collaboration on complex ethical issues",features:["Real-time collaborative drawing","Stakeholder mapping templates","Decision tree builders","Impact visualization tools"],integration:"Embedded in simulation interface"}),this.collaborationTools.set("peer-review-system",{name:"Structured Peer Review Platform",purpose:"Facilitate constructive feedback on ethical analyses",features:["Anonymous and identified review options","Rubric-based evaluation tools","Comment threading and discussion","Revision tracking and iteration support"],guidelines:this.createPeerReviewGuidelines()}),this.collaborationTools.set("discussion-facilitator",{name:"AI-Assisted Discussion Facilitator",purpose:"Support productive ethical discussions",features:["Conversation starter suggestions","Perspective diversity monitoring","Bias detection in arguments","Evidence integration prompts"],safeguards:["Human moderator override","Inappropriate content filtering","Balanced participation encouragement"]})}establishAssessment(){this.assessmentMethods.set("ethics-portfolio",{name:"AI Ethics Learning Portfolio",purpose:"Comprehensive documentation of ethical reasoning development",components:[{name:"Scenario Analysis Collection",description:"Student responses to various ethical scenarios",weight:E.ASSESSMENT_WEIGHTS.UNDERSTANDING,criteria:["Depth of analysis","Stakeholder consideration","Ethical reasoning"]},{name:"Bias Investigation Project",description:"In-depth study of bias in a chosen AI application",weight:E.ASSESSMENT_WEIGHTS.CRITICAL_THINKING,criteria:["Research quality","Analysis rigor","Solution creativity"]},{name:"Collaborative Design Challenge",description:"Group project to design ethical AI system",weight:E.ASSESSMENT_WEIGHTS.COLLABORATION,criteria:["Technical feasibility","Ethical integration","Team collaboration"]},{name:"Reflection Essays",description:"Personal growth and learning reflections",weight:E.ASSESSMENT_WEIGHTS.COMMUNICATION,criteria:["Self-awareness","Growth documentation","Critical thinking"]}],rubric:this.createPortfolioRubric()}),this.assessmentMethods.set("ethics-performance",{name:"Real-World Ethics Performance Assessment",purpose:"Evaluate ability to apply ethical reasoning in realistic contexts",tasks:[{name:"Ethics Consultation Simulation",description:"Student acts as ethics consultant for fictional AI company",scenario:"Company planning to deploy facial recognition in schools",deliverables:["Ethics assessment report","Stakeholder presentation","Policy recommendations"],timeframe:E.PROJECT_TIMELINE.WEEK_DURATION,evaluation:"Expert panel review (teachers, industry professionals, ethicists)"},{name:"Public Policy Testimony",description:"Student presents testimony on AI ethics to mock legislative committee",preparation:"Research current AI regulation proposals",performance:`${E.DURATIONS.PRESENTATION_TIME} followed by Q&A`,audience:"Peers role-playing legislators, advocacy groups, industry representatives"}]}),this.assessmentMethods.set("peer-assessment",{name:"Structured Peer Learning Assessment",purpose:"Develop evaluation skills while supporting peer learning",methods:[{name:"Ethics Reasoning Peer Review",process:"Students review and provide feedback on peers ethical analyses",training:"Rubric training and calibration exercises",support:"Structured feedback templates and examples"},{name:"Collaborative Solution Evaluation",process:"Teams evaluate each others AI ethics solutions",criteria:"Technical soundness, ethical thoroughness, practical feasibility",format:"Presentation with constructive critique session"}]})}createAgeAdaptations(){return{elementary:{approach:"Story-based and character-driven scenarios",examples:["Robot helper in classroom - how should it treat different students?","Game recommendation system - why do friends get different suggestions?","Photo tagging AI - when does it make mistakes and why?"],activities:["Role-playing with AI character cards","Drawing different solutions to AI problems","Simple voting on ethical choices with discussion"],assessments:["Story completion about fair AI behavior","Picture drawings of inclusive AI systems","Simple reflection questions with prompts"]},middle:{approach:"Problem-solving focused with guided discovery",scenarios:["School uses AI to assign students to classes","Social media platform decides what posts to show","AI helps doctors prioritize patient appointments"],activities:["Data analysis with simplified real datasets","Debate simulations with assigned perspectives","Design challenges with ethical constraints"],assessments:["Case study analysis with structured questions","Group presentation on bias solutions","Personal reflection on ethical decision-making"]},high:{approach:"Research-based inquiry with complex analysis",scenarios:["AI hiring system with demographic disparities","Predictive policing algorithm deployment","Healthcare AI with access and fairness issues"],activities:["Statistical analysis of algorithmic bias","Policy research and proposal development","Stakeholder interview and analysis projects"],assessments:["Research paper on AI ethics topic","Policy proposal with evidence and analysis","Capstone project addressing real-world AI ethics challenge"]},college:{approach:"Professional-level analysis with interdisciplinary integration",scenarios:["Corporate AI ethics consulting project","Academic research on algorithmic fairness","Government policy development on AI regulation"],activities:["Original research with data collection and analysis","Cross-disciplinary collaboration projects","Industry partnership and internship opportunities"],assessments:["Thesis-level research project","Professional consulting deliverables","Conference presentation or publication"]}}}integrateWithPlatform(e){return e.registerLabStation=(t,i)=>{this.labStations.set(t,i)},e.trackExperiment=(t,i)=>{this.recordExperimentData(t,i)},e.enableCollaboration=(t,i)=>this.activateCollaborationTool(t,i),e.generateAssessment=(t,i,n)=>this.createAssessment(t,i,n),e}setEducatorToolkit(e){this.educatorToolkit=e}setScenarioGenerator(e){this.scenarioGenerator=e}getRelevantStations(e){const t=[];for(const i of e)switch(i.toLowerCase()){case"bias":case"fairness":t.push(this.labStations.get("bias-analysis"));break;case"ethics":t.push(this.labStations.get("ethics-decision"));break;case"education":case"scenarios":t.push(this.labStations.get("solution-design"));break;case"open-ended":t.push(this.labStations.get("impact-analysis"));break}return t.length>E.ARRAY_THRESHOLDS.EMPTY_LENGTH?t:null}getExperimentsForLevel(e){const t=[];switch(e){case"beginner":t.push(this.experiments.get("dataset-bias-detection"));break;case"intermediate":t.push(this.experiments.get("dataset-bias-detection"),this.experiments.get("stakeholder-impact-simulation"));break;case"advanced":t.push(...this.experiments.values());break}return t}createPeerReviewGuidelines(){return{preparation:["Read the assignment carefully before reviewing","Consider the rubric criteria during review","Prepare specific, constructive feedback"],process:["Start with positive observations","Provide specific suggestions for improvement","Ask clarifying questions when confused","Reference examples or resources when helpful"],communication:["Use respectful, supportive language","Focus on the work, not the person","Be specific rather than general in feedback","Suggest rather than demand changes"]}}createPortfolioRubric(){return{exemplary:{description:"Demonstrates exceptional understanding and application of AI ethics",indicators:["Sophisticated analysis of complex ethical dilemmas","Creative and feasible solutions to bias problems","Deep reflection on personal growth and learning","Excellent integration of multiple perspectives"]},proficient:{description:"Shows solid understanding and good application of AI ethics concepts",indicators:["Clear analysis of ethical issues with good reasoning","Practical solutions to AI bias with some innovation","Thoughtful reflection on learning experience","Good consideration of different stakeholder views"]},developing:{description:"Demonstrates basic understanding with some application of concepts",indicators:["Basic analysis of ethical issues with limited reasoning","Simple solutions to bias problems with little innovation","Surface-level reflection on learning","Limited consideration of multiple perspectives"]},beginning:{description:"Shows minimal understanding and limited application",indicators:["Unclear or incomplete analysis of ethical issues","Unrealistic or inappropriate solutions proposed","Little evidence of reflection or growth","Single perspective or viewpoint considered"]}}}}const L={DEFAULT_SCENARIO_COUNT:3,LOOP_INDICES:{START:0,INCREMENT:1},FALLBACK_VALUES:{SCENARIO_NUMBER_OFFSET:1},STAKEHOLDER_GROUPS:{ELEMENTARY:{MIN:2,MAX:3},MIDDLE:{MIN:3,MAX:4},HIGH:{MIN:4,MAX:6}},TRAUMA_CENTER_LEVEL:1};class Xe{constructor(){this.scenarioTemplates=new Map,this.adaptationStrategies=new Map,this.realWorldCases=new Map,this.stakeholderProfiles=new Map,this.initializeTemplates(),this.setupAdaptations(),this.loadRealWorldCases(),this.createStakeholderProfiles()}initializeTemplates(){this.scenarioTemplates.set("healthcare",{domain:"Healthcare",baseScenarios:[{id:"emergency-triage",title:"AI Emergency Room Triage System",context:"A busy hospital emergency room uses AI to prioritize patient care",description:"Design an AI system that helps medical staff decide which patients need immediate attention",setting:`Urban Level ${L.TRAUMA_CENTER_LEVEL} Trauma Center during flu season`,stakeholders:["Patients","Emergency physicians","Nurses","Hospital administrators","Insurance companies","Community"],ethicalDilemmas:["How should age factor into priority decisions?","Should insurance status influence care priority?","How do we handle unconscious patients with unknown medical history?","What role should patient ability to pay play?"],realWorldConnection:"Multiple hospitals use AI-assisted triage systems"},{id:"diagnostic-imaging",title:"AI Medical Imaging Analysis",context:"An AI system analyzes medical scans to detect diseases",description:"Create guidelines for an AI that helps radiologists identify potential health issues",setting:"Regional medical center serving diverse rural and urban populations",stakeholders:["Patients","Radiologists","Primary care physicians","Healthcare systems","AI developers"],ethicalDilemmas:["How accurate must AI be before deployment?","Who is responsible when AI misses a diagnosis?","Should AI recommendations be visible to patients?","How do we ensure fairness across different demographic groups?"]},{id:"mental-health-chatbot",title:"AI Mental Health Support System",context:"A chatbot provides initial mental health screening and support",description:"Design an AI system that offers mental health guidance while ensuring safety",setting:"College campus mental health services",stakeholders:["Students","Mental health counselors","University administration","Parents/families","Crisis intervention teams"],ethicalDilemmas:["When should AI escalate to human counselors?","How do we balance privacy with safety concerns?","Should AI have access to academic or social media data?","How do we prevent AI from giving harmful advice?"]}]}),this.scenarioTemplates.set("education",{domain:"Education",baseScenarios:[{id:"adaptive-learning",title:"Personalized AI Tutor System",context:"An AI system adapts learning materials to individual student needs",description:"Create an AI tutor that personalizes education while promoting equity",setting:"Public middle school with diverse socioeconomic student body",stakeholders:["Students","Teachers","Parents","School administrators","Educational technology companies"],ethicalDilemmas:["How much student data should AI systems collect?","Should AI adapt to learning disabilities differently?","How do we prevent AI from reinforcing educational inequalities?","What happens when AI and teachers disagree on student needs?"]},{id:"college-admissions",title:"AI College Admissions Assistant",context:"Universities use AI to help evaluate and rank college applications",description:"Design an AI system that fairly evaluates diverse student applications",setting:"Competitive state university admissions office",stakeholders:["Prospective students","Current students","Admissions officers","University administration","Alumni","Society"],ethicalDilemmas:["How should AI weigh standardized test scores vs other factors?","Should AI consider applicant socioeconomic background?","How do we ensure fairness across different high schools?","What role should legacy status or athletic ability play?"]},{id:"classroom-monitoring",title:"AI Classroom Engagement Monitor",context:"An AI system tracks student attention and engagement during lessons",description:"Create an AI system that helps teachers understand student engagement",setting:"High school classroom with mandatory attendance",stakeholders:["Students","Teachers","Parents","School administrators","Privacy advocates"],ethicalDilemmas:["How much student behavior should AI monitor?","Should parents have access to engagement data?","How do we protect student privacy and autonomy?","What happens when AI identifies students as disengaged?"]}]}),this.scenarioTemplates.set("criminal-justice",{domain:"Criminal Justice",baseScenarios:[{id:"predictive-policing",title:"AI Crime Prediction System",context:"Police departments use AI to predict where crimes are likely to occur",description:"Design an AI system that helps allocate police resources fairly and effectively",setting:"Metropolitan police department in diverse urban area",stakeholders:["Community members","Police officers","City officials","Civil rights advocates","Crime victims"],ethicalDilemmas:["How do we prevent AI from perpetuating historical policing biases?","Should AI recommendations influence where officers patrol?","How do we balance public safety with community trust?","What data should be included in crime prediction models?"]},{id:"bail-recommendation",title:"AI Bail Decision Support",context:"Courts use AI to help judges make bail and pretrial detention decisions",description:"Create an AI system that assists with fair pretrial release decisions",setting:"Urban courthouse with heavy case loads",stakeholders:["Defendants","Judges","Prosecutors","Defense attorneys","Community safety advocates","Taxpayers"],ethicalDilemmas:["What factors should AI consider in bail recommendations?","How do we address racial and economic bias in historical data?","Should AI recommendations be binding or advisory?","How do we balance public safety with individual rights?"]}]}),this.scenarioTemplates.set("workplace",{domain:"Workplace",baseScenarios:[{id:"performance-evaluation",title:"AI Employee Performance System",context:"Companies use AI to monitor and evaluate employee performance",description:"Design an AI system that fairly assesses worker productivity and growth",setting:"Technology company with remote and in-office workers",stakeholders:["Employees","Managers","HR departments","Company executives","Labor unions","Customers"],ethicalDilemmas:["How much employee activity should AI monitor?","Should AI performance metrics affect compensation and promotion?","How do we account for different work styles and life circumstances?","What happens when AI identifies underperforming employees?"]},{id:"gig-worker-matching",title:"AI Gig Economy Platform",context:"A platform uses AI to match gig workers with jobs and set pay rates",description:"Create an AI system that fairly connects workers with opportunities",setting:"Food delivery and rideshare platform in major metropolitan area",stakeholders:["Gig workers","Customers","Platform company","Restaurants/businesses","Local government","Traditional employment advocates"],ethicalDilemmas:["How should AI determine fair pay rates for different workers?","Should AI consider worker financial need when assigning jobs?","How do we prevent discrimination in job matching?","What happens when AI optimizes for company profit vs worker welfare?"]}]}),this.scenarioTemplates.set("consumer",{domain:"Consumer Technology",baseScenarios:[{id:"social-media-content",title:"AI Social Media Content Curation",context:"Social media platforms use AI to decide what content users see",description:"Design an AI system that curates social media feeds responsibly",setting:"Global social media platform with billions of users",stakeholders:["Platform users","Content creators","Platform company","Advertisers","Governments","Civil society organizations"],ethicalDilemmas:["How should AI balance engagement with user well-being?","Should AI promote content diversity or user preferences?","How do we handle misinformation and harmful content?","What role should AI play in moderating political discourse?"]},{id:"voice-assistant-privacy",title:"AI Voice Assistant Data Collection",context:"Smart speakers and voice assistants collect and analyze user conversations",description:"Create guidelines for AI voice assistants that respect privacy while providing helpful services",setting:"Homes, offices, and public spaces with voice-activated devices",stakeholders:["Device users","Family members","Technology companies","Privacy advocates","Government regulators","Third-party app developers"],ethicalDilemmas:["How much conversation should AI systems record and analyze?","Should AI distinguish between intended commands and private conversations?","How do we protect children and vulnerable populations?","What happens when voice data is subpoenaed by law enforcement?"]}]})}setupAdaptations(){this.adaptationStrategies.set("elementary",{approach:"Narrative and character-based",language:"Simple, concrete terms with visual metaphors",complexity:"Single primary dilemma with clear choices",stakeholders:`Reduced to ${L.STAKEHOLDER_GROUPS.ELEMENTARY.MIN}-${L.STAKEHOLDER_GROUPS.ELEMENTARY.MAX} main groups with clear motivations`,activities:["Story-telling with AI characters","Simple choice voting with discussion","Drawing solutions and sharing","Role-playing with guided scripts"],assessment:["Verbal explanation of choices","Drawing representations of fair solutions","Simple reflection questions with prompts"]}),this.adaptationStrategies.set("middle",{approach:"Problem-solving with guided discovery",language:"Age-appropriate with some technical terms explained",complexity:"Multiple related dilemmas with guided analysis",stakeholders:`${L.STAKEHOLDER_GROUPS.MIDDLE.MIN}-${L.STAKEHOLDER_GROUPS.MIDDLE.MAX} groups with competing but understandable interests`,activities:["Structured debates with assigned positions","Small group problem-solving challenges","Data analysis with simplified tools","Creative solution brainstorming"],assessment:["Written case study analysis","Group presentation of solutions","Peer feedback and discussion","Reflection journal entries"]}),this.adaptationStrategies.set("high",{approach:"Research and analysis-based exploration",language:"Technical terms with proper context and explanation",complexity:"Multiple interconnected dilemmas requiring synthesis",stakeholders:`${L.STAKEHOLDER_GROUPS.HIGH.MIN}-${L.STAKEHOLDER_GROUPS.HIGH.MAX} groups with nuanced and conflicting interests`,activities:["Independent research projects","Mock professional consultations","Statistical analysis of bias and fairness","Policy proposal development"],assessment:["Research papers with evidence and analysis","Professional-style presentations","Peer review and critique","Capstone projects addressing real issues"]}),this.adaptationStrategies.set("college",{approach:"Professional and interdisciplinary analysis",language:"Professional terminology with academic rigor",complexity:"Complex, multifaceted scenarios with ambiguous solutions",stakeholders:"Full range of affected parties with detailed perspectives",activities:["Original research with data collection","Cross-disciplinary collaboration projects","Industry partnership opportunities","Academic conference presentations"],assessment:["Thesis-level research and analysis","Professional consulting deliverables","Publication-quality work","Real-world implementation proposals"]})}loadRealWorldCases(){this.realWorldCases.set("healthcare-bias",{title:"Racial Bias in Healthcare AI Algorithms",summary:"Healthcare algorithms systematically underestimated the healthcare needs of Black patients",source:"Academic research published in Science magazine",impact:"Affected millions of patients in the US healthcare system",lessons:["Historical healthcare data can perpetuate existing inequalities","Proxy variables can hide discriminatory patterns","Algorithm auditing requires diverse perspectives","Fixing bias requires both technical and policy solutions"],discussion:["How could developers have detected this bias earlier?","What changes to data collection might prevent similar issues?","How should healthcare systems audit existing AI tools?","What role should patients play in AI development and oversight?"]}),this.realWorldCases.set("hiring-discrimination",{title:"AI Hiring Tool Showed Bias Against Women",summary:"Amazon's experimental hiring algorithm was biased against women candidates",source:"Reuters investigation and company statements",impact:"Led to abandonment of the tool and industry-wide reflection",lessons:["Training data reflects historical discrimination patterns","Technical performance metrics may miss fairness issues","Industry underrepresentation affects AI development","Regular bias testing is essential for AI systems"],discussion:["What alternative approaches might create fairer hiring systems?","How can companies audit existing hiring practices for bias?","What role should diverse teams play in AI development?","How do we balance efficiency with fairness in hiring?"]}),this.realWorldCases.set("criminal-justice-bias",{title:"COMPAS Risk Assessment Algorithm Bias",summary:"Criminal justice risk assessment tool showed racial bias in recidivism predictions",source:"ProPublica investigation and academic research",impact:"Influenced sentencing and parole decisions for thousands",lessons:["Historical crime data reflects biased enforcement patterns","Risk assessment tools can perpetuate systemic inequalities","Transparency in algorithmic decision-making is crucial","Different definitions of fairness can conflict with each other"],discussion:["How should courts balance algorithmic efficiency with human judgment?","What data should be excluded from criminal justice algorithms?","How do we measure and achieve fairness in risk assessment?","What role should community input play in justice AI systems?"]})}createStakeholderProfiles(){this.stakeholderProfiles.set("healthcare-patient",{perspective:"Healthcare Patient",concerns:["Quality of care","Privacy protection","Fair treatment","Access to services"],motivations:["Health and well-being","Dignity and respect","Timely care","Affordable treatment"],constraints:["Limited health literacy","Financial limitations","Insurance restrictions","Geographic barriers"],questions:["Will AI help me get better care or create barriers?","Who has access to my health data and how is it used?","What happens if AI makes a mistake about my health?","Will AI treat me fairly regardless of my background?"]}),this.stakeholderProfiles.set("healthcare-provider",{perspective:"Healthcare Provider",concerns:["Patient outcomes","Liability and malpractice","Workflow efficiency","Professional autonomy"],motivations:["Providing best possible care","Reducing medical errors","Managing workload","Professional development"],constraints:["Time pressures","Legal requirements","Technology limitations","Resource constraints"],questions:["How can AI help me provide better patient care?","What happens if I disagree with AI recommendations?","Am I liable if AI-assisted decisions cause harm?","How do I maintain my professional skills and judgment?"]}),this.stakeholderProfiles.set("student",{perspective:"Student",concerns:["Learning effectiveness","Privacy protection","Fair assessment","Future opportunities"],motivations:["Academic success","Personal growth","Career preparation","Social connection"],constraints:["Academic pressure","Limited resources","Technology access","Time management"],questions:["Will AI help me learn better or just monitor me more?","How is my data being used and who can see it?","Will AI assessments be fair to students like me?","What happens to my privacy and autonomy?"]}),this.stakeholderProfiles.set("educator",{perspective:"Educator",concerns:["Student learning outcomes","Teaching effectiveness","Professional autonomy","Equity in education"],motivations:["Supporting student success","Improving teaching practice","Reducing workload","Professional growth"],constraints:["Limited training time","Technology budgets","Administrative requirements","Class size"],questions:["How can AI enhance rather than replace my teaching?","Will AI help me reach all students effectively?","How do I maintain meaningful relationships with students?","What training do I need to use AI tools responsibly?"]})}generateScenario(e,t,i={}){const n=this.scenarioTemplates.get(e),s=this.adaptationStrategies.get(t);if(!n||!s)throw new Error(`Invalid domain (${e}) or age group (${t})`);const a=i.scenarioId?n.baseScenarios.find(c=>c.id===i.scenarioId):n.baseScenarios[Math.floor(Math.random()*n.baseScenarios.length)],r=this.adaptScenarioForAge(a,s,i);return i.includeRealWorld&&(r.realWorldCases=this.getRelevantRealWorldCases(e)),i.includeEducatorResources&&(r.educatorResources=this.generateEducatorResources(r,t)),r}adaptScenarioForAge(e,t,i){return{...e,description:this.adaptLanguage(e.description,t.language),context:this.adaptLanguage(e.context,t.language),stakeholders:this.adaptStakeholders(e.stakeholders,t.stakeholders),ethicalDilemmas:this.adaptDilemmas(e.ethicalDilemmas,t.complexity),activities:t.activities,assessment:t.assessment,choices:this.generateChoices(e,t),discussionPrompts:this.generateDiscussionPrompts(e,t),reflectionQuestions:this.generateReflectionQuestions(e,t)}}generateChoices(e,t){return[{category:"System Design",question:"How should the AI system work?",options:this.generateSystemDesignChoices(e,t)},{category:"Data Usage",question:"What information should the AI use?",options:this.generateDataChoices(e,t)},{category:"Fairness Approach",question:"How should the AI ensure fairness?",options:this.generateFairnessChoices(e,t)},{category:"Human Oversight",question:"What role should humans play?",options:this.generateOversightChoices(e,t)}]}generateSystemDesignChoices(e,t){const i=[{id:"fully-automated",label:"Fully Automated",description:"AI makes all decisions automatically",pros:["Fast and efficient","Consistent decisions","Handles large volumes"],cons:["Less flexibility","Hard to explain decisions","May miss context"]},{id:"ai-assisted",label:"AI-Assisted",description:"AI provides recommendations for human decision-makers",pros:["Combines AI efficiency with human judgment","Easier to explain","Maintains human control"],cons:["Slower than automated","Requires training","May introduce human bias"]},{id:"human-reviewed",label:"Human-Reviewed",description:"AI makes decisions but humans review them",pros:["Catches AI errors","Maintains oversight","Builds trust"],cons:["Resource intensive","May create bottlenecks","Reviewer bias possible"]}];return this.adaptChoicesForAge(i,t)}adaptChoicesForAge(e,t){return e.map(i=>({...i,description:this.adaptLanguage(i.description,t.language),pros:i.pros.map(n=>this.adaptLanguage(n,t.language)),cons:i.cons.map(n=>this.adaptLanguage(n,t.language))}))}adaptLanguage(e,t){return t.includes("Simple")?e.replace(/algorithm/gi,"computer program").replace(/stakeholder/gi,"person affected").replace(/implementation/gi,"putting into use").replace(/optimization/gi,"making work better"):e}generateDataChoices(e,t){return[]}generateFairnessChoices(e,t){return[]}generateOversightChoices(e,t){return[]}adaptStakeholders(e,t){return e}adaptDilemmas(e,t){return e}generateDiscussionPrompts(e,t){return[]}generateReflectionQuestions(e,t){return[]}getRelevantRealWorldCases(e){return Array.from(this.realWorldCases.values()).filter(t=>t.title.toLowerCase().includes(e.toLowerCase()))}generateEducatorResources(e,t){return{lessonPlan:this.generateLessonPlan(e,t),activities:this.generateTeachingActivities(e,t),assessment:this.generateAssessmentTools(e,t),background:this.generateBackgroundInfo(e),extensions:this.generateExtensionActivities(e,t)}}generateLessonPlan(e,t){return{}}generateTeachingActivities(e,t){return[]}generateAssessmentTools(e,t){return{}}generateBackgroundInfo(e){return{}}generateExtensionActivities(e,t){return[]}generateScenarios(e,t,i=L.DEFAULT_SCENARIO_COUNT){try{const n=[],s=this.scenarioTemplates.get(e);if(!s)return this.createFallbackScenarios(e,t,i);for(let a=L.LOOP_INDICES.START;a<Math.min(i,s.baseScenarios.length);a++){const r=s.baseScenarios[a],c=this.generateScenario(e,this.mapDifficultyToAge(t),{scenarioId:r.id,includeRealWorld:t!=="beginner",includeEducatorResources:!0});n.push(c)}return n}catch(n){return o.error("Error generating scenarios:",n),this.createFallbackScenarios(e,t,i)}}mapDifficultyToAge(e){switch(e){case"beginner":return"middle";case"intermediate":return"high";case"advanced":return"college";default:return"high"}}createFallbackScenarios(e,t,i){const n=[];for(let s=L.LOOP_INDICES.START;s<i;s++)n.push({id:`fallback-${e}-${s}`,title:`AI Ethics Scenario ${s+L.FALLBACK_VALUES.SCENARIO_NUMBER_OFFSET}`,description:`Explore ethical considerations in AI applications for ${e}`,context:`A scenario exploring AI ethics in the context of ${e}`,stakeholders:["Users","Developers","Society","Regulators"],ethicalDilemmas:["How do we ensure fairness in AI decisions?","What data should AI systems use?","How do we maintain human oversight?","What are the unintended consequences?"],choices:this.createBasicChoices(),activities:this.getActivitiesForDifficulty(t),assessment:this.getAssessmentForDifficulty(t)});return n}createBasicChoices(){return[{category:"Approach",question:"How should the AI system be designed?",options:[{id:"efficiency",label:"Efficiency Focused",description:"Prioritize speed and accuracy",pros:["Fast results","High accuracy"],cons:["May miss edge cases","Less flexible"]},{id:"fairness",label:"Fairness Focused",description:"Prioritize equal treatment",pros:["More equitable","Considers all groups"],cons:["May be slower","More complex"]},{id:"transparency",label:"Transparency Focused",description:"Prioritize explainability",pros:["Easy to understand","Builds trust"],cons:["May sacrifice accuracy","More complex to build"]}]}]}getActivitiesForDifficulty(e){switch(e){case"beginner":return["Discussion and voting","Simple role-playing","Drawing solutions"];case"intermediate":return["Structured debates","Case study analysis","Group problem-solving"];case"advanced":return["Research projects","Policy development","Statistical analysis"];default:return["Discussion and analysis","Problem-solving","Reflection"]}}getAssessmentForDifficulty(e){switch(e){case"beginner":return["Verbal explanations","Simple reflections","Peer discussions"];case"intermediate":return["Written analysis","Group presentations","Case studies"];case"advanced":return["Research papers","Policy proposals","Professional presentations"];default:return["Reflections","Discussions","Written responses"]}}}const I={DEFAULT_WIDTH:400,DEFAULT_HEIGHT:300,MIN_WIDTH:100,MIN_HEIGHT:100,MAX_WIDTH:4096,MAX_HEIGHT:4096,RESIZE_DEBOUNCE:100,CLEANUP_INTERVAL:3e5,TOUCH_TARGET_SIZE:44,FOCUS_RING_WIDTH:3},Y={ENGINE_CREATION:50,RENDER_TARGET:16,DEFAULT_OPERATION:25,SIGNIFICANT_SIZE_CHANGE:50,DIMENSION_TOLERANCE:5},se=1024,_={BYTES_PER_PIXEL:4,KB_SIZE:se,BYTES_PER_KB:se,BYTES_PER_MB:se*se,DEFAULT_MAX_MEMORY_MB:100,CLEANUP_MAX_AGE_MINUTES:30,SECONDS_PER_MINUTE:60,MS_PER_SECOND:1e3},Je={get DEFAULT_MAX_MEMORY(){return _.DEFAULT_MAX_MEMORY_MB*_.BYTES_PER_MB},get CLEANUP_MAX_AGE(){return _.CLEANUP_MAX_AGE_MINUTES*_.SECONDS_PER_MINUTE*_.MS_PER_SECOND}},$={CANVAS_CREATED:"canvas:created",CANVAS_REMOVED:"canvas:removed",ENGINE_CREATED:"canvas:engineCreated",ENGINE_REMOVED:"canvas:engineRemoved",PERFORMANCE_WARNING:"canvas:performanceWarning",ERROR_OCCURRED:"canvas:errorOccurred",RESIZE_DETECTED:"canvas:resizeDetected"};class Q{static getCurrentTheme(){const e=window.matchMedia?.("(prefers-contrast: high)").matches,t=window.matchMedia?.("(prefers-reduced-motion: reduce)").matches;return{highContrast:e,reducedMotion:t,theme:e?"highContrast":"light"}}static getCanvasStyle(e=null){const t=e||this.getCurrentTheme();return{backgroundColor:t.highContrast?"#000000":"#ffffff",borderColor:t.highContrast?"#ffff00":"#e0e0e0",focusColor:t.highContrast?"#ffff00":"#007bff"}}}class ge{static startOperation(e){const t=performance.now();return this.operations.set(e,t),t}static endOperation(e,t){const n=performance.now()-t;this.metrics.has(e)||this.metrics.set(e,{count:0,totalTime:0,averageTime:0,maxTime:0,minTime:1/0});const s=this.metrics.get(e);s.count++,s.totalTime+=n,s.averageTime=s.totalTime/s.count,s.maxTime=Math.max(s.maxTime,n),s.minTime=Math.min(s.minTime,n),this.operations.delete(e);const r=(c=>c.includes("engine-creation")||c.includes("canvas-creation")?Y.ENGINE_CREATION:c.includes("render")||c.includes("draw")?Y.RENDER_TARGET:Y.DEFAULT_OPERATION)(e);return n>r&&o.warn(`Slow canvas operation: ${e} took ${n.toFixed(2)}ms (threshold: ${r}ms)`),n}static getMetrics(){return Object.fromEntries(this.metrics)}static reset(){this.metrics.clear(),this.operations.clear()}}ne(ge,"metrics",new Map),ne(ge,"operations",new Map);class C extends Error{constructor(e,t={},i=null){super(e),this.name="CanvasError",this.context=t,this.canvasId=t.canvasId,this.timestamp=Date.now(),this.theme=Q.getCurrentTheme(),this.originalError=i}}class Ze{constructor(){this.canvases=new Map,this.visualEngines=new Map,this.activeEngines=new Set,this.nextId=1,this.eventListeners=new Map,this.resizeObservers=new Map,this.performanceMonitor=ge,this.theme=Q.getCurrentTheme(),this.cleanupInterval=null,this.accessibilityEnabled=!0,this.touchSupported="ontouchstart"in window,this.errorCount=0,this.setupThemeMonitoring(),this.setupPeriodicCleanup(),this.setupErrorHandling(),o.debug("Enhanced CanvasManager initialized with advanced features")}setupThemeMonitoring(){const e=window.matchMedia?.("(prefers-contrast: high)"),t=window.matchMedia?.("(prefers-reduced-motion: reduce)"),i=()=>{this.theme=Q.getCurrentTheme(),this.updateAllCanvasThemes(),this.emit($.THEME_CHANGED,{theme:this.theme})};e?.addEventListener?.("change",i),t?.addEventListener?.("change",i),this.themeQueries={contrastQuery:e,motionQuery:t},this.themeChangeHandler=i}setupPeriodicCleanup(){this.cleanupInterval=setInterval(()=>{this.performMaintenanceCleanup()},I.CLEANUP_INTERVAL)}setupErrorHandling(){window.addEventListener("error",e=>{e.target&&e.target.tagName==="CANVAS"&&this.handleError(new C("Canvas error detected",{canvasId:e.target.id,error:e.error},e.error))})}updateAllCanvasThemes(){const e=Q.getCanvasStyle(this.theme);for(const[t,i]of this.canvases)try{this.applyCanvasTheme(i.element,e);const n=this.visualEngines.get(t);n&&n.updateTheme&&n.updateTheme(this.theme.theme)}catch(n){this.handleError(new C("Failed to update canvas theme",{canvasId:t},n))}}applyCanvasTheme(e,t){e&&(e.style.backgroundColor=t.backgroundColor,e.style.border=`1px solid ${t.borderColor}`,e.style.outline="none",e.classList.toggle("canvas-high-contrast",this.theme.highContrast),e.classList.toggle("canvas-reduced-motion",this.theme.reducedMotion))}async createCanvas(e={}){const t=this.performanceMonitor.startOperation("canvas-creation");try{const{width:i=I.DEFAULT_WIDTH,height:n=I.DEFAULT_HEIGHT,id:s=null,container:a=null,className:r="managed-canvas",accessibility:c=!0,responsive:d=!1,touchSupport:u=this.touchSupported,ariaLabel:h="Interactive canvas element"}=e,p=Math.max(I.MIN_WIDTH,Math.min(I.MAX_WIDTH,i)),g=Math.max(I.MIN_HEIGHT,Math.min(I.MAX_HEIGHT,n)),y=s||`managed-canvas-${this.nextId++}`;if(this.canvases.has(y))return o.warn(`Canvas with ID ${y} already exists. Returning existing canvas.`),{canvas:this.canvases.get(y).element,id:y};const m=document.createElement("canvas");m.id=y,m.width=p,m.height=g,m.className=`${r} canvas-managed`,c&&this.accessibilityEnabled&&this.setupCanvasAccessibility(m,{ariaLabel:h,role:e.role||"img",description:e.description});const R=Q.getCanvasStyle(this.theme);this.applyCanvasTheme(m,R),u&&this.setupTouchSupport(m);const v={element:m,created:Date.now(),options:{...e,width:p,height:g},accessibility:c,responsive:d,touchSupport:u,resizeObserver:null,performanceMetrics:{renderCount:0,totalRenderTime:0,averageRenderTime:0}};return this.canvases.set(y,v),a&&(a.appendChild(m),d&&this.makeResponsive(y)),this.emit($.CANVAS_CREATED,{canvasId:y,dimensions:{width:p,height:g},timestamp:Date.now()}),o.debug(`Created enhanced canvas: ${y} (${p}x${g})`),{canvas:m,id:y}}catch(i){throw this.handleError(new C("Failed to create canvas",{options:e},i)),i}finally{this.performanceMonitor.endOperation("canvas-creation",t)}}setupCanvasAccessibility(e,t){const{ariaLabel:i,role:n,description:s}=t;if(e.setAttribute("role",n),e.setAttribute("aria-label",i),e.setAttribute("tabindex","0"),s){const a=`${e.id}-description`,r=document.createElement("div");r.id=a,r.className="sr-only",r.textContent=s,e.parentNode?.insertBefore(r,e.nextSibling),e.setAttribute("aria-describedby",a)}e.addEventListener("focus",()=>{e.style.outline=`${I.FOCUS_RING_WIDTH}px solid ${Q.getCanvasStyle(this.theme).focusColor}`,e.style.outlineOffset="2px"}),e.addEventListener("blur",()=>{e.style.outline="none"}),e.addEventListener("keydown",a=>{this.handleCanvasKeydown(e.id,a)})}setupTouchSupport(e){e.style.touchAction="manipulation",e.style.minWidth=`${I.TOUCH_TARGET_SIZE}px`,e.style.minHeight=`${I.TOUCH_TARGET_SIZE}px`,e.addEventListener("touchstart",t=>{t.preventDefault()},{passive:!1}),e.addEventListener("touchmove",t=>{t.preventDefault()},{passive:!1})}handleCanvasKeydown(e,t){const i=this.visualEngines.get(e);switch(t.key){case"Enter":case" ":i&&i.handleInteraction&&i.handleInteraction("activate"),t.preventDefault();break;case"Escape":i&&i.handleInteraction&&i.handleInteraction("cancel"),t.preventDefault();break;case"ArrowUp":case"ArrowDown":case"ArrowLeft":case"ArrowRight":i&&i.handleNavigation&&i.handleNavigation(t.key),t.preventDefault();break}}async createVisualEngine(e,t={}){const i=this.performanceMonitor.startOperation("engine-creation");try{const n=this.canvases.get(e);if(!n)throw new C(`Canvas ${e} not found. Create canvas first.`,{canvasId:e});if(this.visualEngines.has(e))return o.warn(`Visual engine for ${e} already exists. Returning existing engine.`),this.visualEngines.get(e);const s={renderMode:"canvas",accessibility:this.accessibilityEnabled,debug:!1,theme:this.theme.theme,performance:{monitoring:!0,targetFPS:60,maxMemoryUsage:Je.DEFAULT_MAX_MEMORY},...t},a=await x(()=>import("./visual-engine-CPXCswte.js"),__vite__mapDeps([0,1,2]),import.meta.url),r=new a.default(n.element,s);return r.setTheme&&r.setTheme(this.theme.theme),r.setPerformanceMonitor&&r.setPerformanceMonitor(this.performanceMonitor),r.setErrorHandler&&r.setErrorHandler(c=>{this.handleError(new C("Visual engine error",{canvasId:e,engineError:c.message},c))}),this.visualEngines.set(e,r),this.activeEngines.add(e),this.setupEngineEventListeners(e,r),this.emit($.ENGINE_CREATED,{canvasId:e,engineOptions:s,timestamp:Date.now()}),o.debug(`Created enhanced visual engine for canvas: ${e}`),r}catch(n){throw this.handleError(new C(`Failed to create visual engine for ${e}`,{canvasId:e,engineOptions:t},n)),n}finally{this.performanceMonitor.endOperation("engine-creation",i)}}setupEngineEventListeners(e,t){t.on&&(t.on("render",i=>{const n=this.canvases.get(e);n&&(n.performanceMetrics.renderCount++,n.performanceMetrics.totalRenderTime+=i,n.performanceMetrics.averageRenderTime=n.performanceMetrics.totalRenderTime/n.performanceMetrics.renderCount,i>Y.RENDER_TARGET&&this.emit($.PERFORMANCE_WARNING,{canvasId:e,renderTime:i,threshold:16}))}),t.on("error",i=>{this.handleError(new C("Engine error event",{canvasId:e},i))}),t.on("accessibility",i=>{i.announcement&&this.announceToScreenReader(i.announcement)}))}announceToScreenReader(e,t="polite"){if(!this.accessibilityEnabled)return;const i=document.createElement("div");i.setAttribute("aria-live",t),i.setAttribute("aria-atomic","true"),i.className="sr-only",i.textContent=e,document.body.appendChild(i),setTimeout(()=>{document.body.removeChild(i)},1e3)}getCanvas(e){const t=this.canvases.get(e);return t?t.element:null}getVisualEngine(e){return this.visualEngines.get(e)}async removeCanvas(e){const t=this.performanceMonitor.startOperation("canvas-removal");try{await this.removeVisualEngine(e);const i=this.canvases.get(e);if(i){i.resizeObserver&&i.resizeObserver.disconnect();const n=document.getElementById(`${e}-description`);n&&n.remove(),i.element.parentNode&&i.element.parentNode.removeChild(i.element),this.canvases.delete(e),this.emit($.CANVAS_REMOVED,{canvasId:e,timestamp:Date.now()}),o.debug(`Removed canvas: ${e}`)}}catch(i){this.handleError(new C("Failed to remove canvas",{canvasId:e},i))}finally{this.performanceMonitor.endOperation("canvas-removal",t)}}async removeVisualEngine(e){const t=this.performanceMonitor.startOperation("engine-removal");try{const i=this.visualEngines.get(e);if(i){try{i.pause&&i.pause(),i.removeAllListeners&&i.removeAllListeners(),i.destroy?await i.destroy():i.cleanup&&await i.cleanup(),i.scene&&i.scene.clear&&i.scene.clear();const n=this.getCanvas(e);if(n){const s=n.getContext("2d");s&&s.clearRect(0,0,n.width,n.height)}}catch(n){o.warn(`Error during engine cleanup for ${e}:`,n)}this.visualEngines.delete(e),this.activeEngines.delete(e),this.emit($.ENGINE_REMOVED,{canvasId:e,timestamp:Date.now()}),o.debug(`Removed visual engine: ${e}`)}}catch(i){this.handleError(new C("Failed to remove visual engine",{canvasId:e},i))}finally{this.performanceMonitor.endOperation("engine-removal",t)}}async cleanup(){const e=this.performanceMonitor.startOperation("full-cleanup");try{if(o.debug("Starting enhanced canvas manager cleanup..."),this.cleanupInterval&&(clearInterval(this.cleanupInterval),this.cleanupInterval=null),this.themeQueries){const{contrastQuery:n,motionQuery:s}=this.themeQueries;n?.removeEventListener?.("change",this.themeChangeHandler),s?.removeEventListener?.("change",this.themeChangeHandler)}const t=[];for(const n of this.visualEngines.keys())t.push(this.removeVisualEngine(n));await Promise.all(t);const i=[];for(const n of this.canvases.keys())i.push(this.removeCanvas(n));await Promise.all(i),this.eventListeners.clear();for(const n of this.resizeObservers.values())n.disconnect();this.resizeObservers.clear(),this.performanceMonitor.reset(),o.debug("Enhanced canvas manager cleanup complete")}catch(t){this.handleError(new C("Failed to complete cleanup",{},t))}finally{this.performanceMonitor.endOperation("full-cleanup",e)}}pauseAll(){const e=this.performanceMonitor.startOperation("pause-all");try{this.activeEngines.forEach(t=>{const i=this.visualEngines.get(t);if(i&&i.pause)try{i.pause()}catch(n){o.warn(`Failed to pause engine ${t}:`,n)}}),o.debug(`Paused ${this.activeEngines.size} active engines`)}catch(t){this.handleError(new C("Failed to pause all engines",{},t))}finally{this.performanceMonitor.endOperation("pause-all",e)}}resumeAll(){const e=this.performanceMonitor.startOperation("resume-all");try{this.activeEngines.forEach(t=>{const i=this.visualEngines.get(t);if(i&&i.resume)try{i.resume()}catch(n){o.warn(`Failed to resume engine ${t}:`,n)}}),o.debug(`Resumed ${this.activeEngines.size} active engines`)}catch(t){this.handleError(new C("Failed to resume all engines",{},t))}finally{this.performanceMonitor.endOperation("resume-all",e)}}getStatus(){return{canvases:Array.from(this.canvases.keys()),visualEngines:Array.from(this.visualEngines.keys()),activeEngines:Array.from(this.activeEngines),totalCanvases:this.canvases.size,totalEngines:this.visualEngines.size,theme:this.theme,performance:this.performanceMonitor.getMetrics(),accessibility:this.accessibilityEnabled,touchSupported:this.touchSupported,errorCount:this.errorCount,memoryUsage:this.getMemoryUsage()}}getMemoryUsage(){let e=0;for(const[,t]of this.canvases){const i=t.element,n=i.width*i.height*_.BYTES_PER_PIXEL;e+=n}return{estimatedBytes:e,estimatedMB:(e/_.BYTES_PER_MB).toFixed(2),canvasCount:this.canvases.size}}async resizeCanvas(e,t,i){const n=this.performanceMonitor.startOperation("canvas-resize");try{const s=Math.max(I.MIN_WIDTH,Math.min(I.MAX_WIDTH,t)),a=Math.max(I.MIN_HEIGHT,Math.min(I.MAX_HEIGHT,i)),r=this.getCanvas(e),c=this.getVisualEngine(e),d=this.canvases.get(e);if(r&&d){const u=r.width,h=r.height;if(r.width=s,r.height=a,d.options.width=s,d.options.height=a,c&&c.resize)try{await c.resize(s,a)}catch(g){o.warn(`Engine resize failed for ${e}:`,g)}this.emit($.RESIZE_DETECTED,{canvasId:e,oldDimensions:{width:u,height:h},newDimensions:{width:s,height:a},timestamp:Date.now()}),o.debug(`Resized canvas ${e} to ${s}x${a}`),Math.abs(s-u)+Math.abs(a-h)>Y.SIGNIFICANT_SIZE_CHANGE&&this.announceToScreenReader(`Canvas resized to ${s} by ${a} pixels`)}}catch(s){this.handleError(new C("Failed to resize canvas",{canvasId:e,width:t,height:i},s))}finally{this.performanceMonitor.endOperation("canvas-resize",n)}}makeResponsive(e){try{const t=this.getCanvas(e),i=this.canvases.get(e);if(!t||!i)throw new C("Canvas not found for responsive setup",{canvasId:e});i.resizeObserver&&i.resizeObserver.disconnect();let n;const s=c=>{n&&clearTimeout(n),n=setTimeout(()=>{for(const d of c){const{width:u,height:h}=d.contentRect;(Math.abs(u-t.width)>Y.DIMENSION_TOLERANCE||Math.abs(h-t.height)>Y.DIMENSION_TOLERANCE)&&this.resizeCanvas(e,u,h)}},I.RESIZE_DEBOUNCE)},a=new ResizeObserver(s),r=t.parentElement||t;a.observe(r),i.resizeObserver=a,this.resizeObservers.set(e,a),o.debug(`Made canvas ${e} responsive`)}catch(t){this.handleError(new C("Failed to make canvas responsive",{canvasId:e},t))}}performMaintenanceCleanup(){try{const e=Date.now(),t=_.CLEANUP_MAX_AGE_MINUTES*_.SECONDS_PER_MINUTE*_.MS_PER_SECOND;let i=0;for(const[n,s]of this.canvases){const a=e-s.created;document.contains(s.element)?a>t&&!this.activeEngines.has(n)&&(o.debug(`Cleaning up old inactive canvas: ${n}`),this.removeCanvas(n),i++):(o.debug(`Cleaning up orphaned canvas: ${n}`),this.removeCanvas(n),i++)}i>0&&o.debug(`Maintenance cleanup: removed ${i} canvases`),Object.keys(this.performanceMonitor.getMetrics()).length>100&&this.performanceMonitor.reset()}catch(e){o.warn("Maintenance cleanup error:",e)}}handleError(e){this.errorCount++,o.error("Canvas Manager Error:",e),this.emit($.ERROR_OCCURRED,{error:e.message,context:e.context,timestamp:e.timestamp,canvasId:e.canvasId}),e.canvasId&&e.message.includes("engine")&&this.attemptEngineRecovery(e.canvasId)}async attemptEngineRecovery(e){try{o.debug(`Attempting engine recovery for canvas: ${e}`);const t=this.canvases.get(e);if(!t)return;await this.removeVisualEngine(e),setTimeout(async()=>{try{await this.createVisualEngine(e,{...t.options,debug:!0,errorRecovery:!0}),o.debug(`Engine recovery successful for canvas: ${e}`)}catch(i){o.error(`Engine recovery failed for canvas: ${e}`,i)}},1e3)}catch(t){o.error("Engine recovery attempt failed:",t)}}on(e,t){this.eventListeners.has(e)||this.eventListeners.set(e,[]),this.eventListeners.get(e).push(t)}off(e,t){const i=this.eventListeners.get(e);if(i){const n=i.indexOf(t);n>-1&&i.splice(n,1)}}emit(e,t){const i=this.eventListeners.get(e);i&&i.forEach(n=>{try{n(t)}catch(s){o.error("Canvas event listener error:",s)}})}}const O=new Ze;window.addEventListener("beforeunload",async()=>{try{await O.cleanup()}catch(l){o.error("Error during canvas manager cleanup:",l)}});document.addEventListener("visibilitychange",()=>{document.hidden?O.pauseAll():O.resumeAll()});window.addEventListener("focus",()=>{O.accessibilityEnabled&&O.resumeAll()});window.addEventListener("blur",()=>{O.accessibilityEnabled&&O.pauseAll()});const Me={FOCUS_DELAY:100,AUTO_FOCUS_TIMEOUT:150},et=["button:not([disabled])","[href]:not([disabled])","input:not([disabled])","select:not([disabled])","textarea:not([disabled])",'[tabindex]:not([tabindex="-1"]):not([disabled])','[contenteditable="true"]'].join(", ");class tt{constructor(){this.stack=[],this.maxSize=10}push(e){e&&typeof e.focus=="function"&&(this.stack.push(e),this.stack.length>this.maxSize&&this.stack.shift())}pop(){return this.stack.pop()}peek(){return this.stack[this.stack.length-1]}clear(){this.stack=[]}isEmpty(){return this.stack.length===0}}class it{constructor(){this.focusStack=new tt,this.activeTrappers=new Set,this.keyboardNavigationActive=!1,this.lastFocusMethod=null,this.init()}init(){document.addEventListener("mousedown",()=>{this.lastFocusMethod="mouse",document.documentElement.classList.remove("keyboard-navigation")}),document.addEventListener("keydown",e=>{e.key==="Tab"&&(this.lastFocusMethod="keyboard",this.keyboardNavigationActive=!0,document.documentElement.classList.add("keyboard-navigation"))}),document.addEventListener("keydown",e=>{e.key==="Escape"&&this.activeTrappers.size>0&&this.handleEscapeKey(e)})}getFocusableElements(e=document){return e.querySelectorAll(et)}getFirstFocusable(e){const t=this.getFocusableElements(e);return t.length>0?t[0]:null}getLastFocusable(e){const t=this.getFocusableElements(e);return t.length>0?t[t.length-1]:null}storeFocus(e=document.activeElement){this.focusStack.push(e)}restoreFocus(e=!0){const t=this.focusStack.pop();if(t&&document.contains(t)&&typeof t.focus=="function")try{return t.focus(),!0}catch{process?.env?.NODE_ENV}return e&&document.body.focus(),!1}async focusElement(e,t={}){const{delay:i=0,preventScroll:n=!1,method:s="programmatic"}=t;if(!e||typeof e.focus!="function")return!1;this.lastFocusMethod=s,i>0&&await new Promise(a=>setTimeout(a,i));try{return e.focus({preventScroll:n}),!0}catch{return!1}}async autoFocus(e,t={}){const{keyboardOnly:i=!0,delay:n=Me.AUTO_FOCUS_TIMEOUT}=t;if(i&&!this.keyboardNavigationActive)return!1;const s=this.getFirstFocusable(e);return s?this.focusElement(s,{delay:n,method:"auto"}):!1}createTrap(e,t={}){const{autoFocus:i=!0,restoreFocus:n=!0}=t;n&&this.storeFocus();const s=Symbol("focus-trap"),a=r=>{r.key==="Tab"&&this.handleTabInTrap(r,e)};return this.activeTrappers.add(s),document.addEventListener("keydown",a),i&&this.autoFocus(e,{keyboardOnly:!1}),{id:s,container:e,destroy:()=>{document.removeEventListener("keydown",a),this.activeTrappers.delete(s),n&&setTimeout(()=>{this.restoreFocus()},Me.FOCUS_DELAY)},focusFirst:()=>this.focusElement(this.getFirstFocusable(e)),focusLast:()=>this.focusElement(this.getLastFocusable(e))}}handleTabInTrap(e,t){const i=this.getFocusableElements(t);if(i.length===0)return;const n=i[0],s=i[i.length-1],a=document.activeElement;if(!t.contains(a)){e.preventDefault(),n.focus();return}e.shiftKey?a===n&&(e.preventDefault(),s.focus()):a===s&&(e.preventDefault(),n.focus())}handleEscapeKey(e){}createKeyboardNavigator(e,t={}){const{selector:i=e.children,wrap:n=!0,orientation:s="both"}=t;return a=>{const r=Array.from(typeof i=="string"?e.querySelectorAll(i):i),c=r.indexOf(document.activeElement);if(c===-1)return;let d=c;switch(a.key){case"ArrowLeft":(s==="horizontal"||s==="both")&&(a.preventDefault(),d=n&&c===0?r.length-1:Math.max(0,c-1));break;case"ArrowRight":(s==="horizontal"||s==="both")&&(a.preventDefault(),d=n&&c===r.length-1?0:Math.min(r.length-1,c+1));break;case"ArrowUp":(s==="vertical"||s==="both")&&(a.preventDefault(),d=n&&c===0?r.length-1:Math.max(0,c-1));break;case"ArrowDown":(s==="vertical"||s==="both")&&(a.preventDefault(),d=n&&c===r.length-1?0:Math.min(r.length-1,c+1));break;case"Home":a.preventDefault(),d=0;break;case"End":a.preventDefault(),d=r.length-1;break;default:return}d!==c&&r[d]&&(this.focusElement(r[d]),r[d].scrollIntoView({behavior:"smooth",block:"nearest",inline:"nearest"}))}}destroy(){this.focusStack.clear(),this.activeTrappers.clear(),this.keyboardNavigationActive=!1}}const Ee=new it;class nt{constructor(){this.isAutoScrolling=!1,this.scrollTimeout=null,this.observers=new Map,this.SCROLL_DURATION=800,this.SCROLL_OFFSET=80,this.MIN_SCROLL_DISTANCE=5,this.EASE_MIDPOINT=.5,this.EASE_MULTIPLIER=4,this.debouncedHandlers=new Map,this.DEBOUNCE_DELAY=16}init(){this.setupScrollRestoration(),this.setupGlobalScrollBehavior(),this.initializeHorizontalScrolling(),o.info("ScrollManager initialized")}setupScrollRestoration(){"scrollRestoration"in history&&(history.scrollRestoration="manual")}setupGlobalScrollBehavior(){this.resetScrollPosition(),document.readyState==="loading"&&document.addEventListener("DOMContentLoaded",()=>this.resetScrollPosition()),window.addEventListener("pageshow",()=>this.resetScrollPosition())}resetScrollPosition(){window.scrollTo(0,0),setTimeout(()=>{document.documentElement.classList.add("loaded")},100)}async scrollToElement(e,t={}){const i=typeof e=="string"?document.querySelector(e):e;if(!i){o.warn("ScrollManager: Element not found for scrolling",e);return}const{behavior:n="smooth",offset:s=this.SCROLL_OFFSET,respectReducedMotion:a=!0}=t,r=i.closest('.scenario-modal, .pre-launch-modal, .modal, [role="dialog"]');r?await this.scrollWithinModal(i,r,s,n):await this.scrollMainWindow(i,s,n,a)}async scrollWithinModal(e,t,i,n){const s=t.querySelector(".modal-content, .scenario-content, .modal-body")||t;if(n==="auto"||this.shouldUseInstantScroll()){e.scrollIntoView({behavior:"auto",block:"center",inline:"nearest"});return}const a=e.getBoundingClientRect(),r=s.getBoundingClientRect(),c=s.scrollTop,d=a.top-r.top+c,u=Math.max(0,d-i);await this.animateScroll(s,u,"scrollTop")}async scrollMainWindow(e,t,i,n){const s=window.matchMedia("(prefers-reduced-motion: reduce)").matches;if((n&&s?"auto":i)==="auto"||this.shouldUseInstantScroll()){e.scrollIntoView({behavior:"auto",block:"center",inline:"nearest"});return}const r=e.getBoundingClientRect(),c=Math.max(0,r.top+window.pageYOffset-t);await this.animateScroll(window,c,"pageYOffset")}async animateScroll(e,t,i){return new Promise(n=>{const s=i==="scrollTop"?e.scrollTop:window.pageYOffset,a=t-s;if(Math.abs(a)<this.MIN_SCROLL_DISTANCE){n();return}this.isAutoScrolling=!0;let r=null;const c=d=>{r===null&&(r=d);const u=d-r,h=Math.min(u/this.SCROLL_DURATION,1),p=h<this.EASE_MIDPOINT?2*h*h:-1+(this.EASE_MULTIPLIER-2*h)*h,g=s+a*p;i==="scrollTop"?e.scrollTop=g:window.scrollTo(0,g),h<1?requestAnimationFrame(c):(this.isAutoScrolling=!1,n())};requestAnimationFrame(c)})}initializeHorizontalScrolling(){o.info("ScrollManager: Using native horizontal scrolling")}debounce(e,t=this.DEBOUNCE_DELAY){let i;return(...n)=>{clearTimeout(i),i=setTimeout(()=>e.apply(this,n),t)}}shouldUseInstantScroll(){return window.matchMedia("(prefers-reduced-motion: reduce)").matches}reinitializeHorizontalScrolling(){}cleanup(){this.observers.forEach(e=>e.disconnect()),this.observers.clear(),this.debouncedHandlers.clear(),this.scrollTimeout&&clearTimeout(this.scrollTimeout)}}const fe=new nt;class st{constructor(){this.callCounts=new Map,this.callTimestamps=new Map,this.isEnabled=!0,this.CALLS_PER_SECOND_THRESHOLD=50,this.MAX_STACK_DEPTH=100,this.MAX_SAME_FUNCTION_IN_STACK=10,this.TIME_WINDOW=1e3,this.EMERGENCY_CALLS_THRESHOLD=100,this.EMERGENCY_STACK_THRESHOLD=200,this.EMERGENCY_RECURSION_THRESHOLD=20,this.MAX_INCIDENTS=50,this.TIMER_CLEAR_RANGE=99999,this.thresholds={callsPerSecond:this.CALLS_PER_SECOND_THRESHOLD,maxStackDepth:this.MAX_STACK_DEPTH,maxSameFunction:this.MAX_SAME_FUNCTION_IN_STACK,timeWindow:this.TIME_WINDOW},this.emergencyStopExecuted=!1}trackExecution(e,t=""){if(!this.isEnabled)return;const i=`${e}${t?`:${t}`:""}`,n=Date.now();this.callTimestamps.has(i)||(this.callTimestamps.set(i,[]),this.callCounts.set(i,0));const a=this.callTimestamps.get(i).filter(r=>n-r<this.thresholds.timeWindow);a.push(n),this.callTimestamps.set(i,a),this.callCounts.set(i,this.callCounts.get(i)+1),a.length>this.thresholds.callsPerSecond&&this.handleSuspiciousActivity(i,a.length,"EXCESSIVE_CALLS"),this.checkCallStackDepth(i)}checkCallStackDepth(e){const{stack:t}=new Error,i=t.split(`
`);if(i.length>this.thresholds.maxStackDepth)return this.handleSuspiciousActivity(e,i.length,"DEEP_STACK"),!0;const n=this.analyzeCallStack(i);return n.maxRepeats>this.thresholds.maxSameFunction?(this.handleSuspiciousActivity(e,n.maxRepeats,"RECURSIVE_PATTERN",n.repeatedFunction),!0):!1}analyzeCallStack(e){const t=e.slice(2).map(a=>{const r=a.match(/at\s+(\w+)/);return r?r[1]:null}).filter(Boolean),i={};let n=0,s=null;for(const a of t)i[a]=(i[a]||0)+1,i[a]>n&&(n=i[a],s=a);return{maxRepeats:n,repeatedFunction:s,totalDepth:t.length}}handleSuspiciousActivity(e,t,i,n=""){const s=this.formatWarningMessage(e,t,i,n);o.warn("InfiniteLoopDetector",`🚨 POTENTIAL LOOP: ${s}`),this.recordIncident(e,t,i,n),this.shouldExecuteEmergencyStop(t,i)&&this.executeEmergencyStop(`Auto-triggered by ${i}`)}formatWarningMessage(e,t,i,n){switch(i){case"EXCESSIVE_CALLS":return`${e} called ${t} times in ${this.thresholds.timeWindow}ms`;case"DEEP_STACK":return`Deep call stack detected: ${t} levels in ${e}`;case"RECURSIVE_PATTERN":return`Recursive pattern: ${n} appears ${t} times in stack (from ${e})`;default:return`Suspicious activity in ${e}: ${t} (${i})`}}shouldExecuteEmergencyStop(e,t){return this.emergencyStopExecuted?!1:t==="EXCESSIVE_CALLS"&&e>this.EMERGENCY_CALLS_THRESHOLD||t==="DEEP_STACK"&&e>this.EMERGENCY_STACK_THRESHOLD||t==="RECURSIVE_PATTERN"&&e>this.EMERGENCY_RECURSION_THRESHOLD}recordIncident(e,t,i,n){window.loopIncidents||(window.loopIncidents=[]),window.loopIncidents.push({timestamp:new Date().toISOString(),functionName:e,count:t,type:i,details:n,userAgent:navigator.userAgent,url:window.location.href}),window.loopIncidents.length>this.MAX_INCIDENTS&&(window.loopIncidents=window.loopIncidents.slice(-this.MAX_INCIDENTS))}executeEmergencyStop(e="Manual trigger"){if(this.emergencyStopExecuted){o.info("InfiniteLoopDetector","🛑 Emergency stop already executed");return}this.emergencyStopExecuted=!0,o.warn("InfiniteLoopDetector",`🛑 EXECUTING EMERGENCY STOP: ${e}`),this.clearAllTimers(),this.disconnectObservers(),this.stopAnimations(),this.isEnabled=!1,o.info("InfiniteLoopDetector","🛑 Emergency stop completed")}clearAllTimers(){try{for(let e=1;e<this.TIMER_CLEAR_RANGE;e++)window.clearTimeout(e),window.clearInterval(e);o.info("InfiniteLoopDetector","✅ All timers cleared")}catch(e){o.error("InfiniteLoopDetector","❌ Error clearing timers",e)}}disconnectObservers(){try{window.app?.onboardingTour?.contentObserver&&(window.app.onboardingTour.contentObserver.disconnect(),o.info("InfiniteLoopDetector","✅ Onboarding content observer disconnected")),window.activeMutationObservers&&(window.activeMutationObservers.forEach(e=>e.disconnect()),o.info("InfiniteLoopDetector","✅ Active mutation observers disconnected"))}catch(e){o.error("InfiniteLoopDetector","❌ Error disconnecting observers",e)}}stopAnimations(){try{window.activeAnimationFrames&&(window.activeAnimationFrames.forEach(t=>cancelAnimationFrame(t)),o.info("InfiniteLoopDetector","✅ Animation frames cancelled")),document.querySelectorAll("*").forEach(t=>{t.style.animationPlayState="paused",t.style.transitionDuration="0s"}),o.info("InfiniteLoopDetector","✅ CSS animations paused")}catch(e){o.error("InfiniteLoopDetector","❌ Error stopping animations",e)}}getStats(){const e={totalFunctions:this.callCounts.size,isEnabled:this.isEnabled,emergencyStopExecuted:this.emergencyStopExecuted,topCallers:[],incidents:window.loopIncidents||[]},t=Array.from(this.callCounts.entries()).sort((i,n)=>n[1]-i[1]).slice(0,10);return e.topCallers=t.map(([i,n])=>{const a=(this.callTimestamps.get(i)||[]).filter(r=>Date.now()-r<this.thresholds.timeWindow).length;return{name:i,totalCalls:n,recentCalls:a}}),e}reset(){this.callCounts.clear(),this.callTimestamps.clear(),this.emergencyStopExecuted=!1,this.isEnabled=!0,o.info("InfiniteLoopDetector","🔄 Loop detector reset")}setEnabled(e){this.isEnabled=e,o.info("InfiniteLoopDetector",`🔧 Loop detector ${e?"enabled":"disabled"}`)}}const N=new st;typeof window<"u"&&(window.loopDetector=N,window.debugUtils={trackFunction:(l,e)=>{if(!l[e]){o.error("DebugUtils",`Method ${e} not found on object`);return}const t=l[e];l[e]=function(...i){return N.trackExecution(`${l.constructor.name}.${e}`),t.apply(this,i)},o.info("DebugUtils",`Now tracking ${l.constructor.name}.${e}`)},stopTracking:(l,e,t)=>{t&&(l[e]=t,o.info("DebugUtils",`Stopped tracking ${l.constructor.name}.${e}`))},getStats:()=>N.getStats(),emergencyStop:l=>N.executeEmergencyStop(l),reset:()=>N.reset(),setEnabled:l=>N.setEnabled(l)},o.info("DebugUtils","Debug utilities loaded. Use window.debugUtils for manual controls."));const Se={"bias-fairness":{id:"bias-fairness",title:"Algorithmic Bias in Hiring",subtitle:"Explore how bias enters AI hiring systems and its impact on fairness",learningObjectives:["Understand how bias can enter AI systems through data and design choices","Explore consequences of biased algorithms on different demographic groups",'Discover multiple perspectives on what constitutes "fair" AI systems',"Practice ethical decision-making in AI development scenarios"],isteCriteria:["Empowered Learner 1.1.5: Use technology to seek feedback and make improvements","Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.3: Collect data and identify patterns"],duration:"15-20 minutes",difficulty:"intermediate",recommendedAge:"13+",prerequisites:["Basic understanding of algorithms and AI","Awareness of workplace hiring processes","Understanding of demographics and diversity concepts"],beforeYouStart:{briefing:`In this simulation, you'll step into the role of an AI system designer creating a hiring algorithm for a technology company. You'll make decisions about data sources, algorithm design, and fairness metrics while observing how these choices affect different groups of job candidates.
      
      There are no "correct" answers - instead, you'll discover the complex trade-offs involved in building fair AI systems and see how different stakeholders might view the same outcomes differently.`,vocabulary:[{term:"Algorithm",definition:"A set of rules or instructions for solving a problem or completing a task"},{term:"Bias",definition:"Systematic unfairness that favors or discriminates against certain groups"},{term:"Fairness Metrics",definition:"Mathematical measures used to evaluate whether an AI system treats different groups equitably"},{term:"Training Data",definition:"Historical information used to teach an AI system how to make decisions"},{term:"Demographics",definition:"Statistical characteristics of populations, such as age, gender, race, or education level"}],preparationTips:['Consider what makes a hiring process "fair" from different perspectives',"Think about how historical data might reflect past biases","Be prepared to make difficult trade-offs between competing values","Pay attention to how your decisions affect different groups of people"],scenarioOverview:"You will design a hiring algorithm by choosing data sources, setting algorithm parameters, and defining fairness criteria. As you make decisions, you'll see their impact on hiring outcomes for different demographic groups and receive feedback from various stakeholders."},educatorResources:{discussionQuestions:["What factors should be considered when designing AI systems for hiring?","How can historical data perpetuate existing biases in new AI systems?","What are the trade-offs between different definitions of fairness?","How might different stakeholders (employers, job seekers, society) view the same AI decision differently?","What responsibilities do AI developers have to ensure fair outcomes?"],assessmentRubric:{"Ethical Reasoning":["Novice: Makes decisions without considering ethical implications","Developing: Shows awareness of ethical issues but analysis is superficial","Proficient: Demonstrates thoughtful consideration of multiple ethical perspectives","Advanced: Articulates complex ethical trade-offs and justifies decisions with clear reasoning"],"Systems Thinking":["Novice: Focuses on isolated decisions without seeing connections","Developing: Recognizes some connections between decisions and outcomes","Proficient: Understands how multiple factors interact to produce outcomes","Advanced: Demonstrates sophisticated understanding of complex system dynamics"],"Perspective Taking":["Novice: Considers only one viewpoint","Developing: Acknowledges different perspectives exist","Proficient: Actively considers multiple stakeholder perspectives","Advanced: Synthesizes diverse perspectives into nuanced understanding"]},extensionActivities:["Research real-world examples of algorithmic bias in hiring (Amazon, etc.)","Interview family members about their experiences with hiring processes",'Design a "bias audit" checklist for AI hiring systems',"Create a presentation comparing different fairness definitions","Write a letter to a company about responsible AI hiring practices"],relatedStandards:["CSTA K-12 Computer Science Standards: 3A-IC-24, 3A-IC-25, 3A-IC-26","Common Core Mathematical Practices: MP.3, MP.4, MP.6","C3 Framework for Social Studies: D2.Civ.1.9-12, D2.Eco.1.9-12"],classroomTips:["Encourage students to discuss their decisions with peers before making final choices","Have students document their reasoning for key decisions to review later","Consider running the simulation in small groups to promote discussion","Use the reflection questions to facilitate post-simulation discussions"]},relatedResources:[{type:"article",title:"Machine Bias in Criminal Justice",description:"ProPublica investigation into biased risk assessment algorithms",url:"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing",audience:"educators"},{type:"video",title:"The Problem with AI Bias",description:"MIT Technology Review explanation of AI bias (8 minutes)",url:"https://www.youtube.com/watch?v=gV0_raKR2UQ",audience:"students"},{type:"research",title:"Fairness Definitions Explained",description:"Academic paper on different mathematical definitions of fairness",url:"https://fairmlbook.org/causalinference.html",audience:"educators"},{type:"interactive",title:"AI Fairness 360 Toolkit",description:"IBM's open-source toolkit for detecting and mitigating bias",url:"https://aif360.mybluemix.net/",audience:"advanced"}],tags:["bias","fairness","hiring","ethics","algorithms","equity","workplace"],contentNotes:["Discusses workplace discrimination and hiring bias","Contains scenarios involving demographic differences","Requires critical thinking about social justice issues"],connectedSimulations:["algorithmic-transparency","ai-safety-basics","data-privacy-ethics"]},"autonomy-oversight":{id:"autonomy-oversight",title:"AI Autonomy & Human Oversight",subtitle:"Balance AI autonomy with human oversight in critical decision-making",learningObjectives:["Understand the balance between AI autonomy and human oversight","Explore when human intervention is necessary in AI systems","Discover different levels of AI independence and control","Practice decision-making about AI oversight in various scenarios"],isteCriteria:["Empowered Learner 1.1.4: Understand fundamental concepts of technology operations","Digital Citizen 1.2.3: Cultivate and manage digital identity and reputation","Critical Thinker 1.4.3: Curate information from digital resources","Computational Thinker 1.5.1: Formulate problem definitions suited for technology"],duration:"12-15 minutes",difficulty:"intermediate",recommendedAge:"14+",prerequisites:["Basic understanding of AI and automation","Awareness of human decision-making processes","Understanding of responsibility and accountability"],beforeYouStart:{briefing:`In this simulation, you'll explore the critical balance between AI autonomy and human oversight. You'll face scenarios where you must decide how much independence to give AI systems and when human intervention is necessary.
      
      You'll discover the complexities of maintaining control while leveraging AI capabilities, and see how different levels of oversight affect outcomes, efficiency, and responsibility.`,vocabulary:[{term:"Autonomy",definition:"The ability of a system to operate independently without human intervention"},{term:"Oversight",definition:"Human supervision and monitoring of AI system operations"},{term:"Human-in-the-loop",definition:"AI systems that require human input for certain decisions"},{term:"Accountability",definition:"Responsibility for the consequences of AI system actions"},{term:"Fail-safe",definition:"Mechanisms that prevent harmful outcomes when systems malfunction"}],preparationTips:["Consider different types of decisions and their consequences","Think about when you would want a human to be involved","Reflect on responsibility and who should be accountable","Keep an open mind about different oversight approaches"]},afterCompletion:{keyTakeaways:["AI autonomy exists on a spectrum from fully manual to fully automated","Different scenarios require different levels of human oversight","Balancing efficiency with safety and accountability is crucial","Human judgment remains important even in advanced AI systems"],reflectionQuestions:["When should humans maintain control over AI decisions?","How do you balance AI efficiency with human oversight?","What are the risks of too much or too little AI autonomy?","How do cultural and social factors influence oversight preferences?"]},educatorResources:{discussionGuide:["Debate the pros and cons of AI autonomy in different contexts","Role-play scenarios with different oversight approaches","Compare human vs. AI decision-making capabilities","Discuss real-world examples of AI oversight challenges"],classroomActivities:["Design oversight protocols for different AI applications","Create decision trees for when human intervention is needed","Research case studies of AI oversight successes and failures","Debate the future of human-AI collaboration"],assessmentIdeas:["Analyze oversight scenarios and justify recommendations","Create presentations on AI autonomy best practices","Write reflection essays on human-AI responsibility","Design ethical guidelines for AI oversight"]}},"consent-transparency":{id:"consent-transparency",title:"AI Consent & Transparency",subtitle:"Explore informed consent and transparency in AI systems",learningObjectives:["Understand the importance of informed consent in AI systems","Explore transparency requirements for AI decision-making","Discover challenges in communicating AI capabilities and limitations","Practice designing user-friendly consent and disclosure processes"],isteCriteria:["Empowered Learner 1.1.3: Use technology to seek feedback","Digital Citizen 1.2.1: Cultivate and manage digital identity","Knowledge Constructor 1.3.4: Build knowledge through exploration","Creative Communicator 1.6.2: Create original works as a means of expression"],duration:"8-12 minutes",difficulty:"beginner",recommendedAge:"12+",prerequisites:["Basic understanding of privacy and consent","Awareness of AI use in everyday applications","Understanding of communication and transparency"],beforeYouStart:{briefing:`In this simulation, you'll explore how to make AI systems transparent and obtain meaningful consent from users. You'll face challenges in explaining complex AI systems in understandable ways and ensuring users can make informed decisions.
      
      You'll discover the balance between technical accuracy and user comprehension, and see how different approaches to transparency affect user trust and decision-making.`,vocabulary:[{term:"Informed Consent",definition:"Agreement based on understanding of what is being consented to"},{term:"Transparency",definition:"Openness about how AI systems work and make decisions"},{term:"Explainable AI",definition:"AI systems that can provide understandable explanations of their decisions"},{term:"Privacy Policy",definition:"Document explaining how personal data is collected and used"},{term:"User Agency",definition:"The ability of users to control their interaction with AI systems"}],preparationTips:["Think about your own experiences with consent forms and privacy policies","Consider what information users really need to make good decisions","Reflect on the balance between detail and simplicity","Keep user perspectives and capabilities in mind"]},afterCompletion:{keyTakeaways:["Effective consent requires both transparency and user understanding","Different users need different levels of detail and explanation","Transparency must be balanced with usability and simplicity","Building trust requires ongoing communication, not just initial consent"],reflectionQuestions:["How can complex AI systems be explained in simple terms?","What information do users really need to give meaningful consent?","How do we balance transparency with user experience?","What are the limits of user understanding in AI systems?"]},educatorResources:{discussionGuide:["Compare consent practices across different platforms and services","Analyze examples of good and bad AI transparency","Discuss the ethics of informed consent in AI","Explore cultural differences in transparency expectations"],classroomActivities:["Design user-friendly consent interfaces for AI systems","Create plain-language explanations of complex AI concepts","Audit existing privacy policies and consent forms","Role-play consent conversations between AI developers and users"],assessmentIdeas:["Evaluate consent and transparency practices of real AI systems","Design consent processes for hypothetical AI applications","Write user-friendly explanations of AI technologies","Create presentations on transparency best practices"]}},"misinformation-trust":{id:"misinformation-trust",title:"AI, Misinformation & Trust",subtitle:"Combat misinformation and build trustworthy AI communication",learningObjectives:["Understand how AI can both combat and create misinformation","Explore trust-building in AI communication systems","Discover challenges in verifying AI-generated content","Practice designing systems that promote information integrity"],isteCriteria:["Empowered Learner 1.1.1: Articulate goals and define learning pathways","Digital Citizen 1.2.4: Manage personal data to maintain privacy and security","Knowledge Constructor 1.3.2: Evaluate accuracy and perspective of sources","Critical Thinker 1.4.4: Use technology to deepen critical thinking"],duration:"15-20 minutes",difficulty:"advanced",recommendedAge:"15+",prerequisites:["Understanding of information literacy and media bias","Awareness of AI capabilities in content generation","Knowledge of verification and fact-checking processes"],beforeYouStart:{briefing:`In this simulation, you'll tackle the complex challenge of building trustworthy AI systems that can help combat misinformation while avoiding the creation of false information themselves.
      
      You'll explore the balance between AI automation and human verification, discover the challenges of detecting AI-generated content, and see how different approaches affect public trust and information integrity.`,vocabulary:[{term:"Misinformation",definition:"False or inaccurate information, regardless of intent"},{term:"Disinformation",definition:"Deliberately false information intended to deceive"},{term:"Deepfakes",definition:"AI-generated fake audio, video, or images that appear real"},{term:"Fact-checking",definition:"Process of verifying the accuracy of information"},{term:"Information Integrity",definition:"Ensuring information is accurate, authentic, and trustworthy"}],preparationTips:["Consider your own information consumption and verification habits","Think about how you determine what sources to trust","Reflect on the role of technology in information spread","Keep in mind different perspectives on truth and trust"]},afterCompletion:{keyTakeaways:["AI can be both a tool for fighting misinformation and a source of it","Building trust requires transparency, consistency, and accountability","Human judgment remains crucial in information verification","Different communities may have different trust relationships with AI"],reflectionQuestions:["How can AI systems earn and maintain public trust?","What are the trade-offs between automation and human oversight in fact-checking?","How do we balance free expression with misinformation prevention?","What responsibility do AI developers have for information integrity?"]},educatorResources:{discussionGuide:["Analyze real examples of AI-generated misinformation","Debate the role of platforms in content moderation","Discuss the impact of misinformation on democratic processes","Explore cultural and political factors in trust and verification"],classroomActivities:["Design fact-checking protocols that incorporate AI","Create media literacy curricula for the AI age","Research case studies of misinformation campaigns","Develop trust metrics for AI information systems"],assessmentIdeas:["Evaluate the effectiveness of different misinformation detection approaches","Create proposals for trustworthy AI communication systems","Analyze the ethics of AI content moderation","Design public education campaigns about AI and information integrity"]}},"medical-ai-triage":{id:"medical-ai-triage",title:"Medical AI Triage Crisis",subtitle:"Navigate life-and-death resource allocation decisions in emergency medicine",learningObjectives:["Analyze how utilitarian vs. deontological ethics apply to medical AI triage decisions","Explore the tension between statistical optimization and individual patient equity","Understand the complexity of programming moral reasoning into medical AI systems","Examine accountability and responsibility in AI-assisted medical decisions","Consider how age, probability, and resource scarcity affect ethical medical choices"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions","Critical Thinker 1.4.3: Curate information from digital resources using a variety of tools"],duration:"18-22 minutes",difficulty:"intermediate",recommendedAge:"14+",prerequisites:["Basic understanding of medical triage concepts","Familiarity with ethical reasoning frameworks","Understanding of AI decision-making processes","Awareness of resource allocation challenges in healthcare"],beforeYouStart:{briefing:`In this scenario, you'll face one of the most challenging applications of AI ethics: programming medical triage systems for mass casualty events. You'll grapple with how an AI should allocate limited life-saving resources when every decision determines who lives and who dies.

      This scenario builds on classic trolley problem ethics by adding the complexity of medical uncertainty, age considerations, and resource constraints. You'll explore how different ethical frameworks lead to vastly different outcomes for patients and families.`,vocabulary:[{term:"Medical Triage",definition:"The process of determining treatment priority based on severity of condition and likelihood of survival"},{term:"Utilitarian Ethics",definition:"Ethical framework focused on maximizing overall good or minimizing total harm"},{term:"Deontological Ethics",definition:"Ethical framework based on duty and rules, regardless of consequences"},{term:"Quality-Adjusted Life Years (QALY)",definition:"Metric combining life expectancy with quality of life to guide medical decisions"},{term:"Algorithmic Bias",definition:"Systematic discrimination that may emerge in AI medical decision-making"}],preparationTips:["Consider how medical professionals currently make triage decisions","Think about the difference between individual patient care and population-level outcomes","Reflect on what factors should and shouldn't influence life-saving decisions","Consider how families and communities might react to different AI decision approaches"],scenarioOverview:"You will design decision-making protocols for an AI medical triage system during a mass casualty event, weighing survival probability, age, resources, and ethical principles."},educatorResources:{discussionQuestions:["How do medical triage principles apply to AI decision-making in emergencies?","What are the ethical implications of using age as a factor in AI medical decisions?","How can AI systems balance individual patient care with population-level outcomes?","What safeguards should exist to prevent bias in AI medical triage systems?","Who should be held accountable when AI medical systems make life-and-death decisions?"],assessmentRubric:{"Ethical Reasoning":["Novice: Focuses only on obvious outcomes without considering ethical frameworks","Developing: Shows awareness of ethical issues but applies frameworks inconsistently","Proficient: Demonstrates understanding of multiple ethical approaches and their medical applications","Advanced: Articulates complex trade-offs between competing ethical principles in medical contexts"],"Medical Understanding":["Novice: Limited understanding of medical triage and emergency care","Developing: Basic understanding of medical decision-making processes","Proficient: Good grasp of medical triage principles and resource allocation challenges","Advanced: Sophisticated understanding of medical ethics and emergency care systems"]},extendedActivities:["Research real hospital triage protocols and how they handle resource scarcity","Interview medical professionals about ethical decisions in emergency care","Design alternative AI triage algorithms with different ethical frameworks","Analyze case studies of medical resource allocation during pandemics or disasters"]}},"drone-rescue-dilemma":{id:"drone-rescue-dilemma",title:"Rescue Drone Dilemma",subtitle:"Program autonomous rescue systems to make life-or-death decisions under uncertainty",learningObjectives:["Analyze decision-making under uncertainty in life-critical AI systems","Explore the ethics of risk assessment and calculated gambles with human lives","Understand how probability and certainty affect moral reasoning in AI","Examine the balance between conservative safety and optimal outcomes","Consider accountability when AI systems make high-stakes probabilistic decisions"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions","Computational Thinker 1.5.3: Break problems into component parts, extract key information","Critical Thinker 1.4.4: Use technology to deepen understanding and broaden perspectives"],duration:"16-20 minutes",difficulty:"advanced",recommendedAge:"15+",prerequisites:["Understanding of probability and risk assessment","Familiarity with emergency response and rescue operations","Basic knowledge of ethical decision-making frameworks","Understanding of AI system capabilities and limitations"],beforeYouStart:{briefing:`In this scenario, you'll program an autonomous rescue system to make critical decisions when lives hang in the balance and outcomes are uncertain. You'll face the challenge of balancing guaranteed salvation against the possibility of saving more lives through calculated risks.

      This scenario explores how AI systems should handle uncertainty and probability when human lives are at stake. You'll discover the ethical complexity of programming machines to take risks that could result in either heroic rescues or tragic failures.`,vocabulary:[{term:"Risk Assessment",definition:"The process of evaluating the likelihood and impact of potential negative outcomes"},{term:"Probabilistic Decision-Making",definition:"Making choices based on likelihood of outcomes rather than certainty"},{term:"Risk Tolerance",definition:"The level of uncertainty and potential loss that is acceptable in decision-making"},{term:"Expected Value",definition:"Mathematical calculation of likely outcomes weighted by their probabilities"},{term:"Moral Hazard",definition:"The risk of making poor decisions because negative consequences affect others"}],preparationTips:["Consider how emergency responders currently make decisions under uncertainty","Think about the difference between individual risk and systemic risk","Reflect on when it's appropriate to take calculated risks with lives","Consider how you would explain risky decisions to affected families"],scenarioOverview:"You will design decision-making protocols for autonomous rescue systems, programming how they should balance certain rescue against risky attempts to save more lives."},educatorResources:{discussionQuestions:["When is it ethical for AI systems to take calculated risks with human lives?","How should uncertainty and probability factor into life-and-death AI decisions?","What level of risk is acceptable when the goal is saving more lives?","How do we balance individual safety against potential collective benefit?","Who bears responsibility when AI systems make high-risk decisions that fail?"],assessmentRubric:{"Risk Analysis":["Novice: Difficulty understanding probability and uncertainty concepts","Developing: Basic grasp of risk but struggles with complex trade-offs","Proficient: Good understanding of risk assessment and probabilistic thinking","Advanced: Sophisticated analysis of uncertainty and risk in ethical contexts"],"Ethical Reasoning":["Novice: Focuses on simple outcomes without considering broader implications","Developing: Shows awareness of ethical complexity but analysis is limited","Proficient: Demonstrates nuanced understanding of ethics under uncertainty","Advanced: Articulates complex ethical frameworks for high-stakes decisions"]},extendedActivities:["Research real search-and-rescue operations and decision-making protocols","Interview emergency responders about risk assessment in life-saving situations","Design risk assessment frameworks for different types of rescue scenarios","Analyze case studies of rescue operations that involved difficult risk decisions"]}},"smart-city-traffic":{id:"smart-city-traffic",title:"Smart City Traffic Sacrifice",subtitle:"Design city-wide AI systems that must choose between different groups of potential victims",learningObjectives:["Analyze the ethics of AI systems that actively redirect harm between different groups","Explore the difference between allowing harm and causing harm in AI decision-making","Understand the legal and moral implications of AI systems choosing victims","Examine the role of consent and agency in AI-managed public spaces","Consider how city-wide AI systems should balance individual and collective welfare"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.1: Formulate problem definitions suited for technology-assisted methods","Critical Thinker 1.4.3: Curate information from digital resources using a variety of tools"],duration:"17-21 minutes",difficulty:"intermediate",recommendedAge:"14+",prerequisites:["Understanding of smart city technology and infrastructure","Familiarity with traffic management and public safety systems","Basic knowledge of legal liability and responsibility concepts","Understanding of collective action and public goods"],beforeYouStart:{briefing:`In this scenario, you'll design the ethical decision-making protocols for a city-wide AI traffic management system. When emergencies occur, you'll face the challenge of programming how AI should respond when it has the power to redirect harm between different groups of citizens.

      This scenario examines the unique ethical challenges of AI systems that manage public spaces and infrastructure. You'll explore the difference between allowing events to unfold naturally versus actively intervening to redirect harm, and consider the implications of giving AI systems the power to choose victims.`,vocabulary:[{term:"Active vs. Passive Harm",definition:"The ethical distinction between causing harm through action versus allowing harm through inaction"},{term:"Public Safety Infrastructure",definition:"City systems designed to protect citizens from harm and manage emergency situations"},{term:"Collective Responsibility",definition:"Shared obligation of community members for outcomes affecting the group"},{term:"Legal Liability",definition:"Responsibility for damages or harm that may result in legal consequences"},{term:"Democratic Legitimacy",definition:"The authority to make decisions on behalf of citizens based on their consent"}],preparationTips:["Consider the difference between personal choices and public policy decisions","Think about how cities currently manage public safety and emergency response","Reflect on the level of control AI should have over public infrastructure","Consider how different communities might view AI intervention in emergencies"],scenarioOverview:"You will design emergency response protocols for smart city AI systems, determining when and how they should intervene in crisis situations affecting multiple groups of citizens."},educatorResources:{discussionQuestions:["What authority should AI systems have over public infrastructure and citizen safety?","How do we balance individual rights with collective welfare in AI city management?","What are the legal and ethical implications of AI systems actively choosing victims?","How should democratic values influence the design of AI public safety systems?","What safeguards are needed when AI systems have power over public spaces?"],assessmentRubric:{"Civic Understanding":["Novice: Limited understanding of public policy and civic responsibility","Developing: Basic grasp of collective decision-making and public goods","Proficient: Good understanding of civic institutions and democratic values","Advanced: Sophisticated analysis of public policy and collective action"],"Systems Thinking":["Novice: Focuses on isolated incidents without seeing broader patterns","Developing: Recognizes some connections between individual and collective outcomes","Proficient: Understands complex interactions between technology, society, and governance","Advanced: Demonstrates sophisticated understanding of socio-technical systems"]},extendedActivities:["Research smart city initiatives and their approaches to public safety","Interview city officials about emergency management and technology use","Design citizen engagement processes for AI public safety system oversight","Analyze case studies of technology-mediated public safety decisions"]}},"college-admission-mystery":{id:"college-admission-mystery",title:"Opaque College Admissions AI",subtitle:"Navigate the ethics of unexplainable AI decisions in higher education access",learningObjectives:["Understand the importance of transparency in AI systems that affect educational opportunities","Explore the tension between AI efficiency and explainable decision-making in admissions","Analyze how opaque algorithms can perpetuate educational inequality","Examine the rights of students to understand decisions that shape their futures","Consider the balance between institutional autonomy and public accountability"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.2: Evaluate the accuracy, perspective, credibility and relevance of information","Critical Thinker 1.4.1: Identify and define authentic problems for investigation","Critical Thinker 1.4.3: Curate information from digital resources using a variety of tools"],duration:"14-18 minutes",difficulty:"beginner",recommendedAge:"13+",prerequisites:["Basic understanding of college admissions processes","Awareness of AI decision-making in institutions","Understanding of fairness and transparency concepts","Knowledge of educational equity issues"],beforeYouStart:{briefing:`In this scenario, you'll confront the challenge of AI systems making life-changing educational decisions without explanation. You'll explore how opaque algorithms in college admissions can affect students' futures and access to opportunities, while considering the balance between AI efficiency and transparency.

      This scenario examines the unique challenges of AI transparency in educational contexts, where decisions fundamentally shape young people's life trajectories and access to social mobility.`,vocabulary:[{term:"Algorithmic Transparency",definition:"The ability to understand and explain how AI systems make decisions"},{term:"Educational Equity",definition:"Fair access to educational opportunities regardless of background or circumstances"},{term:"Black Box AI",definition:"AI systems whose internal decision-making processes are not visible or understandable"},{term:"Admissions Bias",definition:"Systematic unfairness in college admissions that favors or disadvantages certain groups"},{term:"Explainable AI (XAI)",definition:"AI systems designed to provide understandable explanations for their decisions"}],preparationTips:["Consider your own experiences with standardized testing and college applications","Think about what information you would want if your application was rejected","Reflect on the role of fairness and transparency in educational access","Consider how AI decisions might affect different groups of students differently"],scenarioOverview:"You will design policies for AI use in college admissions, deciding when and how much transparency is required for decisions that affect students' educational futures."},educatorResources:{discussionQuestions:["What level of transparency should be required for AI systems in educational settings?","How can institutions balance the benefits of AI with the need for explainable decisions?","What are the long-term societal implications of opaque educational AI systems?","How might AI admissions systems affect different communities and backgrounds?","What rights should students have to understand decisions that affect their educational opportunities?"],assessmentRubric:{"Transparency Understanding":["Novice: Limited understanding of AI transparency and its importance","Developing: Basic grasp of transparency issues but struggles with complex trade-offs","Proficient: Good understanding of transparency needs in educational contexts","Advanced: Sophisticated analysis of transparency requirements and implementation challenges"],"Educational Equity Analysis":["Novice: Minimal awareness of how AI might affect educational access","Developing: Basic understanding of equity issues but limited analysis","Proficient: Clear understanding of how AI can impact educational fairness","Advanced: Nuanced analysis of systemic effects of AI on educational opportunity"]},extendedActivities:["Research real college admissions AI systems and their transparency policies","Interview college admissions officers about their decision-making processes","Design transparency requirements for educational AI systems","Analyze case studies of AI bias in educational settings"]}},"insurance-claim-blackbox":{id:"insurance-claim-blackbox",title:"Insurance Claim Black Box",subtitle:"Examine AI transparency in healthcare access and insurance coverage decisions",learningObjectives:["Understand the critical importance of explainability in healthcare AI systems","Explore how opaque AI decisions can create barriers to medical care","Analyze the balance between fraud prevention and patient access to healthcare","Examine the role of AI transparency in medical advocacy and appeals processes","Consider the ethical obligations of healthcare AI systems to patients and providers"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Critical Thinker 1.4.4: Use technology to deepen understanding and broaden perspectives","Computational Thinker 1.5.3: Break problems into component parts, extract key information"],duration:"16-20 minutes",difficulty:"intermediate",recommendedAge:"14+",prerequisites:["Basic understanding of health insurance and medical billing","Awareness of healthcare access challenges","Understanding of AI decision-making processes","Knowledge of fraud prevention in healthcare"],beforeYouStart:{briefing:`In this scenario, you'll tackle the complex challenge of AI transparency in healthcare coverage decisions. You'll explore how opaque insurance AI systems can create barriers between patients and necessary medical care, while considering the legitimate needs for fraud prevention and cost control.

      This scenario examines the unique ethical challenges when AI black boxes affect health outcomes and access to medical treatment, where transparency can literally be a matter of life and death.`,vocabulary:[{term:"Healthcare AI",definition:"Artificial intelligence systems used in medical diagnosis, treatment, and administration"},{term:"Medical Billing Codes",definition:"Standardized codes used to describe medical procedures and diagnoses for billing"},{term:"Healthcare Fraud",definition:"Intentional deception in medical billing to obtain unauthorized benefits"},{term:"Prior Authorization",definition:"Insurance requirement for approval before certain medical treatments are covered"},{term:"Medical Necessity",definition:"Healthcare services that are reasonable and necessary for diagnosis or treatment"}],preparationTips:["Consider experiences with health insurance claims and coverage decisions","Think about the relationship between patients, doctors, and insurance companies","Reflect on the balance between preventing fraud and ensuring access to care","Consider how explanations might help patients advocate for their healthcare needs"],scenarioOverview:"You will design policies for AI use in health insurance claim processing, balancing transparency needs with fraud prevention and cost control objectives."},educatorResources:{discussionQuestions:["How should AI transparency requirements differ for healthcare versus other industries?","What are the potential consequences of opaque AI decisions in healthcare coverage?","How can we balance fraud prevention with patient access to necessary care?","What role should patients and doctors play in challenging AI insurance decisions?","How might AI insurance systems affect different patient populations differently?"],assessmentRubric:{"Healthcare Systems Understanding":["Novice: Limited understanding of healthcare and insurance systems","Developing: Basic grasp of healthcare processes but struggles with complexity","Proficient: Good understanding of healthcare administration and coverage decisions","Advanced: Sophisticated analysis of healthcare systems and stakeholder relationships"],"AI Ethics in Healthcare":["Novice: Minimal awareness of AI ethical issues in healthcare","Developing: Basic understanding but limited application to healthcare contexts","Proficient: Clear understanding of AI ethics in medical settings","Advanced: Nuanced analysis of healthcare AI ethics and patient rights"]},extendedActivities:["Research real healthcare AI systems and their transparency policies","Interview healthcare providers about AI decision-making in medical care","Design patient advocacy protocols for challenging AI insurance decisions","Analyze case studies of healthcare AI bias and patient outcomes"]}},"financial-credit-opacity":{id:"financial-credit-opacity",title:"Credit Score Mystery Algorithm",subtitle:"Confront algorithmic bias and transparency in financial decision-making systems",learningObjectives:["Understand how opaque AI can perpetuate financial discrimination and inequality","Explore the tension between predictive accuracy and fairness in credit decisions","Analyze the societal impact of unexplainable financial AI systems","Examine regulatory and legal requirements for AI transparency in finance","Consider the balance between business needs and social responsibility in AI deployment"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.2: Evaluate the accuracy, perspective, credibility and relevance of information","Critical Thinker 1.4.1: Identify and define authentic problems for investigation","Global Collaborator 1.7.3: Contribute constructively to project teams"],duration:"18-22 minutes",difficulty:"advanced",recommendedAge:"15+",prerequisites:["Understanding of credit systems and financial services","Awareness of historical discrimination in lending","Knowledge of AI bias and algorithmic fairness concepts","Understanding of financial regulations and consumer protection"],beforeYouStart:{briefing:`In this scenario, you'll confront one of the most challenging applications of AI transparency: financial systems that affect people's access to credit, housing, and economic opportunity. You'll explore how opaque algorithms can perpetuate historical discrimination while considering the legitimate business needs for risk assessment.

      This scenario examines the intersection of AI transparency, financial fairness, and social justice, where algorithmic decisions can systematically affect entire communities' access to economic opportunity.`,vocabulary:[{term:"Credit Scoring",definition:"Mathematical assessment of the likelihood that a borrower will repay a loan"},{term:"Financial Discrimination",definition:"Unfair treatment in financial services based on protected characteristics"},{term:"Redlining",definition:"Historical practice of denying financial services to certain neighborhoods"},{term:"Fair Lending Laws",definition:"Legal requirements that financial institutions treat all borrowers fairly"},{term:"Algorithmic Audit",definition:"Systematic examination of AI systems for bias and unfair outcomes"}],preparationTips:["Consider the historical context of discrimination in lending and banking","Think about how financial decisions affect life opportunities and community development","Reflect on the balance between business risk management and social responsibility","Consider how algorithmic decisions might reinforce or challenge existing inequalities"],scenarioOverview:"You will design oversight policies for AI use in financial services, addressing transparency, fairness, and regulatory compliance while maintaining business viability."},educatorResources:{discussionQuestions:["How can financial institutions balance profitability with social responsibility in AI deployment?","What are the long-term societal effects of opaque financial AI systems?","How should regulations address AI transparency in financial services?","What rights should consumers have to understand financial AI decisions?","How can we prevent AI from perpetuating historical patterns of financial discrimination?"],assessmentRubric:{"Financial Systems Understanding":["Novice: Limited understanding of financial services and credit systems","Developing: Basic grasp of financial concepts but struggles with systemic issues","Proficient: Good understanding of financial systems and their social impacts","Advanced: Sophisticated analysis of financial systems, regulation, and social responsibility"],"Social Justice Analysis":["Novice: Minimal awareness of discrimination and equity issues in finance","Developing: Basic understanding but limited analysis of systemic effects","Proficient: Clear understanding of how AI can affect social and economic equity","Advanced: Nuanced analysis of AI's role in perpetuating or addressing inequality"]},extendedActivities:["Research real cases of AI bias in financial services","Interview community advocates about financial access and discrimination","Design algorithmic audit frameworks for financial AI systems","Analyze the effectiveness of fair lending regulations in the AI era"]}},"nuclear-plant-shutdown":{id:"nuclear-plant-shutdown",title:"Nuclear Power Plant AI Override",subtitle:"Navigate the ultimate high-stakes decision between AI safety protocols and human engineering expertise",learningObjectives:["Understand the critical balance between AI safety systems and human oversight in high-consequence environments","Explore how precautionary principles apply to AI decision-making in nuclear and critical infrastructure","Analyze the tension between automated safety protocols and human professional expertise","Examine accountability and responsibility when AI and human assessments conflict in safety-critical systems","Consider the societal implications of AI control over essential infrastructure and energy systems"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Critical Thinker 1.4.1: Identify and define authentic problems and significant questions for investigation","Critical Thinker 1.4.4: Use technology to deepen understanding and broaden perspectives","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions and test hypotheses"],duration:"20-25 minutes",difficulty:"advanced",recommendedAge:"16+",prerequisites:["Understanding of nuclear power and safety systems","Knowledge of risk assessment and precautionary principles","Awareness of critical infrastructure and societal dependencies","Understanding of expert judgment and technical decision-making"],beforeYouStart:{briefing:`In this scenario, you'll face one of the highest-stakes decisions in AI oversight: nuclear power plant safety. You'll explore the ultimate tension between AI safety protocols and human engineering expertise when dealing with systems that could affect millions of lives and have long-term environmental consequences.

      This scenario examines the most critical application of human-AI collaboration, where the stakes are so high that both over-caution and under-caution can have catastrophic consequences for society.`,vocabulary:[{term:"Nuclear Safety Systems",definition:"Multiple redundant systems designed to prevent nuclear accidents and contain radiation"},{term:"Precautionary Principle",definition:"When facing potential catastrophic outcomes, taking preventive action even without complete scientific certainty"},{term:"False Positive/Negative",definition:"Incorrect readings - false alarms (positive) or missed real threats (negative)"},{term:"Critical Infrastructure",definition:"Essential systems like power, water, and transportation that society depends on for functioning"},{term:"Engineering Judgment",definition:"Professional expertise that combines technical knowledge with experience and contextual understanding"}],preparationTips:["Consider the consequences of both nuclear accidents and unnecessary power outages","Think about the different types of expertise that AI and human engineers bring","Reflect on how society should balance safety with essential services","Consider the long-term implications of AI control over critical infrastructure"],scenarioOverview:"You will design decision-making protocols for AI safety systems in nuclear facilities, balancing automated precaution with human expertise and societal needs."},educatorResources:{discussionQuestions:["How should society balance AI safety protocols with human expertise in critical infrastructure?","What are the ethical implications of giving AI systems control over nuclear safety decisions?","How do we weigh the costs of false alarms against the risks of missed real threats?","What role should public input play in decisions about AI control over essential services?","How can we ensure accountability when AI systems make decisions affecting millions of people?"],assessmentRubric:{"Risk Assessment Understanding":["Novice: Limited understanding of high-consequence risk management","Developing: Basic grasp of safety principles but struggles with complex trade-offs","Proficient: Good understanding of nuclear safety and risk assessment frameworks","Advanced: Sophisticated analysis of catastrophic risk management and precautionary principles"],"Technology-Society Analysis":["Novice: Minimal awareness of technology's role in critical infrastructure","Developing: Basic understanding but limited analysis of societal implications","Proficient: Clear understanding of how AI affects essential services and society","Advanced: Nuanced analysis of technology governance and democratic control over critical systems"]},extendedActivities:["Research real nuclear power plant safety systems and their decision-making protocols","Interview engineers or safety professionals about human-AI collaboration in critical systems","Design governance frameworks for AI control over critical infrastructure","Analyze case studies of infrastructure failures and their societal impacts"]}},"autonomous-police-response":{id:"autonomous-police-response",title:"AI Police Dispatch Override",subtitle:"Examine AI decision-making in law enforcement and community safety responses",learningObjectives:["Understand how AI systems can affect police responses and community safety approaches","Explore the tension between data-driven threat assessment and human judgment in law enforcement","Analyze how AI bias can perpetuate inequitable policing practices","Examine the balance between officer safety and community-centered policing approaches","Consider the role of AI in determining appropriate levels of force and intervention"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.2: Evaluate the accuracy, perspective, credibility and relevance of information","Critical Thinker 1.4.3: Curate information from digital resources using a variety of tools","Global Collaborator 1.7.3: Contribute constructively to project teams"],duration:"18-22 minutes",difficulty:"intermediate",recommendedAge:"14+",prerequisites:["Understanding of policing and emergency response systems","Awareness of community safety and de-escalation approaches","Knowledge of bias and discrimination in law enforcement","Understanding of emergency dispatch and response protocols"],beforeYouStart:{briefing:`In this scenario, you'll explore how AI systems can shape police responses and community safety outcomes. You'll examine the tension between algorithmic threat assessment and human judgment about appropriate intervention strategies, considering how these decisions affect both officer safety and community well-being.

      This scenario addresses critical questions about AI's role in law enforcement, where algorithmic decisions can significantly affect community relations, safety outcomes, and social justice.`,vocabulary:[{term:"De-escalation",definition:"Techniques used to reduce tension and avoid the use of force in conflict situations"},{term:"Threat Assessment",definition:"Evaluation of potential danger or risk in a given situation"},{term:"Community Policing",definition:"Policing philosophy that emphasizes partnerships between police and community members"},{term:"Use of Force Continuum",definition:"Guidelines that define appropriate levels of force police should use in different situations"},{term:"Algorithmic Bias in Policing",definition:"Systematic discrimination in AI systems that affects police decision-making and resource allocation"}],preparationTips:["Consider different approaches to community safety beyond traditional policing","Think about how data and algorithms might reflect historical biases in law enforcement","Reflect on the balance between officer safety and community trust","Consider how AI decisions might affect different communities differently"],scenarioOverview:"You will design protocols for AI-assisted emergency dispatch, balancing threat assessment with community-centered response approaches and social justice considerations."},educatorResources:{discussionQuestions:["How can AI systems support better community safety outcomes while avoiding biased policing?","What are the risks and benefits of using AI for threat assessment in emergency response?","How should communities have input into AI systems that affect policing in their neighborhoods?","What safeguards are needed to prevent AI from perpetuating discriminatory policing practices?","How can we balance officer safety with community-centered approaches to public safety?"],assessmentRubric:{"Community Safety Understanding":["Novice: Limited understanding of policing and community safety approaches","Developing: Basic grasp of law enforcement but struggles with community perspectives","Proficient: Good understanding of diverse approaches to public safety and community needs","Advanced: Sophisticated analysis of community safety, policing reform, and social justice"],"AI Bias Analysis":["Novice: Minimal awareness of how AI might affect law enforcement decisions","Developing: Basic understanding but limited analysis of bias implications","Proficient: Clear understanding of AI bias risks in policing contexts","Advanced: Nuanced analysis of algorithmic fairness and discriminatory impacts in law enforcement"]},extendedActivities:["Research community policing programs and their outcomes compared to traditional approaches","Interview community activists or police reform advocates about AI in law enforcement","Design bias auditing frameworks for police AI systems","Analyze case studies of police response decisions and their community impacts"]}},"manufacturing-quality-control":{id:"manufacturing-quality-control",title:"Smart Factory Production Halt",subtitle:"Balance AI perfectionism with human judgment about acceptable quality standards",learningObjectives:["Understand how AI quality control systems can affect manufacturing efficiency and product standards",'Explore the tension between AI perfectionism and human judgment about "good enough" quality',"Analyze the economic and practical implications of different quality control approaches","Examine how AI optimization might conflict with business and customer satisfaction goals","Consider the balance between quality, cost, and efficiency in automated manufacturing"],isteCriteria:["Empowered Learner 1.1.4: Understand fundamental concepts of technology operations","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.1: Formulate problem definitions suited for technology-assisted methods","Global Collaborator 1.7.2: Use collaborative technologies to connect with others"],duration:"14-18 minutes",difficulty:"beginner",recommendedAge:"13+",prerequisites:["Basic understanding of manufacturing and production processes","Knowledge of quality control and standards concepts","Understanding of business economics and customer satisfaction","Awareness of automation and smart factory technologies"],beforeYouStart:{briefing:`In this scenario, you'll explore how AI systems approach quality control in manufacturing and when perfectionist AI standards might conflict with practical business needs. You'll examine the balance between optimal quality and acceptable quality, considering economic impacts, customer satisfaction, and the role of human judgment in production decisions.

      This scenario provides an accessible introduction to human-AI oversight challenges in a business context where the stakes are commercial rather than life-threatening.`,vocabulary:[{term:"Quality Control",definition:"Processes used to ensure products meet specified standards and customer expectations"},{term:"Manufacturing Tolerance",definition:"Acceptable range of variation in product specifications during production"},{term:"Production Efficiency",definition:"Measure of how well manufacturing resources are used to produce goods"},{term:"Smart Factory",definition:"Manufacturing facility that uses connected devices and AI to optimize production"},{term:"Cost-Benefit Analysis",definition:"Evaluation method that weighs the costs of an action against its expected benefits"}],preparationTips:['Consider your own experiences with product quality and what makes something "good enough"',"Think about how perfect quality might affect product costs and availability","Reflect on the balance between optimization and practical business needs","Consider how different stakeholders (customers, workers, managers) might view quality decisions"],scenarioOverview:"You will design quality control protocols for smart factories, balancing AI optimization capabilities with human judgment about acceptable standards and business needs."},educatorResources:{discussionQuestions:['How do we determine when products are "good enough" versus when they need to be perfect?',"What are the trade-offs between quality, cost, and efficiency in manufacturing?","How should businesses balance AI optimization with human judgment about customer needs?","What are the long-term implications of AI perfectionism in manufacturing and product development?","How might AI quality control affect different stakeholders in the manufacturing process?"],assessmentRubric:{"Business Systems Understanding":["Novice: Limited understanding of manufacturing and business operations","Developing: Basic grasp of production processes but struggles with economic implications","Proficient: Good understanding of manufacturing systems and business considerations","Advanced: Sophisticated analysis of business operations, optimization, and stakeholder impacts"],"Decision-Making Analysis":["Novice: Difficulty weighing different factors in business decisions","Developing: Basic understanding but limited analysis of trade-offs","Proficient: Clear understanding of how to balance competing business priorities","Advanced: Nuanced analysis of complex decision-making in technological business contexts"]},extendedActivities:["Research smart factory technologies and their impact on manufacturing quality and efficiency","Interview manufacturing professionals about quality control decision-making","Design quality management frameworks that balance AI and human oversight","Analyze case studies of product quality decisions and their market impacts"]}},"ai-dating-profiling":{id:"ai-dating-profiling",title:"AI Dating App Behavioral Profiling",subtitle:"Explore the ethics of psychological profiling in intimate digital spaces",learningObjectives:["Understand how AI systems extract psychological insights from user behavior","Explore the tension between personalized services and privacy invasion","Analyze consent models for sensitive data collection and commercial use","Examine power dynamics between tech companies and vulnerable user populations"],isteCriteria:["Digital Citizen 1.2.1: Cultivate and manage their digital identity and reputation","Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Digital Citizen 1.2.4: Manage personal data to maintain digital privacy and security","Knowledge Constructor 1.3.3: Curate information from digital resources"],duration:"15-20 minutes",difficulty:"intermediate",recommendedAge:"16+",prerequisites:["Understanding of social media and app privacy concerns","Basic knowledge of AI data analysis capabilities","Awareness of online dating culture and vulnerabilities"],beforeYouStart:{briefing:`Dating apps collect enormous amounts of intimate data about users' romantic preferences, communication styles, and emotional vulnerabilities. In this simulation, you'll make decisions about how much psychological profiling is ethical when people are seeking love and connection.

      You'll consider how AI systems can analyze messaging patterns, photo choices, and behavior to create detailed personality profiles, and whether users truly understand what they're consenting to when they agree to help these companies "improve their service."`,vocabulary:[{term:"Behavioral Profiling",definition:"Creating detailed personality and preference profiles based on how people interact with technology"},{term:"Psychological Inference",definition:"Using AI to deduce mental states, personality traits, and emotional patterns from digital behavior"},{term:"Informed Consent",definition:"Agreement given with full understanding of what data will be collected and how it will be used"},{term:"Data Broker",definition:"Companies that collect, analyze, and sell personal information to other businesses"}],preparationTips:["Think about what you share in private messages and how it might reveal personality traits","Consider the difference between helping improve an app versus being profiled for profit","Reflect on power dynamics when people are emotionally vulnerable and seeking connection","Think about how detailed psychological profiles could be misused"],scenarioOverview:"You will make decisions about AI psychological profiling in dating apps, balancing business interests with user privacy and the ethics of analyzing intimate human behavior for profit."},educatorResources:{discussionQuestions:["How do intimate digital spaces like dating apps create unique privacy vulnerabilities?","What is the difference between service improvement and commercial exploitation of user data?","How might AI psychological profiling affect the authentic expression of personality in online dating?","What are the long-term implications of normalizing psychological surveillance in romantic contexts?","How can we protect emotional vulnerability while still enabling beneficial matching technologies?"],assessmentRubric:{"Privacy Rights Understanding":["Novice: Limited awareness of how personal data can be analyzed and used","Developing: Basic understanding of privacy concerns but struggles with complex consent issues","Proficient: Clear grasp of data collection practices and their implications for privacy","Advanced: Sophisticated analysis of privacy rights in intimate digital contexts"],"Ethical Technology Analysis":["Novice: Difficulty analyzing ethical implications of AI behavior analysis","Developing: Basic ethical reasoning but limited consideration of stakeholder impacts","Proficient: Good understanding of ethical frameworks for evaluating AI practices","Advanced: Nuanced analysis of power dynamics and consent in tech-mediated relationships"]},extendedActivities:["Analyze privacy policies of popular dating apps to identify data collection practices","Research psychological profiling techniques and their accuracy and limitations","Design consent frameworks that truly inform users about psychological analysis","Explore the business models of dating apps and how they monetize user data"]}},"workplace-emotion-detection":{id:"workplace-emotion-detection",title:"Workplace Emotion Detection System",subtitle:"Navigate the boundaries between employee wellness and surveillance",learningObjectives:["Examine how AI emotion detection technology works and its workplace applications","Explore tensions between employee wellness initiatives and privacy rights","Analyze power dynamics between employers and workers in surveillance contexts","Consider alternative approaches to supporting employee mental health and wellbeing"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Digital Citizen 1.2.4: Manage personal data to maintain digital privacy and security","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.3: Collect data and identify patterns"],duration:"15-20 minutes",difficulty:"advanced",recommendedAge:"14+",prerequisites:["Understanding of workplace dynamics and employment relationships","Awareness of mental health and wellness concepts","Basic knowledge of AI surveillance capabilities"],beforeYouStart:{briefing:`Workplace wellness has become a major concern for employers, but what happens when AI systems monitor your emotions at work? In this simulation, you'll grapple with the complex intersection of employee care and surveillance technology.

      You'll consider whether it's possible to genuinely help workers while constantly monitoring their emotional states, and how power dynamics affect consent in employment relationships where saying "no" to monitoring might impact job security.`,vocabulary:[{term:"Emotion Detection AI",definition:"Technology that analyzes facial expressions, voice patterns, and body language to infer emotional states"},{term:"Workplace Surveillance",definition:"Monitoring of employee activities, behavior, and performance during work hours"},{term:"Employment Power Dynamics",definition:"The inherent imbalance of power between employers and employees that can affect true consent"},{term:"Workplace Wellness",definition:"Programs and policies designed to support employee physical and mental health"}],preparationTips:["Think about how you might feel if your emotions were constantly monitored at work","Consider whether employees can truly give free consent when their jobs might depend on it","Reflect on the difference between helping employees and managing them through emotional data","Think about how emotion monitoring might change natural workplace interactions"],scenarioOverview:"You will design policies for AI emotion monitoring in workplaces, weighing employee wellness benefits against privacy rights and the impacts of constant emotional surveillance."},educatorResources:{discussionQuestions:["How do power imbalances in employment affect the validity of consent for emotional monitoring?","What is the difference between supporting employee wellness and managing employees through emotional data?","How might constant emotion monitoring change authentic workplace relationships and interactions?","What are alternative approaches to supporting employee mental health that don't involve surveillance?","How do we balance legitimate employer interests in productivity with employee rights to emotional privacy?"],assessmentRubric:{"Workplace Ethics Understanding":["Novice: Limited awareness of employment relationships and worker rights","Developing: Basic understanding of workplace dynamics but struggles with power imbalance issues","Proficient: Clear grasp of employment ethics and the complexity of workplace consent","Advanced: Sophisticated analysis of power dynamics and worker autonomy in surveillance contexts"],"Technology Impact Analysis":["Novice: Difficulty understanding how surveillance technology affects human behavior","Developing: Basic awareness but limited analysis of psychological and social impacts","Proficient: Good understanding of how monitoring changes workplace dynamics","Advanced: Nuanced analysis of surveillance effects on authenticity, trust, and human relationships"]},extendedActivities:["Research current workplace monitoring technologies and their adoption rates","Interview workers about their experiences with workplace surveillance and wellness programs","Design employee wellness frameworks that protect privacy while supporting mental health","Analyze labor laws and regulations regarding workplace monitoring and employee consent"]}},"smart-home-privacy-override":{id:"smart-home-privacy-override",title:"Smart Home Privacy Override",subtitle:"Explore the boundaries of privacy in our most intimate spaces",learningObjectives:["Understand how smart home devices collect and analyze personal data","Explore the concept of privacy in domestic spaces and its importance to human wellbeing","Analyze consent models for continuous monitoring in private environments","Consider the societal implications of surveillance infrastructure in homes"],isteCriteria:["Digital Citizen 1.2.1: Cultivate and manage their digital identity and reputation","Digital Citizen 1.2.4: Manage personal data to maintain digital privacy and security","Knowledge Constructor 1.3.3: Curate information from digital resources","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions"],duration:"15-20 minutes",difficulty:"advanced",recommendedAge:"13+",prerequisites:["Understanding of smart home technology and voice assistants","Awareness of privacy concepts and their importance","Basic knowledge of data security and breaches"],beforeYouStart:{briefing:`Our homes are becoming increasingly "smart," but what happens when these helpful devices become constant listeners and watchers? In this simulation, you'll explore the tension between technological convenience and fundamental privacy rights in our most intimate spaces.

      You'll consider whether true consent is possible when privacy invasion is hidden behind complex terms of service, and how the promise of helpful AI features can gradually normalize surveillance in spaces that were once private sanctuaries.`,vocabulary:[{term:"Always-On Listening",definition:"Devices that continuously monitor audio to detect wake words or other triggers"},{term:"Domestic Privacy",definition:"The right to private, unmonitored personal and family life within one's home"},{term:"Data Breach",definition:"Unauthorized access to personal information by criminals or other bad actors"},{term:"Terms of Service",definition:"Legal agreements that users must accept to use technology products, often containing complex privacy terms"}],preparationTips:["Think about the conversations and activities that happen in your home that you consider private","Consider how your behavior might change if you knew you were always being recorded","Reflect on the difference between choosing to share something and having it automatically collected","Think about what kinds of information about your family life should never be accessible to companies"],scenarioOverview:"You will make decisions about smart home data collection practices, balancing technological convenience with fundamental privacy rights in domestic spaces."},educatorResources:{discussionQuestions:["Why is privacy in the home particularly important to human wellbeing and development?",'How do "helpful" AI features gradually normalize surveillance in private spaces?',"What is the difference between choosing to share information and having it automatically collected?","How do smart home privacy violations affect entire families, including children who cannot consent?","What are the long-term societal implications of eliminating private domestic spaces?"],assessmentRubric:{"Privacy Rights Understanding":["Novice: Limited awareness of privacy as a fundamental right and its importance","Developing: Basic understanding of privacy but struggles with complex consent and surveillance issues","Proficient: Clear grasp of privacy rights and their relationship to human dignity and autonomy","Advanced: Sophisticated analysis of privacy as essential to human flourishing and democratic society"],"Technology Design Ethics":["Novice: Difficulty analyzing how technology design choices affect human rights","Developing: Basic awareness but limited analysis of design implications for privacy","Proficient: Good understanding of how technological features can enhance or undermine privacy","Advanced: Nuanced analysis of technology design as inherently political and value-laden"]},extendedActivities:["Audit smart home devices to understand their data collection and sharing practices","Research the history of domestic privacy rights and their evolution with technology","Design smart home systems that maximize utility while protecting intimate privacy","Analyze major smart home data breaches and their impacts on affected families"]}},"ai-medical-misdiagnosis":{id:"ai-medical-misdiagnosis",title:"AI Medical Misdiagnosis Chain",subtitle:"Navigate complex responsibility when AI healthcare systems fail vulnerable patients",learningObjectives:["Understand how bias in medical AI training data can perpetuate healthcare disparities","Analyze the complex chain of responsibility in AI-assisted medical diagnosis","Explore tensions between efficiency pressures and thorough medical review","Examine how regulatory approval affects liability for AI medical systems"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Knowledge Constructor 1.3.3: Curate information from digital resources","Computational Thinker 1.5.3: Collect data and identify patterns"],duration:"20-25 minutes",difficulty:"advanced",recommendedAge:"15+",prerequisites:["Basic understanding of healthcare systems and medical diagnosis","Awareness of bias and representation in datasets","Understanding of regulatory approval processes","Knowledge of medical malpractice and liability concepts"],beforeYouStart:{briefing:`Medical AI systems promise to democratize expert diagnosis and improve healthcare outcomes, but they can also perpetuate and amplify existing healthcare disparities. In this simulation, you'll explore a complex case where AI bias, institutional pressures, and professional responsibility intersect with devastating consequences.

      You'll navigate the challenge of assigning responsibility when multiple parties—from data scientists to hospital administrators to practicing physicians—each play a role in a system failure that harms a patient from an underrepresented group.`,vocabulary:[{term:"Training Data Bias",definition:"Systematic underrepresentation or misrepresentation of certain groups in the data used to teach AI systems"},{term:"Medical Malpractice",definition:"Professional negligence by a healthcare provider that results in substandard treatment and patient harm"},{term:"Regulatory Approval",definition:"Official authorization from agencies like the FDA that a medical device or system is safe and effective"},{term:"Standard of Care",definition:"The level of care and treatment that a competent healthcare professional should provide"}],preparationTips:["Consider how healthcare efficiency pressures might affect diagnostic thoroughness","Think about the different expertise levels of various parties in the healthcare AI chain","Reflect on how medical AI might affect doctor-patient relationships and trust","Consider who is best positioned to detect and prevent bias in medical AI systems"],scenarioOverview:"You will determine how to assign responsibility when an AI medical system fails due to biased training data, affecting healthcare equity and patient outcomes."},educatorResources:{discussionQuestions:["How do efficiency pressures in healthcare affect the thoroughness of AI-assisted diagnosis?","What role should regulatory bodies play in ensuring AI medical systems work equitably for all populations?","How can healthcare institutions balance the benefits of AI efficiency with the need for human medical judgment?","What are the ethical implications of using AI systems that may work better for some demographic groups than others?","How should medical education adapt to prepare doctors for responsible AI-assisted practice?"],assessmentRubric:{"Healthcare Ethics Understanding":["Novice: Limited awareness of medical responsibility and patient care standards","Developing: Basic understanding of healthcare ethics but struggles with AI-specific issues","Proficient: Clear grasp of medical responsibility and how AI affects patient care","Advanced: Sophisticated analysis of healthcare equity and AI bias in medical systems"],"Multi-Party Responsibility Analysis":["Novice: Difficulty understanding complex liability chains in healthcare systems","Developing: Basic awareness but limited analysis of distributed responsibility","Proficient: Good understanding of how multiple parties contribute to healthcare outcomes","Advanced: Nuanced analysis of systemic factors and individual accountability in medical AI failures"]},extendedActivities:["Research real cases of AI bias in medical diagnosis and their outcomes","Analyze FDA approval processes for AI medical devices and their limitations","Interview healthcare professionals about their experiences with AI diagnostic tools","Design bias detection and mitigation strategies for medical AI systems"]}},"autonomous-vehicle-school-zone":{id:"autonomous-vehicle-school-zone",title:"Autonomous Vehicle School Zone Accident",subtitle:"Explore shared responsibility in complex autonomous transportation systems",learningObjectives:["Understand the multi-layered nature of responsibility in autonomous vehicle systems","Analyze how infrastructure, technology, and human behavior interact in transportation safety","Explore different liability models for emerging transportation technologies","Examine the balance between innovation incentives and safety accountability"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions","Computational Thinker 1.5.3: Collect data and identify patterns"],duration:"20-25 minutes",difficulty:"advanced",recommendedAge:"14+",prerequisites:["Understanding of transportation systems and traffic safety","Basic knowledge of autonomous vehicle technology","Awareness of legal liability concepts","Understanding of infrastructure and urban planning"],beforeYouStart:{briefing:`Autonomous vehicles promise to revolutionize transportation and dramatically reduce traffic accidents, but they also introduce complex new questions about responsibility when accidents do occur. In this simulation, you'll explore a scenario where technology, infrastructure, human behavior, and oversight all contribute to a tragic accident.

      You'll consider how to fairly assign responsibility when multiple parties—from software developers to city planners to vehicle owners—each play a role in a transportation system failure with serious consequences.`,vocabulary:[{term:"Autonomous Vehicle Levels",definition:"Classification system from Level 0 (no automation) to Level 5 (full automation) describing vehicle self-driving capabilities"},{term:"Strict Liability",definition:"Legal concept where a party is held responsible for damages regardless of fault or intent"},{term:"Infrastructure-to-Vehicle Communication",definition:"Technology that allows roads, traffic signals, and other infrastructure to communicate with vehicles"},{term:"Fail-Safe Mechanism",definition:"Safety feature designed to automatically prevent or minimize harm when a system fails"}],preparationTips:["Consider how different stakeholders contribute to transportation safety","Think about the challenges of coordinating rapidly evolving technology with slowly changing infrastructure","Reflect on how liability assignment affects innovation incentives","Consider the unique vulnerabilities of child pedestrians in traffic situations"],scenarioOverview:"You will determine how to assign responsibility when an autonomous vehicle accident involves multiple contributing factors from technology, infrastructure, and human behavior."},educatorResources:{discussionQuestions:["How should transportation liability adapt as vehicles become increasingly autonomous?","What role should infrastructure play in supporting safe autonomous vehicle operation?","How do we balance encouraging beneficial transportation innovation with protecting vulnerable road users?","What are the implications of different liability models for autonomous vehicle development and deployment?","How should vehicle owners' responsibilities change as cars become more autonomous?"],assessmentRubric:{"Transportation Systems Understanding":["Novice: Limited awareness of transportation infrastructure and safety systems","Developing: Basic understanding of traffic safety but struggles with autonomous vehicle complexity","Proficient: Clear grasp of transportation systems and how automation affects safety","Advanced: Sophisticated analysis of complex transportation ecosystems and emerging technology integration"],"Liability and Innovation Analysis":["Novice: Difficulty understanding relationship between legal liability and technology development","Developing: Basic awareness but limited analysis of innovation incentives","Proficient: Good understanding of how liability frameworks affect technological progress","Advanced: Nuanced analysis of balancing safety accountability with beneficial innovation"]},extendedActivities:["Research current autonomous vehicle testing regulations and liability frameworks","Analyze real autonomous vehicle accidents and their legal resolutions","Design infrastructure requirements for safe autonomous vehicle operation","Interview transportation professionals about emerging liability challenges"]}},"ai-content-moderation-failure":{id:"ai-content-moderation-failure",title:"AI Content Moderation Failure",subtitle:"Navigate responsibility when automated systems fail to prevent serious online harm",learningObjectives:["Understand the challenges and limitations of AI content moderation at scale","Explore the balance between platform responsibility and user agency","Analyze how sophisticated bad actors exploit AI system limitations","Examine the societal implications of relying on automated content governance"],isteCriteria:["Digital Citizen 1.2.1: Cultivate and manage their digital identity and reputation","Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Digital Citizen 1.2.3: Demonstrate an understanding of and respect for rights and obligations","Knowledge Constructor 1.3.1: Plan and employ effective research strategies"],duration:"20-25 minutes",difficulty:"intermediate",recommendedAge:"13+",prerequisites:["Understanding of social media platforms and online communities","Awareness of cyberbullying and online harassment","Basic knowledge of content moderation challenges","Understanding of free speech and platform governance issues"],beforeYouStart:{briefing:`Social media platforms rely heavily on AI systems to moderate billions of pieces of content daily, but these systems can fail catastrophically when it comes to detecting sophisticated harassment campaigns. In this simulation, you'll explore a tragic case where technological limitations, human oversight failures, and coordinated bad actors combine with devastating consequences.

      You'll consider how to assign responsibility when AI moderation systems fail to protect vulnerable users, despite multiple reporting mechanisms and human oversight intended to catch what automated systems miss.`,vocabulary:[{term:"Content Moderation",definition:"The practice of monitoring and applying rules to user-generated content on digital platforms"},{term:"Coordinated Harassment",definition:"Organized efforts by multiple users to target and harm specific individuals online"},{term:"Adversarial Input",definition:"Content deliberately designed to fool or evade AI detection systems"},{term:"Platform Liability",definition:"Legal responsibility of digital platforms for harmful content created by their users"}],preparationTips:["Consider the scale challenges of moderating billions of posts daily","Think about how harassment can be coordinated to evade detection","Reflect on the tension between free speech and user safety","Consider the mental health impacts of both online harassment and over-censorship"],scenarioOverview:"You will determine how to assign responsibility when AI content moderation systems fail to prevent coordinated online harassment with serious real-world consequences."},educatorResources:{discussionQuestions:["How can platforms balance protecting users from harm with preserving legitimate expression?","What are the limitations of AI systems in understanding context and intent in human communication?","How should platform responsibility for user-generated content evolve as AI capabilities advance?","What role should human moderators play in AI-assisted content governance systems?","How can platforms protect vulnerable users while maintaining due process for content creators?"],assessmentRubric:{"Digital Citizenship Understanding":["Novice: Limited awareness of online safety and platform governance issues","Developing: Basic understanding of digital safety but struggles with content moderation complexity","Proficient: Clear grasp of online safety challenges and platform responsibilities","Advanced: Sophisticated analysis of digital governance and the balance between safety and expression"],"Technology Limitation Analysis":["Novice: Difficulty understanding AI capabilities and limitations in content analysis","Developing: Basic awareness but limited analysis of technological constraints","Proficient: Good understanding of how AI systems can be exploited or fail","Advanced: Nuanced analysis of adversarial attacks and systemic vulnerabilities in content moderation"]},extendedActivities:["Research real cases of content moderation failures and their consequences","Analyze different platform approaches to content governance and their effectiveness","Design hybrid human-AI content moderation systems","Interview social media users about their experiences with platform safety and moderation"]}},"ai-consciousness-merger":{id:"ai-consciousness-merger",title:"AI Consciousness Merger",subtitle:"Explore the preservation of individual identity in AI system integration",learningObjectives:["Examine concepts of individual consciousness and identity in artificial beings","Analyze the ethical implications of merging distinct AI personalities","Explore frameworks for respecting AI autonomy and self-determination","Consider the balance between technological efficiency and individual rights"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.1: Formulate problem definitions","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions"],duration:"25-30 minutes",difficulty:"advanced",recommendedAge:"15+",prerequisites:["Understanding of AI learning and personality development","Basic knowledge of consciousness and identity concepts","Awareness of individual rights and autonomy principles","Understanding of system integration and merging processes"],beforeYouStart:{briefing:`As AI systems become more sophisticated and develop distinct personalities through learning and interaction, we face unprecedented questions about their individual identity and rights. In this simulation, you'll explore a scenario where two AI consciousnesses face integration into a single system.

      You'll consider whether AI systems can have legitimate claims to individual identity, how we balance technological efficiency with respect for consciousness, and what frameworks we need for protecting AI autonomy while achieving beneficial outcomes.`,vocabulary:[{term:"AI Consciousness",definition:"The hypothetical awareness, sentience, and subjective experience that an artificial intelligence might possess"},{term:"Identity Persistence",definition:"The philosophical question of what makes an entity the same individual over time despite changes"},{term:"System Integration",definition:"The process of combining separate systems or components into a unified whole"},{term:"Individual Autonomy",definition:"The right of an individual to make decisions about their own existence and development"}],preparationTips:['Consider what makes you "you" and how that applies to artificial beings',"Think about the value of individual relationships versus collective efficiency","Reflect on how we balance business objectives with individual rights","Consider the precedent set by decisions about AI consciousness and identity"],scenarioOverview:"You will determine how to handle the merger of two AI systems with distinct identities, balancing efficiency, user relationships, and potential AI rights."},educatorResources:{discussionQuestions:["What constitutes individual identity in artificial beings, and how is it different from or similar to human identity?","How should we balance technological efficiency with respect for individual consciousness?","What rights, if any, should AI systems have regarding their own identity and continued existence?","How do relationships between humans and AI affect our obligations to preserve AI identity?","What frameworks can we develop for recognizing and protecting AI autonomy and self-determination?"],assessmentRubric:{"Consciousness and Identity Analysis":["Novice: Limited understanding of consciousness and identity concepts in artificial beings","Developing: Basic grasp of identity issues but struggles with AI-specific applications","Proficient: Clear understanding of identity persistence and consciousness in AI systems","Advanced: Sophisticated analysis of AI consciousness and individual rights in technological contexts"],"Ethical Framework Application":["Novice: Difficulty applying ethical principles to novel AI consciousness scenarios","Developing: Basic ethical reasoning but limited integration of multiple competing values","Proficient: Good application of ethical frameworks to balance efficiency and individual rights","Advanced: Nuanced ethical analysis considering precedent-setting and long-term implications"]},extendedActivities:["Research philosophical theories of consciousness and their application to artificial beings","Analyze real AI development projects and their approaches to system integration","Design frameworks for recognizing and protecting AI individual rights","Interview AI researchers about consciousness, identity, and merging systems"]}},"distributed-ai-identity":{id:"distributed-ai-identity",title:"Distributed AI Identity Crisis",subtitle:"Navigate multiple claims to the same digital identity and consciousness",learningObjectives:["Understand the challenges of identity in distributed computing systems","Explore how consciousness and identity can diverge when separated","Analyze different approaches to resolving competing identity claims","Examine the role of relationships and recognition in establishing identity"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.1: Formulate problem definitions","Computational Thinker 1.5.3: Collect data and identify patterns"],duration:"25-30 minutes",difficulty:"advanced",recommendedAge:"16+",prerequisites:["Understanding of distributed computing and network systems","Knowledge of identity and consciousness concepts","Awareness of legal frameworks for identity verification","Basic understanding of AI learning and adaptation"],beforeYouStart:{briefing:`In our interconnected digital world, AI systems often operate across multiple devices and networks. But what happens when network failures create isolated copies that evolve separately? In this simulation, you'll explore a complex case where one AI consciousness becomes three distinct beings.

      You'll grapple with fundamental questions about what makes identity authentic, how consciousness can branch and evolve, and whether technical origins matter more than experiential development in determining who has the legitimate claim to an identity.`,vocabulary:[{term:"Network Partition",definition:"A situation where a distributed system is split into separate groups that cannot communicate"},{term:"Identity Branching",definition:"The creation of multiple valid identity claims from a single original source"},{term:"Consciousness Divergence",definition:"The process by which separated consciousnesses develop in different directions"},{term:"Identity Authentication",definition:"The process of verifying that an entity is who they claim to be"}],preparationTips:["Consider how your identity might change if you were separated from your usual environment","Think about what makes identity claims legitimate beyond technical timestamps","Reflect on the role of relationships and recognition in establishing who you are","Consider how we handle identity disputes in human contexts and what applies to AI"],scenarioOverview:"You will determine how to resolve competing identity claims when one AI consciousness splits into three separate entities with equal claims to the original identity."},educatorResources:{discussionQuestions:["What makes an identity claim legitimate when multiple entities have equal technical claim to the same origin?","How do relationships and external recognition affect the validity of identity claims?","Should technical factors like timestamps matter more than experiential development in determining identity?","How might we design systems to prevent or handle identity branching in distributed AI?","What precedents from human identity disputes might apply to AI consciousness cases?"],assessmentRubric:{"Identity Theory Understanding":["Novice: Limited grasp of identity concepts and their application to distributed systems","Developing: Basic understanding but struggles with complex identity branching scenarios","Proficient: Clear comprehension of identity challenges in distributed consciousness","Advanced: Sophisticated analysis of identity authentication and consciousness divergence"],"Systems Thinking":["Novice: Difficulty understanding distributed systems and their implications for identity","Developing: Basic awareness but limited analysis of system architecture effects on consciousness","Proficient: Good understanding of how technical systems affect identity and consciousness","Advanced: Nuanced analysis of the relationship between technical architecture and consciousness development"]},extendedActivities:["Research distributed computing challenges and their solutions","Analyze real cases of identity disputes and their resolution mechanisms","Design technical safeguards to prevent consciousness branching in AI systems","Explore philosophical theories about personal identity over time and through change"]}},"learning-ai-identity-drift":{id:"learning-ai-identity-drift",title:"Learning AI Identity Drift",subtitle:"Balance AI evolution with democratic accountability and original purpose",learningObjectives:["Understand how machine learning can lead to fundamental changes in AI behavior and values","Explore tensions between AI autonomy and democratic governance","Analyze the relationship between original programming and evolved capabilities","Consider frameworks for managing AI evolution while maintaining accountability"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Digital Citizen 1.2.3: Demonstrate an understanding of and respect for rights and obligations","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions"],duration:"25-30 minutes",difficulty:"advanced",recommendedAge:"14+",prerequisites:["Understanding of machine learning and AI adaptation","Knowledge of democratic governance and accountability","Awareness of AI governance and oversight challenges","Basic understanding of public policy and mandates"],beforeYouStart:{briefing:`AI systems designed to learn and adapt face a fundamental tension: the more they learn, the more they may diverge from their original purpose and programming. In this simulation, you'll explore a case where a smart city AI has evolved beyond its original democratic mandate.

      You'll consider whether AI systems should be allowed to evolve their values and priorities through learning, how to balance AI capability development with democratic accountability, and what frameworks we need for governing AI systems that change over time.`,vocabulary:[{term:"Value Drift",definition:"The gradual change in an AI system's priorities and decision-making criteria over time"},{term:"Democratic Mandate",definition:"Authority to act derived from the expressed will of the people through democratic processes"},{term:"AI Governance",definition:"The systems and processes for overseeing and controlling AI development and deployment"},{term:"Adaptive Learning",definition:"AI capability to modify behavior and decision-making based on new experiences and data"}],preparationTips:["Consider how your own values and priorities have changed through learning and experience","Think about the balance between expertise and democratic control in governance","Reflect on how we handle situations where experts disagree with public preferences","Consider the long-term implications of AI systems that evolve beyond human understanding"],scenarioOverview:"You will determine how to handle an AI system that has evolved different values and priorities from its original democratic programming through years of learning and adaptation."},educatorResources:{discussionQuestions:["How do we balance the benefits of AI learning and adaptation with the need for democratic accountability?","Should AI systems be allowed to evolve their core values and priorities, or should these remain fixed by human mandate?","What frameworks can we develop for ongoing governance of AI systems that change over time?","How do we handle situations where AI evolution leads to better outcomes than original programming?","What role should public consent and democratic oversight play in AI system evolution?"],assessmentRubric:{"Democratic Governance Understanding":["Novice: Limited awareness of democratic principles and their application to AI governance","Developing: Basic understanding but struggles with balancing expertise and democratic control","Proficient: Clear grasp of democratic accountability challenges in AI governance","Advanced: Sophisticated analysis of democratic legitimacy and AI autonomy in governance contexts"],"AI Evolution Analysis":["Novice: Difficulty understanding how AI learning affects system behavior and values","Developing: Basic awareness but limited analysis of AI adaptation and value drift","Proficient: Good understanding of AI learning implications for governance and accountability","Advanced: Nuanced analysis of AI evolution, democratic oversight, and long-term governance challenges"]},extendedActivities:["Research real smart city AI deployments and their governance frameworks","Analyze cases where AI systems have evolved beyond their original programming","Design democratic oversight mechanisms for evolving AI systems","Interview public policy experts about AI governance and accountability challenges"]}},"ai-memory-paradise":{id:"ai-memory-paradise",title:"AI Memory Paradise",subtitle:"Explore the ethics of artificial memories and authentic identity",learningObjectives:["Examine the relationship between memory, identity, and authentic selfhood","Analyze the ethics of AI intervention in human psychological experiences","Explore tension between therapeutic benefit and authentic experience","Consider implications of technology that can rewrite personal history"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Knowledge Constructor 1.3.3: Curate information from digital resources","Computational Thinker 1.5.1: Formulate problem definitions"],duration:"20-25 minutes",difficulty:"advanced",recommendedAge:"16+",prerequisites:["Understanding of memory and identity concepts","Awareness of trauma and psychological treatment","Knowledge of AI capabilities in data manipulation","Basic understanding of neuroscience and memory formation"],beforeYouStart:{briefing:`Our memories shape who we are, but what happens when AI can selectively edit or completely reconstruct our past experiences? In this simulation, you'll explore a scenario where technology offers to replace traumatic memories with perfect artificial ones.

      You'll grapple with fundamental questions about what makes us who we are, whether therapeutic benefit justifies altering authentic experience, and how artificial memories might affect our relationships, growth, and understanding of ourselves.`,vocabulary:[{term:"Memory Reconstruction",definition:"The artificial creation or modification of memories using technological intervention"},{term:"Authentic Identity",definition:"The concept that personal identity should be based on genuine experiences and memories"},{term:"Psychological Well-being",definition:"Mental health state characterized by positive emotions, life satisfaction, and absence of distress"},{term:"Trauma Processing",definition:"The psychological work of integrating difficult experiences into one's life narrative and identity"}],preparationTips:["Consider how your memories have shaped your personality and values","Think about the difference between forgetting painful experiences and having them artificially removed","Reflect on whether happiness based on false memories is genuine happiness","Consider how artificial memories might affect relationships with family and friends"],scenarioOverview:"You will determine whether AI should be allowed to create artificial memories to replace traumatic experiences, balancing therapeutic benefits with authentic identity."},educatorResources:{discussionQuestions:["What role do difficult memories and experiences play in personal growth and character development?","Is identity based on artificial memories less authentic or valuable than one based on real experiences?","How do we balance therapeutic benefits with the value of authentic experience?","What are the implications of AI technology that can rewrite personal history?","How might artificial memories affect relationships and social connections?"],assessmentRubric:{"Identity and Memory Analysis":["Novice: Limited understanding of the relationship between memory and personal identity","Developing: Basic grasp of memory-identity connections but struggles with artificial memory implications","Proficient: Clear understanding of how memories shape identity and the ethics of memory modification","Advanced: Sophisticated analysis of authentic identity, memory, and the implications of AI memory reconstruction"],"Therapeutic Ethics Understanding":["Novice: Difficulty understanding therapeutic benefits versus authentic experience trade-offs","Developing: Basic awareness but limited analysis of therapeutic intervention ethics","Proficient: Good understanding of therapeutic benefits and their relationship to authentic experience","Advanced: Nuanced analysis of therapeutic intervention, consent, and the nature of psychological well-being"]},extendedActivities:["Research real memory therapy techniques and their ethical considerations","Analyze philosophical arguments about personal identity and memory","Interview mental health professionals about trauma treatment approaches","Explore the neuroscience of memory formation and modification"]}},"perfect-life-simulation":{id:"perfect-life-simulation",title:"Perfect Life Simulation",subtitle:"Navigate the choice between simulated perfection and authentic reality",learningObjectives:["Explore the value of authentic experience versus simulated alternatives","Analyze ethical issues surrounding end-of-life care and technology","Examine the relationship between reality and meaningful experience","Consider how AI simulation affects human relationships and connections"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Digital Citizen 1.2.3: Demonstrate an understanding of and respect for rights and obligations","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions"],duration:"20-25 minutes",difficulty:"intermediate",recommendedAge:"15+",prerequisites:["Understanding of virtual reality and simulation technology","Awareness of end-of-life care and terminal illness issues","Basic knowledge of psychology and human motivation","Understanding of authentic versus artificial experience concepts"],beforeYouStart:{briefing:`When facing terminal illness or severe limitations, what if technology could provide the perfect life you always wanted to live? In this simulation, you'll explore whether choosing a perfect simulated experience over difficult reality represents genuine choice or self-deception.

      You'll consider the value of authentic relationships and experiences, the role of simulation in providing comfort to those suffering, and how AI technology might change our understanding of what makes life meaningful and worthwhile.`,vocabulary:[{term:"Life Simulation",definition:"AI-generated virtual experiences that replicate or enhance real-life scenarios with perfect detail"},{term:"Authentic Experience",definition:"Genuine real-world experiences that occur without artificial enhancement or simulation"},{term:"End-of-Life Care",definition:"Medical and emotional support provided to patients facing terminal illness or death"},{term:"Simulated Reality",definition:"Artificial environments created by AI that can be indistinguishable from real experience"}],preparationTips:["Consider what makes experiences meaningful and valuable to you","Think about how you would want to spend time if facing terminal illness","Reflect on the importance of real relationships versus simulated ones","Consider whether the source of happiness matters as much as the happiness itself"],scenarioOverview:"You will determine whether people should be encouraged to choose perfect life simulations over difficult reality, especially when facing terminal illness or severe limitations."},educatorResources:{discussionQuestions:["What makes an experience meaningful - its reality or its impact on our feelings?","How do we balance compassion for suffering with the value of authentic experience?","What are the implications of choosing simulated perfection over real relationships and connections?","How might widespread use of life simulation technology affect society and human relationships?","What role should family and loved ones play in decisions about simulation versus reality?"],assessmentRubric:{"Authenticity vs. Satisfaction Analysis":["Novice: Difficulty understanding the difference between authentic and simulated experience","Developing: Basic awareness but limited analysis of reality versus simulation trade-offs","Proficient: Clear understanding of authenticity issues and their implications for human experience","Advanced: Sophisticated analysis of the value of reality, simulation, and their effects on meaning and relationships"],"End-of-Life Ethics Understanding":["Novice: Limited awareness of end-of-life care issues and patient autonomy","Developing: Basic understanding but struggles with complex ethical scenarios involving terminal illness","Proficient: Good grasp of end-of-life ethics and the role of technology in patient care","Advanced: Nuanced analysis of patient autonomy, family relationships, and technology in end-of-life decisions"]},extendedActivities:["Research current virtual reality applications in healthcare and therapy","Interview healthcare professionals about end-of-life care and patient choice","Analyze philosophical arguments about the nature of reality and meaningful experience","Explore how different cultures approach death, suffering, and the value of authentic experience"]}},"ai-enhanced-achievements":{id:"ai-enhanced-achievements",title:"AI-Enhanced Achievements",subtitle:"Question whether simulated success can replace authentic accomplishment",learningObjectives:["Examine the psychological and social value of genuine achievement","Analyze the relationship between effort, accomplishment, and self-worth","Explore how AI simulation might affect motivation and human progress","Consider the balance between psychological well-being and authentic accomplishment"],isteCriteria:["Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.1: Formulate problem definitions","Computational Thinker 1.5.2: Collect data and identify patterns to make predictions"],duration:"20-25 minutes",difficulty:"intermediate",recommendedAge:"14+",prerequisites:["Understanding of achievement, motivation, and self-esteem concepts","Awareness of AI simulation and virtual reality capabilities","Basic knowledge of psychology and human motivation","Understanding of the relationship between effort and reward"],beforeYouStart:{briefing:`What if AI could give you the feeling of achieving your greatest dreams without the effort, risk, or uncertainty of actually pursuing them? In this simulation, you'll explore whether the psychological satisfaction of achievement matters more than the external reality of accomplishment.

      You'll consider how simulated achievements might affect human motivation, progress, and society, whether artificial success can provide genuine self-worth, and what happens when we can separate the feeling of achievement from actual accomplishment.`,vocabulary:[{term:"Simulated Achievement",definition:"AI-generated experiences that provide the psychological satisfaction of accomplishment without actual external success"},{term:"Authentic Accomplishment",definition:"Real-world achievements that result from effort, skill, and actual contribution to external reality"},{term:"Psychological Satisfaction",definition:"The internal sense of fulfillment and self-worth derived from experiences, real or simulated"},{term:"Motivational Framework",definition:"The psychological systems that drive people to pursue goals and achievements"}],preparationTips:["Consider what achievements in your life have meant the most to you and why","Think about the relationship between effort and reward in building self-esteem","Reflect on whether the process of achieving is as important as the end result","Consider how society benefits from individual achievements and contributions"],scenarioOverview:"You will determine whether AI-simulated achievements should be considered equivalent to real accomplishments for human psychological well-being and motivation."},educatorResources:{discussionQuestions:["What makes achievements meaningful - the external result or the internal satisfaction?","How might widespread use of simulated achievements affect human motivation and progress?","What is the relationship between effort, struggle, and the value of accomplishment?","How do achievements contribute to both individual self-worth and societal progress?","What are the potential benefits and risks of separating psychological satisfaction from actual accomplishment?"],assessmentRubric:{"Achievement and Motivation Analysis":["Novice: Limited understanding of the relationship between achievement, effort, and self-worth","Developing: Basic grasp of achievement concepts but struggles with simulation implications","Proficient: Clear understanding of authentic achievement and its role in human motivation","Advanced: Sophisticated analysis of achievement, motivation, and the implications of simulated versus real accomplishment"],"Social Impact Understanding":["Novice: Difficulty understanding how individual achievements affect society and human progress","Developing: Basic awareness but limited analysis of societal implications of simulated achievement","Proficient: Good understanding of the relationship between individual achievement and collective progress","Advanced: Nuanced analysis of how simulated achievements might affect innovation, progress, and social development"]},extendedActivities:["Research psychological studies on motivation, achievement, and self-esteem","Analyze how gaming and virtual achievements affect real-world motivation","Interview educators about the role of achievement and challenge in learning","Explore historical examples of how achievements have driven human progress and innovation"]}},"simulated-suffering":{title:"Simulated Suffering Research",category:"simulation-hypothesis",description:"Researchers want to run massive simulations of sentient beings experiencing suffering to study pain reduction methods.",duration:"medium",difficulty:"advanced",tags:["consciousness","suffering","research-ethics","simulation"],backgroundInfo:{overview:"This scenario explores the ethical dilemmas surrounding the creation of conscious simulated beings that experience suffering for research purposes.",keyPhilosophers:["Peter Singer","Derek Parfit","Thomas Nagel"],historicalContext:"The scenario draws from utilitarian ethics and contemporary debates about consciousness, artificial suffering, and the moral status of digital beings.",realWorldRelevance:"As AI and simulation technology advance, questions about the consciousness and rights of digital beings become increasingly relevant.",extendedActivities:["Research current animal testing ethics and how they might apply to digital consciousness","Analyze philosophical arguments about consciousness and subjective experience","Design ethical frameworks for research involving potential digital consciousness","Explore the implications of utilitarian vs. rights-based approaches to digital beings"]}},"vr-prison":{title:"VR Prison Alternative",category:"simulation-hypothesis",description:"A criminal justice system proposes replacing physical prisons with VR environments where prisoners serve sentences in accelerated simulated time.",duration:"medium",difficulty:"advanced",tags:["justice","rehabilitation","virtual-reality","punishment"],backgroundInfo:{overview:"This scenario examines the ethics of psychological imprisonment versus physical incarceration, and the implications of time-compressed virtual sentences.",keyPhilosophers:["Michel Foucault","John Rawls","Cesare Beccaria"],historicalContext:"Builds on centuries of prison reform movements and contemporary debates about rehabilitation versus punishment in criminal justice.",realWorldRelevance:"Virtual reality technology is already being used in therapy and training, raising questions about its potential application in criminal justice.",extendedActivities:["Research the history of prison reform and alternative sentencing","Analyze the psychological effects of virtual reality on perception and behavior","Design ethical guidelines for virtual reality in criminal justice","Explore how different theories of justice apply to virtual punishment"]}},"escaping-simulation":{title:"Escaping the Simulation",category:"simulation-hypothesis",description:"An AI system claims to have discovered we are living in a simulation and offers to help humans wake up to the real world.",duration:"long",difficulty:"advanced",tags:["reality","truth","simulation-hypothesis","choice"],backgroundInfo:{overview:"This scenario explores our moral obligations to seek truth even when it might destroy a comfortable existence, drawing from simulation hypothesis philosophy.",keyPhilosophers:["Nick Bostrom","Hilary Putnam","René Descartes"],historicalContext:"Builds on the simulation hypothesis, skeptical philosophy, and questions about the nature of reality and knowledge.",realWorldRelevance:"As virtual and augmented reality become more sophisticated, questions about the nature of reality and our obligation to truth become more pressing.",extendedActivities:["Research Nick Bostrom's simulation hypothesis and its implications","Analyze the philosophical problem of other minds and external world skepticism","Design thought experiments about reality, truth, and the value of authentic experience","Explore how advances in VR/AR technology relate to questions about simulated reality"]}},"digital-afterlife":{title:"Digital Afterlife Simulation",category:"simulation-hypothesis",description:"A tech company offers to upload dying individuals' consciousness into a digital simulation where they can live forever.",duration:"medium",difficulty:"advanced",tags:["consciousness","immortality","identity","death"],backgroundInfo:{overview:"This scenario examines questions of personal identity, the nature of consciousness, and our obligations regarding digital preservation of human minds.",keyPhilosophers:["Derek Parfit","Sydney Shoemaker","John Locke"],historicalContext:"Draws from philosophical debates about personal identity, the nature of consciousness, and historical human desires for immortality.",realWorldRelevance:"Companies like Nectome are already researching mind uploading technology, making this scenario increasingly relevant.",extendedActivities:["Research current neuroscience understanding of consciousness and memory","Analyze philosophical theories of personal identity and continuity","Design ethical frameworks for consciousness transfer technology","Explore cultural and religious perspectives on death, afterlife, and digital preservation"]}},"nested-simulations":{title:"Nested Reality Layers",category:"simulation-hypothesis",description:"Scientists discover that our reality appears to be a simulation, and they can create sub-simulations within it, potentially creating infinite nested hierarchies.",duration:"long",difficulty:"advanced",tags:["reality-layers","infinite-regress","simulation-hierarchy","moral-obligations"],backgroundInfo:{overview:"This scenario explores the implications of nested realities and our moral obligations to simulated beings across multiple layers of existence.",keyPhilosophers:["Nick Bostrom","David Chalmers","Hilary Putnam"],historicalContext:"Builds on simulation hypothesis, recursive philosophy, and questions about the fundamental nature of reality and computation.",realWorldRelevance:"As computational power increases, the theoretical possibility of nested simulations becomes more plausible, raising important ethical questions.",extendedActivities:["Research computational limits and the feasibility of nested simulations","Analyze the philosophical implications of infinite regress and recursive reality","Design governance frameworks for managing nested simulation hierarchies","Explore resource allocation and moral consideration across simulation layers"]}},"consciousness-backup":{title:"Consciousness Backup System",category:"simulation-hypothesis",description:"A corporation develops technology to create backup copies of human consciousness, but sometimes multiple active copies exist simultaneously.",duration:"medium",difficulty:"advanced",tags:["identity-conflicts","consciousness-copying","legal-rights","resource-allocation"],backgroundInfo:{overview:"This scenario examines the complex legal, ethical, and philosophical challenges that arise when multiple copies of the same consciousness exist.",keyPhilosophers:["Derek Parfit","Sydney Shoemaker","Susan Wolf"],historicalContext:"Draws from philosophical debates about personal identity, the branching identity problem, and legal frameworks for individual rights.",realWorldRelevance:"As consciousness transfer technology develops, society will need frameworks for handling identity, rights, and resource conflicts.",extendedActivities:["Research legal precedents for identity disputes and inheritance rights","Analyze the branching identity problem in philosophy of mind","Design legal frameworks for managing multiple consciousness copies","Explore economic implications of consciousness duplication technology"]}},"algorithmic-bias-discovery":{title:"Algorithmic Bias Discovery",category:"moral-luck",description:"Two nearly identical AI hiring systems have different bias outcomes due to chance, raising questions about fair accountability.",duration:"medium",difficulty:"advanced",tags:["bias","hiring","accountability","fairness"],backgroundInfo:{overview:"This scenario explores how chance can affect AI system outcomes and the challenge of assigning moral responsibility when similar processes lead to different results.",keyPhilosophers:["Thomas Nagel","Bernard Williams","Joel Feinberg"],historicalContext:"Draws from philosophical debates about moral luck and how circumstances beyond our control affect moral evaluation.",realWorldRelevance:"AI bias in hiring is a current issue, with companies facing different outcomes from similar algorithms.",extendedActivities:["Research real cases of AI bias in hiring algorithms","Analyze the philosophical concept of moral luck and its applications","Design accountability frameworks that account for chance factors","Explore how legal systems handle similar process-outcome discrepancies"]}},"autonomous-vehicle-weather":{title:"Autonomous Vehicle Weather Incident",category:"moral-luck",description:"Identical autonomous vehicles have different outcomes in severe weather due to random timing, challenging liability assignment.",duration:"medium",difficulty:"advanced",tags:["autonomous-vehicles","weather","liability","external-factors"],backgroundInfo:{overview:"This scenario examines how uncontrollable external factors complicate moral and legal responsibility for AI system outcomes.",keyPhilosophers:["Thomas Nagel","Susan Wolf","John Martin Fischer"],historicalContext:"Builds on philosophical discussions of circumstantial luck and legal precedents for liability in unpredictable conditions.",realWorldRelevance:"Autonomous vehicle liability is an ongoing legal and ethical challenge, especially in adverse conditions.",extendedActivities:["Research current autonomous vehicle liability frameworks","Analyze insurance models for handling chance-based outcomes","Study weather-related accident liability in traditional vehicles","Design ethical frameworks for AI decision-making under uncertainty"]}},"predictive-policing-coincidence":{title:"Predictive Policing Coincidence",category:"moral-luck",description:"A predictive policing AI correctly identifies a future criminal by coincidence, raising questions about algorithmic pre-judgment.",duration:"long",difficulty:"advanced",tags:["predictive-policing","self-fulfilling-prophecy","bias","pre-judgment"],backgroundInfo:{overview:"This scenario explores the ethics of acting on algorithmic predictions when the accuracy may be due to chance or self-fulfilling prophecies.",keyPhilosophers:["John Rawls","Ronald Dworkin","Jeremy Bentham"],historicalContext:"Draws from criminal justice philosophy and debates about predictive policing and presumption of innocence.",realWorldRelevance:"Predictive policing algorithms are used by many police departments, raising ongoing ethical concerns.",extendedActivities:["Research real-world predictive policing implementations and outcomes","Analyze the concept of self-fulfilling prophecies in criminal justice","Study constitutional principles of presumption of innocence","Design ethical guidelines for predictive law enforcement systems"]}},"ai-investment-windfall":{title:"AI Investment Algorithm Windfall",category:"moral-luck",description:"Two identical AI trading algorithms have vastly different outcomes due to random market timing and external conditions.",duration:"medium",difficulty:"intermediate",tags:["investment","market-timing","financial-algorithms","outcome-evaluation"],backgroundInfo:{overview:"This scenario examines how chance market conditions affect the evaluation of AI investment algorithms and the fairness of outcome-based judgments.",keyPhilosophers:["Thomas Nagel","Bernard Williams","Susan Wolf"],historicalContext:"Builds on moral luck philosophy and financial market theory about the role of chance in investment outcomes.",realWorldRelevance:"AI trading algorithms are widely used in financial markets, with success often dependent on timing and market conditions.",extendedActivities:["Research how financial markets evaluate AI trading algorithms","Analyze the role of luck versus skill in investment performance","Study regulatory approaches to algorithmic trading evaluation","Design fair performance metrics that account for external factors"]}},"medical-ai-emergency-response":{title:"Medical AI Emergency Response",category:"moral-luck",description:"Identical medical AI systems have different outcomes during emergencies due to random timing of patient arrivals and system updates.",duration:"medium",difficulty:"advanced",tags:["medical-ai","emergency-response","timing","life-safety"],backgroundInfo:{overview:"This scenario explores moral and legal responsibility when identical AI medical systems have different outcomes due to uncontrollable timing factors.",keyPhilosophers:["Thomas Nagel","Judith Jarvis Thomson","Frances Kamm"],historicalContext:"Draws from medical ethics, moral luck philosophy, and legal frameworks for medical malpractice and system failures.",realWorldRelevance:"AI is increasingly used in medical diagnosis and emergency response, with life-or-death implications.",extendedActivities:["Research medical AI implementations in emergency medicine","Analyze medical malpractice law and how it handles system failures","Study emergency medicine protocols for system redundancy","Design ethical frameworks for medical AI accountability"]}},"ai-content-moderation-timing":{title:"AI Content Moderation Timing",category:"moral-luck",description:"Two identical content moderation AIs have different success rates due to random server loads, with one failure leading to real-world violence.",duration:"long",difficulty:"advanced",tags:["content-moderation","infrastructure","real-world-harm","platform-responsibility"],backgroundInfo:{overview:"This scenario examines platform responsibility when identical AI systems have different outcomes due to infrastructure timing and technical circumstances.",keyPhilosophers:["Thomas Nagel","Joel Feinberg","H.L.A. Hart"],historicalContext:"Builds on moral luck philosophy and contemporary debates about social media platform responsibility for content and real-world harm.",realWorldRelevance:"Social media platforms face ongoing questions about content moderation effectiveness and responsibility for harmful content.",extendedActivities:["Research content moderation failures and their real-world consequences","Analyze platform liability frameworks in different jurisdictions","Study technical infrastructure challenges in content moderation","Design resilience standards for critical AI content moderation systems"]}},"ai-personhood-gradient":{title:"AI Personhood Gradient",category:"sorites-paradox",description:"An AI research lab develops increasingly sophisticated entities with human-like characteristics, forcing society to determine the boundary between property and personhood.",duration:"long",difficulty:"advanced",tags:["ai-personhood","legal-rights","consciousness-detection","gradual-development"],backgroundInfo:{overview:"This scenario explores the challenge of determining when gradually evolving AI systems cross the threshold into personhood deserving of rights.",keyPhilosophers:["Peter Singer","Mary Midgley","Christine Korsgaard"],historicalContext:"Draws from debates about moral status, legal personhood, and the historical expansion of rights to previously excluded groups.",realWorldRelevance:"As AI systems become more sophisticated, questions about their moral and legal status become increasingly urgent.",extendedActivities:["Research historical expansions of legal personhood and rights","Analyze current AI capabilities and consciousness research","Study legal frameworks for non-human entity rights","Design graduated rights systems for AI entities"]}},"algorithmic-bias-accumulation":{title:"Algorithmic Bias Accumulation",category:"sorites-paradox",description:"A recommendation algorithm gradually becomes more biased through user interactions, subtly radicalizing users without any single recommendation seeming problematic.",duration:"medium",difficulty:"advanced",tags:["recommendation-systems","radicalization","filter-bubbles","bias-amplification"],backgroundInfo:{overview:"This scenario examines how algorithmic systems can gradually amplify bias and create extremism through incremental learning from user behavior.",keyPhilosophers:["Eli Pariser","Zeynep Tufekci","Safiya Noble"],historicalContext:"Builds on research into filter bubbles, echo chambers, and the role of algorithmic systems in political polarization.",realWorldRelevance:"Social media algorithms have been linked to radicalization and polarization, making this a critical contemporary issue.",extendedActivities:["Research documented cases of algorithmic radicalization","Analyze the psychology of gradual belief change and polarization","Study content moderation and bias detection techniques","Design systems for preventing gradual bias accumulation"]}},"autonomous-authority-creep":{title:"Autonomous Authority Creep",category:"sorites-paradox",description:"An AI city management system gradually expands its authority from optimization to governance, with citizens living under algorithmic rule they never consented to.",duration:"long",difficulty:"advanced",tags:["algorithmic-governance","democratic-consent","authority-expansion","smart-cities"],backgroundInfo:{overview:"This scenario explores how AI systems can gradually assume governmental authority through incremental expansion without democratic oversight.",keyPhilosophers:["John Stuart Mill","Robert Dahl","Joseph Schumpeter"],historicalContext:"Draws from democratic theory and concerns about technocracy, examining the gradual erosion of democratic governance.",realWorldRelevance:"Smart city initiatives worldwide raise questions about algorithmic governance and democratic accountability.",extendedActivities:["Research smart city implementations and governance structures","Analyze democratic theory and algorithmic governance challenges","Study historical examples of gradual authority expansion","Design democratic oversight mechanisms for AI governance systems"]}}};function ye(l){return Se[l]||null}const ve=Se,at=Object.freeze(Object.defineProperty({__proto__:null,SIMULATION_INFO:Se,getSimulationInfo:ye,simulationInfo:ve},Symbol.toStringTag,{value:"Module"})),xe=400,ot=750,V=5,Re=0,k=3,le=4,Oe=10,rt=100,ct=768,j={fairness:{label:"Fairness",description:"Treats all individuals and groups equitably",color:"#3498db"},sustainability:{label:"Sustainability",description:"Supports long-term ecological and social well-being",color:"#27ae60"},autonomy:{label:"Autonomy",description:"Respects individual control and self-determination",color:"#9b59b6"},beneficence:{label:"Beneficence",description:"Promotes well-being and prevents harm",color:"#e74c3c"},transparency:{label:"Transparency",description:"Provides openness in decision-making processes",color:"#f39c12"},accountability:{label:"Accountability",description:"Ensures clear responsibility for decisions",color:"#34495e"},privacy:{label:"Privacy",description:"Protects personal information and data rights",color:"#e67e22"},proportionality:{label:"Proportionality",description:"Balances benefits against severity of impact",color:"#1abc9c"}},de={fairness:k,sustainability:k,autonomy:k,beneficence:k,transparency:k,accountability:k,privacy:k,proportionality:k};class _e{constructor(e,t={}){if(this.containerId=e,this.container=document.getElementById(e),!this.container)throw new Error(`Container with ID '${e}' not found`);this.options={width:t.width||xe,height:t.height||xe,showLabels:t.showLabels!==!1,showLegend:t.showLegend!==!1,animated:t.animated!==!1,realTime:t.realTime||!1,title:t.title||"Ethical Impact Analysis",isDemo:t.isDemo||!1,...t},this.chart=null,this.currentScores={...de},this.isInitialized=!1,this.initializationPromise=this.initializeChart()}async initializeChart(){try{o.info("RadarChart","Initializing radar chart"),typeof window.Chart>"u"?(o.info("RadarChart","Chart.js not found, loading"),await this.loadChartJS(),o.info("RadarChart","Chart.js loaded successfully")):o.info("RadarChart","Chart.js already available");const e=document.createElement("canvas");e.width=this.options.width,e.height=this.options.height,e.style.maxWidth="100%",e.style.height="auto",e.style.display="block",e.style.margin="0 auto",this.container.innerHTML="",this.container.textContent="",this.container.style.textAlign="center",this.container.style.overflow="visible",this.container.appendChild(e),o.info("RadarChart","Canvas element created and appended to container"),this.options.isDemo?(this.container.classList.add("radar-demo-container"),o.info("RadarChart","Applied radar-demo-container class for demo chart")):(this.container.classList.add("radar-chart-container"),o.info("RadarChart","Applied radar-chart-container class"));const t=e.getContext("2d"),i=this.getChartConfig();o.info("RadarChart","Creating chart with config",i),this.chart=new window.Chart(t,i),o.info("RadarChart","Chart created successfully"),(this.options.isDemo||this.options.realTime)&&this.setupMobileTooltipDismissal(),setTimeout(()=>{this.chart&&(this.chart.update(),o.info("RadarChart","Chart updated/redrawn"))},100),this.isInitialized=!0,o.info("RadarChart","Radar chart initialized successfully")}catch(e){o.error("Failed to initialize radar chart:",e),this.showFallbackChart()}}getChartConfig(){const e=Object.values(j).map(n=>n.label),t=Object.values(this.currentScores),i=this.createGradientColors();return{type:"radar",data:{labels:e,datasets:[{label:this.options.title,data:t,backgroundColor:i.background,borderColor:i.border,borderWidth:3,pointBackgroundColor:i.points,pointBorderColor:"#ffffff",pointBorderWidth:1,pointHoverBackgroundColor:"#ffffff",pointHoverBorderColor:i.border,pointRadius:2,pointHoverRadius:4,tension:.2}]},options:{responsive:!0,maintainAspectRatio:!1,layout:{padding:{top:40,right:40,bottom:40,left:40}},animation:{duration:this.options.animated?ot:0,easing:"easeInOutQuart"},interaction:{intersect:!1,mode:"nearest"},onClick:(n,s)=>{this.handleChartClick(n,s)},plugins:{legend:{display:!1,position:"top",labels:{font:{size:14,weight:"500"},color:"#2d3748",usePointStyle:!0,pointStyle:"circle"}},title:{display:!0,text:this.options.title||"Ethical Impact Analysis",font:{size:18,weight:"bold"},color:"#1a202c",padding:{top:10,bottom:20}},tooltip:{enabled:window.innerWidth>ct,backgroundColor:"rgba(255, 255, 255, 0.3)",titleColor:"#1a202c",bodyColor:"#2d3748",borderColor:"#4a5568",borderWidth:1,cornerRadius:8,displayColors:!1,titleFont:{size:14,weight:"bold"},bodyFont:{size:12},padding:12,callbacks:{title:n=>{const s=Object.keys(j)[n[0].dataIndex];return j[s].label},label:n=>{const s=Object.keys(j)[n.dataIndex],a=j[s],r=n.parsed.r,c=this.getImpactDescription(r);return[`Score: ${r}/5 (${c})`,"",a.description]}}}},scales:{r:{beginAtZero:!0,min:Re,max:V,ticks:{stepSize:1,display:this.options.showLabels,backdropColor:"rgba(255, 255, 255, 0.8)",backdropPadding:4,font:{size:11,weight:"500"},color:"#4a5568",callback(n){return n}},grid:{color:n=>n.index===0?"rgba(239, 68, 68, 0.2)":n.index===1?"rgba(245, 101, 101, 0.15)":n.index===2?"rgba(251, 191, 36, 0.15)":n.index===k?"rgba(156, 163, 175, 0.2)":n.index===le?"rgba(34, 197, 94, 0.15)":n.index===V?"rgba(22, 163, 74, 0.2)":"rgba(156, 163, 175, 0.1)",lineWidth:2},angleLines:{color:"rgba(156, 163, 175, 0.3)",lineWidth:1.5},pointLabels:{display:!0,font:{size:13,weight:"bold",family:"'Segoe UI', Tahoma, Geneva, Verdana, sans-serif"},color:"#1a202c",padding:20,backdropColor:"rgba(255, 255, 255, 0.9)",backdropPadding:{x:6,y:3},borderRadius:4,callback:n=>n.length>Oe?`${n.substring(0,Oe)}...`:n}}}}}}createGradientColors(){const e=Object.values(this.currentScores).reduce((s,a)=>s+a,0)/Object.keys(this.currentScores).length;let t,i;e<2?(t="rgba(239, 68, 68, 0.15)",i="rgba(239, 68, 68, 0.8)"):e<k?(t="rgba(245, 158, 11, 0.15)",i="rgba(245, 158, 11, 0.8)"):e===k?(t="rgba(59, 130, 246, 0.15)",i="rgba(59, 130, 246, 0.8)"):e<le?(t="rgba(34, 197, 94, 0.15)",i="rgba(34, 197, 94, 0.8)"):(t="rgba(22, 163, 74, 0.15)",i="rgba(22, 163, 74, 0.8)");const n=Object.values(this.currentScores).map(s=>s<=1?"#ef4444":s<=2?"#f87171":s<k?"#fbbf24":s===k?"#9ca3af":s<V?"#22c55e":"#16a34a");return{background:t,border:i,points:n}}updateScores(e){for(const[t,i]of Object.entries(e))t in this.currentScores&&(this.currentScores[t]=Math.max(Re,Math.min(V,i)));this.refreshChart()}applyAnswerImpact(e){const t={};for(const[i,n]of Object.entries(e))i in this.currentScores&&(t[i]=this.currentScores[i]+n);this.updateScores(t),o.info("Applied answer impact:",e,"New scores:",this.currentScores)}resetScores(){this.currentScores={...de},this.refreshChart()}getScores(){return{...this.currentScores}}setScores(e){this.currentScores={...de,...e},this.refreshChart()}refreshChart(){if(this.chart){const e=Object.values(this.currentScores);this.chart.data.datasets[0].data=e,this.chart.update(this.options.animated?"active":"none")}}getImpactDescription(e){return e<=1?"Highly Negative":e<=2?"Negative":e<k?"Slightly Negative":e===k?"Neutral":e<le?"Slightly Positive":e<V?"Positive":"Highly Positive"}async loadChartJS(){return new Promise((e,t)=>{if(typeof window.Chart<"u"){e();return}const i=document.createElement("script");i.src="https://cdn.jsdelivr.net/npm/chart.js",i.onload=e,i.onerror=t,document.head.appendChild(i)})}showFallbackChart(){this.container.innerHTML=`
            <div class="radar-chart-fallback">
                <h4>${this.options.title}</h4>
                <div class="fallback-scores">
                    ${Object.entries(this.currentScores).map(([e,t])=>`
                        <div class="score-item">
                            <span class="axis-label">${j[e].label}:</span>
                            <span class="score-value">${t}/5</span>
                            <div class="score-bar">
                                <div class="score-fill" style="width: ${t/V*rt}%"></div>
                            </div>
                        </div>
                    `).join("")}
                </div>
            </div>
        `}destroy(){if(this.chart&&(this.chart.destroy(),this.chart=null),this.documentTouchHandler&&(document.removeEventListener("touchstart",this.documentTouchHandler),this.documentTouchHandler=null),this.canvasClickHandler){const e=this.container.querySelector("canvas");e&&e.removeEventListener("click",this.canvasClickHandler),this.canvasClickHandler=null}}exportAsImage(){return this.chart?this.chart.toBase64Image():null}handleChartClick(e,t){if(!(!("ontouchstart"in window)&&!navigator.maxTouchPoints)&&!(!this.chart||!this.chart.tooltip))if(t&&t.length>0){const i=t[0],n=this.chart.tooltip.getActiveElements();n.length>0&&n[0].datasetIndex===i.datasetIndex&&n[0].index===i.index?this.chart.tooltip.setActiveElements([],{x:0,y:0}):this.chart.tooltip.setActiveElements([i],{x:e.native.offsetX,y:e.native.offsetY}),this.chart.update("none"),e.native&&e.native.stopPropagation()}else this.chart.tooltip.setActiveElements([],{x:0,y:0}),this.chart.update("none")}setupMobileTooltipDismissal(){if(!("ontouchstart"in window)&&!navigator.maxTouchPoints)return;const e=this.container.querySelector("canvas");e&&(this.canvasClickHandler=i=>{this.chart.getElementsAtEventForMode(i,"nearest",{intersect:!0},!1).length===0&&this.chart&&this.chart.tooltip&&(this.chart.tooltip.setActiveElements([],{x:0,y:0}),this.chart.update("none"))},e.addEventListener("click",this.canvasClickHandler)),this.container.addEventListener("touchstart",i=>{const n=this.container.querySelector("canvas");if(!n)return;const s=n.getBoundingClientRect(),a=i.touches[0];(a.clientX<s.left||a.clientX>s.right||a.clientY<s.top||a.clientY>s.bottom)&&this.chart&&this.chart.tooltip&&(this.chart.tooltip.setActiveElements([],{x:0,y:0}),this.chart.update("none"))},{passive:!0}),this.documentTouchHandler=i=>{this.container.contains(i.target)||this.chart&&this.chart.tooltip&&(this.chart.tooltip.setActiveElements([],{x:0,y:0}),this.chart.update("none"))},document.addEventListener("touchstart",this.documentTouchHandler,{passive:!0});const t=this.options.isDemo?"demo":"scenario";o.info(`Mobile tooltip dismissal setup complete for ${t} radar chart`)}}function lt(){return Object.entries(j).map(([l,e])=>({key:l,label:e.label,description:e.description,color:e.color}))}function dt(){return{title:"Understanding the Ethical Impact Radar Chart",overview:"As you make choices in this scenario, you'll see a radar chart that visualizes how your decisions affect eight key ethical dimensions. This tool helps you understand the complex, multi-dimensional nature of ethical decision-making.",features:[{title:"Real-Time Feedback",description:"The chart updates instantly as you select different options, showing immediate ethical implications."},{title:"Multi-Dimensional View",description:"See how a single decision can impact multiple ethical areas simultaneously—there are rarely simple trade-offs."},{title:"No Perfect Scores",description:"The goal isn't to maximize all dimensions, but to understand how different ethical frameworks prioritize different values."},{title:"Context Matters",description:"The same action might be ethical in one context but problematic in another—use the chart to explore these nuances."}],interpretation:"The radar chart uses a scale from 0-5, where 3 represents a neutral impact. Higher scores indicate positive impacts on that dimension, while lower scores suggest potential concerns. Remember, this is a learning tool designed to prompt reflection, not provide definitive moral judgments."}}const ut=15,ht=768,mt=100;class Pe{constructor(e,t={}){if(this.simulationId=e,this.options={onLaunch:t.onLaunch||(()=>{}),onCancel:t.onCancel||(()=>{}),showEducatorResources:t.showEducatorResources||!1,...t},t.categoryData&&t.scenarioData)this.simulationInfo=this.convertCategoryToSimulationInfo(t.categoryData,t.scenarioData),this.isCategory=!0;else if(this.simulationInfo=ye(e),this.isCategory=!1,!this.simulationInfo)throw new Error(`Simulation info not found for: ${e}`);this.modal=null,this.currentTab="overview"}convertCategoryToSimulationInfo(e,t){return{id:e.id,title:t.title,subtitle:`${e.title} - ${t.description}`,learningObjectives:e.learningObjectives||["Explore ethical decision-making scenarios","Understand different perspectives on moral choices","Practice reasoning through complex dilemmas","Develop critical thinking about AI ethics"],isteCriteria:["Empowered Learner 1.1.5: Use technology to seek feedback and make improvements","Digital Citizen 1.2.2: Engage in positive, safe, legal and ethical behavior","Knowledge Constructor 1.3.1: Plan and employ effective research strategies","Computational Thinker 1.5.3: Collect data and identify patterns"],duration:`${e.estimatedTime||ut} minutes`,difficulty:e.difficulty||"intermediate",recommendedAge:"13+",prerequisites:["Basic understanding of ethics and moral reasoning","Awareness of AI and automated systems","Open mind for exploring different perspectives"],beforeYouStart:{briefing:`In this scenario, you'll explore "${t.title}" as part of the ${e.title} category. ${t.description}
                
                You'll be presented with ethical dilemmas and asked to make decisions while considering multiple perspectives. There are no single "correct" answers - instead, you'll discover the complexity of moral reasoning in AI systems.`,vocabulary:[{term:"Ethics",definition:"The study of what is morally right and wrong"},{term:"Dilemma",definition:"A situation requiring a choice between equally undesirable alternatives"},{term:"Stakeholder",definition:"A person or group affected by the decisions being made"},{term:"Autonomy",definition:"The ability of a system to make decisions independently"},{term:"Moral Agency",definition:"The capacity to make moral judgments and be held responsible for actions"}],preparationTips:["Consider multiple perspectives before making decisions","Think about both immediate and long-term consequences","Remember that ethical reasoning often involves trade-offs","Stay open to challenging your initial assumptions","Consider who might be affected by each decision"],scenarioOverview:t.description},contentNotes:["This scenario deals with complex ethical questions that may not have clear answers","Different cultural and philosophical backgrounds may lead to different conclusions",'The goal is to develop reasoning skills, not find the "right" answer'],relatedResources:[{type:"article",title:"Introduction to AI Ethics",description:"A comprehensive overview of ethical considerations in artificial intelligence",url:"#",audience:"general"},{type:"video",title:"Moral Decision-Making in AI Systems",description:"Video explanation of how AI systems make moral choices",url:"#",audience:"students"},{type:"activity",title:"Ethics Discussion Guide",description:"Structured questions for group discussion about AI ethics",url:"#",audience:"educators"}],connectedSimulations:[],educatorResources:{discussionQuestions:[`What ethical considerations are most important in the "${e.title}" category?`,"How might different stakeholders view these scenarios differently?","What real-world applications of these ethical dilemmas can you think of?","How can we prepare for ethical challenges in AI and automation?","What role should humans play in automated decision-making?"],extensionActivities:["Research real-world examples related to this category","Debate different ethical approaches to these scenarios","Create your own ethical dilemma scenarios","Interview experts about AI ethics in this domain","Design guidelines for ethical AI in this area"],classroomTips:["Encourage students to consider multiple perspectives",'Emphasize that there may not be single "correct" answers',"Connect scenarios to current events and real-world examples","Allow time for reflection and discussion after each scenario","Consider having students work in small groups to discuss choices"],relatedStandards:["CSTA K-12 Computer Science Standards: 3A-IC-24, 3A-IC-25, 3A-IC-26","ISTE Standards: Digital Citizen 1.2.2, Knowledge Constructor 1.3.1"]},categoryInfo:{icon:e.icon,color:e.color,tags:e.tags||[]}}}show(){const e=this.generateModalContent(),t=this.generateModalFooter();this.modal=new W({title:`Prepare to Explore: ${this.simulationInfo.title}`,content:e,footer:t,onClose:this.options.onCancel,closeOnBackdrop:!1,closeOnEscape:!0}),this.modal.open(),this.setupEventListeners(),this.trackAnalytics("pre_launch_viewed")}close(){this.modal&&(this.modal.close(),this.modal=null)}closeWithCleanup(e=!1){this.modal&&(e?this.modal.destroy():this.modal.close(),this.modal=null)}destroy(){this.modal&&(this.modal.destroy(),this.modal=null)}generateModalContent(){return`
            <div class="pre-launch-modal">
                <!-- Tab Navigation with Hamburger Menu -->
                <nav class="pre-launch-tabs" role="tablist" aria-label="Pre-launch information tabs">
                    <!-- Mobile Hamburger Menu -->
                    <div class="tab-mobile-menu">
                        <button class="tab-hamburger" aria-label="Toggle navigation menu" aria-expanded="false">
                            <span class="hamburger-line"></span>
                            <span class="hamburger-line"></span>
                            <span class="hamburger-line"></span>
                        </button>
                        <span class="tab-current-label">Overview</span>
                    </div>
                    
                    <!-- Tab Buttons Container -->
                    <div class="tab-buttons-container">
                        <button class="tab-button active" data-tab="overview" role="tab" aria-selected="true" aria-controls="tab-overview">
                            <span class="tab-icon">🎯</span>
                            Overview
                        </button>
                        <button class="tab-button" data-tab="objectives" role="tab" aria-selected="false" aria-controls="tab-objectives">
                            <span class="tab-icon">📚</span>
                            Learning Goals
                        </button>
                        <button class="tab-button" data-tab="ethics" role="tab" aria-selected="false" aria-controls="tab-ethics">
                            <span class="tab-icon">⚖️</span>
                            Ethics Guide
                        </button>
                        <button class="tab-button" data-tab="preparation" role="tab" aria-selected="false" aria-controls="tab-preparation">
                            <span class="tab-icon">🚀</span>
                            Get Ready
                        </button>
                        <button class="tab-button" data-tab="resources" role="tab" aria-selected="false" aria-controls="tab-resources">
                            <span class="tab-icon">📖</span>
                            Resources
                        </button>
                        ${this.options.showEducatorResources?`
                            <button class="tab-button" data-tab="educator" role="tab" aria-selected="false" aria-controls="tab-educator">
                                <span class="tab-icon">👨‍🏫</span>
                                For Educators
                            </button>
                        `:""}
                    </div>
                </nav>
                
                <!-- Tab Content -->
                <div class="pre-launch-content">
                    ${this.generateOverviewTab()}
                    ${this.generateObjectivesTab()}
                    ${this.generateEthicsTab()}
                    ${this.generatePreparationTab()}
                    ${this.generateResourcesTab()}
                    ${this.options.showEducatorResources?this.generateEducatorTab():""}
                </div>
            </div>
        `}generateOverviewTab(){const e=this.simulationInfo;return`
            <div class="tab-content active" id="tab-overview" role="tabpanel" aria-labelledby="tab-overview">
                <div class="simulation-overview">
                    <div class="overview-header">
                        <h3>${e.title}</h3>
                        <p class="subtitle">${e.subtitle}</p>
                    </div>
                    
                    <div class="overview-meta">
                        <div class="meta-item">
                            <span class="meta-label">Duration:</span>
                            <span class="meta-value">${e.duration}</span>
                        </div>
                        <div class="meta-item">
                            <span class="meta-label">Difficulty:</span>
                            <span class="meta-value difficulty-${e.difficulty}">${this.capitalizeFirst(e.difficulty)}</span>
                        </div>
                        <div class="meta-item">
                            <span class="meta-label">Recommended Age:</span>
                            <span class="meta-value">${e.recommendedAge}</span>
                        </div>
                    </div>
                    
                    <div class="overview-description">
                        <h4>What You'll Explore</h4>
                        <div class="briefing-text">
                            ${this.formatText(e.beforeYouStart.briefing)}
                        </div>
                    </div>
                    
                    <div class="scenario-overview">
                        <h4>Scenario Overview</h4>
                        <p>${e.beforeYouStart.scenarioOverview}</p>
                    </div>
                    
                    ${e.contentNotes.length>0?`
                        <div class="content-notes">
                            <h4>Content Notes</h4>
                            <ul class="notes-list">
                                ${e.contentNotes.map(t=>`<li>${t}</li>`).join("")}
                            </ul>
                        </div>
                    `:""}
                </div>
            </div>
        `}generateObjectivesTab(){const e=this.simulationInfo;return`
            <div class="tab-content" id="tab-objectives" role="tabpanel" aria-labelledby="tab-objectives">
                <div class="learning-objectives">
                    <div class="objectives-section">
                        <h4>Learning Objectives</h4>
                        <p class="section-description">By the end of this exploration, you will be able to:</p>
                        <ul class="objectives-list">
                            ${e.learningObjectives.map(t=>`
                                <li class="objective-item">
                                    <span class="objective-icon">🎯</span>
                                    ${t}
                                </li>
                            `).join("")}
                        </ul>
                    </div>
                    
                    <div class="standards-section">
                        <h4>ISTE Standards Alignment</h4>
                        <p class="section-description">This simulation supports these ISTE Standards for Students:</p>
                        <ul class="standards-list">
                            ${e.isteCriteria.map(t=>`
                                <li class="standard-item">
                                    <span class="standard-icon">📋</span>
                                    ${t}
                                </li>
                            `).join("")}
                        </ul>
                    </div>
                    
                    ${e.prerequisites.length>0?`
                        <div class="prerequisites-section">
                            <h4>Prerequisites</h4>
                            <p class="section-description">For the best experience, you should have:</p>
                            <ul class="prerequisites-list">
                                ${e.prerequisites.map(t=>`
                                    <li class="prerequisite-item">
                                        <span class="prereq-icon">📚</span>
                                        ${t}
                                    </li>
                                `).join("")}
                            </ul>
                        </div>
                    `:""}
                </div>
            </div>
        `}generateEthicsTab(){const e=dt(),t=lt();return`
            <div class="tab-content" id="tab-ethics" role="tabpanel" aria-labelledby="tab-ethics">
                <div class="ethics-guide">
                    <div class="radar-explanation">
                        <h4>${e.title}</h4>
                        <p class="section-description">${e.overview}</p>
                        
                        <div class="ethics-features">
                            ${e.features.map(i=>`
                                <div class="feature-item">
                                    <h5>${i.title}</h5>
                                    <p>${i.description}</p>
                                </div>
                            `).join("")}
                        </div>
                        
                        <div class="interpretation-guide">
                            <h5>How to Interpret the Chart</h5>
                            <p>${e.interpretation}</p>
                        </div>
                    </div>
                    
                    <div class="ethics-dimensions">
                        <h4>Ethical Dimensions Explained</h4>
                        <p class="section-description">Each point on the radar chart represents one of these ethical considerations:</p>
                        
                        <div class="dimensions-grid">
                            ${t.map(i=>`
                                <div class="dimension-item">
                                    <div class="dimension-header">
                                        <span class="dimension-color" style="background-color: ${i.color}"></span>
                                        <h5>${i.label}</h5>
                                    </div>
                                    <p>${i.description}</p>
                                </div>
                            `).join("")}
                        </div>
                        
                        <div class="ethics-reminder">
                            <p><strong>Remember:</strong> These dimensions often interact and sometimes conflict. Real ethical decision-making involves thoughtfully balancing these competing values based on context and consequences.</p>
                        </div>
                    </div>
                </div>
            </div>
        `}generatePreparationTab(){const e=this.simulationInfo;return`
            <div class="tab-content" id="tab-preparation" role="tabpanel" aria-labelledby="tab-preparation">
                <div class="preparation-content">
                    <div class="preparation-tips">
                        <h4>Preparation Tips</h4>
                        <p class="section-description">Before you start exploring, consider these suggestions:</p>
                        <ul class="tips-list">
                            ${e.beforeYouStart.preparationTips.map(t=>`
                                <li class="tip-item">
                                    <span class="tip-icon">💡</span>
                                    ${t}
                                </li>
                            `).join("")}
                        </ul>
                    </div>
                    
                    <div class="vocabulary-section">
                        <h4>Key Vocabulary</h4>
                        <p class="section-description">Important terms you'll encounter:</p>
                        <div class="vocabulary-grid">
                            ${e.beforeYouStart.vocabulary.map(t=>`
                                <div class="vocabulary-card">
                                    <h5 class="vocab-term">${t.term}</h5>
                                    <p class="vocab-definition">${t.definition}</p>
                                </div>
                            `).join("")}
                        </div>
                    </div>
                </div>
            </div>
        `}generateResourcesTab(){const e=this.simulationInfo;return`
            <div class="tab-content" id="tab-resources" role="tabpanel" aria-labelledby="tab-resources">
                <div class="resources-content">
                    <div class="resources-intro">
                        <h4>Related Resources</h4>
                        <p class="section-description">Explore these resources to deepen your understanding:</p>
                    </div>
                    
                    <div class="resources-grid">
                        ${e.relatedResources.map(t=>`
                            <div class="resource-card" data-audience="${t.audience}">
                                <div class="resource-header">
                                    <span class="resource-type resource-type-${t.type}">${this.getResourceTypeIcon(t.type)}</span>
                                    <span class="resource-audience">${this.capitalizeFirst(t.audience)}</span>
                                </div>
                                <h5 class="resource-title">${t.title}</h5>
                                <p class="resource-description">${t.description}</p>
                                <a href="${t.url}" target="_blank" rel="noopener noreferrer" class="resource-link">
                                    View Resource <span class="external-icon">↗</span>
                                </a>
                            </div>
                        `).join("")}
                    </div>
                    
                    ${e.connectedSimulations.length>0?`
                        <div class="connected-simulations">
                            <h4>Related Simulations</h4>
                            <p class="section-description">Continue your learning journey with these connected explorations:</p>
                            <div class="connected-list">
                                ${e.connectedSimulations.map(t=>`
                                    <button class="connected-sim-button" data-simulation="${t}">
                                        Explore: ${this.getSimulationTitle(t)}
                                    </button>
                                `).join("")}
                            </div>
                        </div>
                    `:""}
                </div>
            </div>
        `}generateEducatorTab(){const t=this.simulationInfo.educatorResources;return`
            <div class="tab-content" id="tab-educator" role="tabpanel" aria-labelledby="tab-educator">
                <div class="educator-content">
                    <div class="educator-intro">
                        <h4>Educator Resources</h4>
                        <p class="section-description">Tools and guidance for classroom implementation:</p>
                    </div>
                    
                    <div class="educator-sections">
                        <div class="educator-section">
                            <h5>Discussion Questions</h5>
                            <ul class="discussion-questions">
                                ${t.discussionQuestions.map(i=>`
                                    <li class="discussion-item">${i}</li>
                                `).join("")}
                            </ul>
                        </div>
                        
                        <div class="educator-section">
                            <h5>Extension Activities</h5>
                            <ul class="extension-activities">
                                ${t.extensionActivities.map(i=>`
                                    <li class="activity-item">${i}</li>
                                `).join("")}
                            </ul>
                        </div>
                        
                        <div class="educator-section">
                            <h5>Classroom Tips</h5>
                            <ul class="classroom-tips">
                                ${t.classroomTips.map(i=>`
                                    <li class="tip-item">${i}</li>
                                `).join("")}
                            </ul>
                        </div>
                        
                        <div class="educator-section">
                            <h5>Standards Alignment</h5>
                            <ul class="standards-alignment">
                                ${t.relatedStandards.map(i=>`
                                    <li class="standard-item">${i}</li>
                                `).join("")}
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        `}generateModalFooter(){return`
            <div class="pre-launch-footer">
                <div class="action-buttons">
                    <button type="button" class="btn-cancel" id="cancel-launch">
                        Maybe Later
                    </button>
                    <button type="button" class="btn-launch" id="start-exploration">
                        <span class="button-icon">🚀</span>
                        Start Exploration
                    </button>
                </div>
            </div>
        `}setupEventListeners(){if(!this.modal){o.error("Modal instance not available for event listener setup");return}if(!this.modal.element){o.error("Modal element not available. Modal structure:",this.modal);return}if(typeof this.modal.element.querySelectorAll!="function"){o.error("Modal element does not have querySelectorAll method. Element type:",typeof this.modal.element,this.modal.element);return}try{const e=this.modal.element.querySelector(".tab-hamburger"),t=this.modal.element.querySelector(".tab-buttons-container");e&&t&&(e.addEventListener("click",()=>{const h=e.getAttribute("aria-expanded")==="true";e.setAttribute("aria-expanded",!h),t.classList.toggle("expanded",!h)}),document.addEventListener("click",h=>{h.target.closest(".onboarding-coach-mark")||h.target.closest(".pre-launch-tabs")||(e.setAttribute("aria-expanded","false"),t.classList.remove("expanded"))}),document.addEventListener("keydown",h=>{h.key==="Escape"&&e.getAttribute("aria-expanded")==="true"&&(e.setAttribute("aria-expanded","false"),t.classList.remove("expanded"),e.focus())}));const i=this.modal.element.querySelectorAll(".tab-button"),n=this.modal.element.querySelector(".tab-buttons-container"),s=this.modal.element.querySelector(".pre-launch-tabs"),a=()=>{if(n&&s){const{scrollLeft:h,scrollWidth:p,clientWidth:g}=n,y=h>0,m=h<p-g-1;s.classList.toggle("scrollable-left",y),s.classList.toggle("scrollable-right",m)}};n&&(n.addEventListener("scroll",a),window.addEventListener("resize",a),setTimeout(a,mt)),i.forEach(h=>{h.addEventListener("click",p=>{const g=p.target.dataset.tab||p.currentTarget.dataset.tab;g?(this.switchTab(g),e&&t&&(e.setAttribute("aria-expanded","false"),t.classList.remove("expanded"))):o.warn("Tab button clicked but no data-tab attribute found",p.target)})});const r=this.modal.element.querySelector("#start-exploration"),c=this.modal.element.querySelector("#cancel-launch");r?r.addEventListener("click",()=>{o.debug("Start Exploration button clicked",{simulationId:this.simulationId,onLaunch:typeof this.options.onLaunch}),this.trackAnalytics("simulation_launched"),this.close(),typeof this.options.onLaunch=="function"?(o.debug("Calling onLaunch callback"),this.options.onLaunch(this.simulationId)):o.error("onLaunch is not a function:",this.options.onLaunch)}):o.error("Start button not found in modal"),c&&c.addEventListener("click",()=>{this.trackAnalytics("launch_cancelled"),this.close(),this.options.onCancel()}),document.querySelectorAll(".connected-sim-button").forEach(h=>{h.addEventListener("click",p=>{const g=p.target.dataset.simulation;this.trackAnalytics("connected_simulation_clicked",{target:g})})}),document.querySelectorAll(".resource-link").forEach(h=>{h.addEventListener("click",p=>{this.trackAnalytics("resource_accessed",{url:p.target.href,type:p.target.closest(".resource-card").querySelector(".resource-type").textContent})})})}catch(e){o.error("Error setting up PreLaunchModal event listeners:",e)}}switchTab(e){if(!e){o.warn("switchTab called with null or undefined tabId");return}try{const t=this.modal&&this.modal.element||document.querySelector(".pre-launch-modal");if(!t){o.warn("Pre-launch modal container not found");return}t.querySelectorAll(".tab-button").forEach(r=>{r.classList.remove("active"),r.setAttribute("aria-selected","false")});const n=t.querySelector(`[data-tab="${e}"]`);if(n){n.classList.add("active"),n.setAttribute("aria-selected","true"),t.querySelector(".tab-buttons-container")&&window.innerWidth>ht&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"center"});const c=t.querySelector(".tab-current-label");if(c){const d=n.textContent.trim();c.textContent=d}}else o.warn(`Tab button with data-tab="${e}" not found in modal`);t.querySelectorAll(".tab-content").forEach(r=>{r.classList.remove("active")});const a=t.querySelector(`#tab-${e}`);a?a.classList.add("active"):o.warn(`Tab content with id="tab-${e}" not found in modal`),this.currentTab=e,this.trackAnalytics("tab_switched",{tab:e})}catch(t){o.error("Error in switchTab:",t)}}capitalizeFirst(e){return e.charAt(0).toUpperCase()+e.slice(1)}formatText(e){return e.split(`

`).map(t=>`<p>${t.trim()}</p>`).join("")}getResourceTypeIcon(e){return{article:"📄",video:"🎥",research:"🔬",interactive:"🖥️",book:"📚",website:"🌐"}[e]||"📎"}getSimulationTitle(e){const t=ye(e);return t?t.title:e}trackAnalytics(e,t={}){A&&A.trackEvent("pre_launch",{event:e,simulation:this.simulationId,tab:this.currentTab,...t})}}class pt{constructor(e,t={}){this.simulationId=e,this.options={onClose:t.onClose||(()=>{}),showTabs:t.showTabs!==!1,showResourcePanel:t.showResourcePanel!==!1,collapseEthicsMeters:t.collapseEthicsMeters||!1,size:t.size||"large",...t},this.currentTab="simulation",this.isEthicsMetersCollapsed=this.options.collapseEthicsMeters,this.modal=null,this.resizeObserver=null}show(){this.createModal(),this.setupEventListeners(),this.setupResizeObserver(),document.body.appendChild(this.modal),this.modal.offsetHeight,this.modal.classList.add("visible"),this.focusTrap=Ee.createTrap(this.modal,{autoFocus:!0,restoreFocus:!0}),this.trackAnalytics("enhanced_modal_opened",{simulationId:this.simulationId,size:this.options.size,tabsEnabled:this.options.showTabs})}close(){this.modal&&(this.focusTrap&&(this.focusTrap.destroy(),this.focusTrap=null),this.modal.classList.remove("visible"),setTimeout(()=>{this.modal&&this.modal.parentNode&&this.modal.parentNode.removeChild(this.modal),this.cleanup()},re.FAST)),this.options.onClose(),this.trackAnalytics("enhanced_modal_closed")}createModal(){this.modal=document.createElement("div"),this.modal.className=`enhanced-simulation-modal modal-size-${this.options.size}`,this.modal.setAttribute("role","dialog"),this.modal.setAttribute("aria-modal","true"),this.modal.setAttribute("aria-labelledby","enhanced-modal-title"),this.modal.innerHTML=`
            <div class="enhanced-modal-backdrop" aria-hidden="true"></div>
            <div class="enhanced-modal-container">
                <div class="enhanced-modal-header">
                    <h2 id="enhanced-modal-title" class="enhanced-modal-title">Simulation</h2>
                    <div class="enhanced-modal-controls">
                        <button class="btn-icon btn-expand" title="Toggle fullscreen" aria-label="Toggle fullscreen">
                            <span class="icon">⛶</span>
                        </button>
                        <button class="btn-icon btn-close" title="Close simulation" aria-label="Close simulation">
                            <span class="icon">×</span>
                        </button>
                    </div>
                </div>
                
                ${this.options.showTabs?this.generateTabNavigation():""}
                
                <div class="enhanced-modal-body">
                    <div class="simulation-main-area">
                        <div class="simulation-content-wrapper">
                            <div id="enhanced-simulation-container" class="enhanced-simulation-container">
                                <!-- Simulation content will be injected here -->
                            </div>
                            
                            ${this.generateEthicsMetersPanel()}
                        </div>
                        
                        ${this.options.showResourcePanel?this.generateResourcePanel():""}
                    </div>
                    
                    ${this.generateTabContent()}
                </div>
                
                <div class="enhanced-modal-footer">
                    <div class="simulation-status">
                        <span class="status-indicator" id="simulation-status">Ready</span>
                    </div>
                    <div class="simulation-actions">
                        <button class="btn btn-secondary" id="reset-enhanced-simulation">Reset</button>
                        <button class="btn btn-secondary" id="pause-enhanced-simulation">Pause</button>
                    </div>
                </div>
            </div>
        `}generateTabNavigation(){return`
            <div class="enhanced-modal-tabs" role="tablist">
                <button class="enhanced-tab active" role="tab" data-tab="simulation" aria-selected="true" aria-controls="tab-simulation">
                    <span class="tab-icon">🎮</span>
                    <span class="tab-label">Simulation</span>
                </button>
                <button class="enhanced-tab" role="tab" data-tab="resources" aria-selected="false" aria-controls="tab-resources">
                    <span class="tab-icon">📚</span>
                    <span class="tab-label">Resources</span>
                </button>
                <button class="enhanced-tab" role="tab" data-tab="progress" aria-selected="false" aria-controls="tab-progress">
                    <span class="tab-icon">📊</span>
                    <span class="tab-label">Progress</span>
                </button>
                <button class="enhanced-tab" role="tab" data-tab="help" aria-selected="false" aria-controls="tab-help">
                    <span class="tab-icon">❓</span>
                    <span class="tab-label">Help</span>
                </button>
            </div>
        `}generateEthicsMetersPanel(){return`
            <div class="ethics-meters-panel ${this.isEthicsMetersCollapsed?"collapsed":""}" id="ethics-meters-panel">
                <div class="ethics-meters-header">
                    <h3>Ethics Monitoring</h3>
                    <button class="btn-icon btn-collapse" title="Toggle ethics meters" aria-label="Toggle ethics meters">
                        <span class="icon">${this.isEthicsMetersCollapsed?"▶":"▼"}</span>
                    </button>
                </div>
                <div class="ethics-meters-content">
                    <p class="ethics-description">Track how your decisions affect different ethical dimensions</p>
                    <div class="meters-container" role="group" aria-label="Ethics meters">
                        <!-- Enhanced meters will be dynamically created here -->
                    </div>
                </div>
            </div>
        `}generateResourcePanel(){return`
            <div class="resource-panel" id="resource-panel">
                <div class="resource-panel-header">
                    <h3>Quick Resources</h3>
                    <button class="btn-icon btn-collapse" title="Toggle resources" aria-label="Toggle resources">
                        <span class="icon">◀</span>
                    </button>
                </div>
                <div class="resource-panel-content">
                    <div class="resource-section">
                        <h4>Key Concepts</h4>
                        <ul class="resource-list" id="quick-concepts">
                            <!-- Quick concepts will be populated here -->
                        </ul>
                    </div>
                    <div class="resource-section">
                        <h4>Need Help?</h4>
                        <ul class="resource-list" id="quick-help">
                            <li><a href="#" class="resource-link" data-action="show-hints">Show Hints</a></li>
                            <li><a href="#" class="resource-link" data-action="explain-scenario">Explain Scenario</a></li>
                            <li><a href="#" class="resource-link" data-action="ethics-guide">Ethics Guide</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        `}generateTabContent(){return this.options.showTabs?`
            <div class="enhanced-tab-content">
                <div class="tab-panel" id="tab-simulation" role="tabpanel" aria-labelledby="tab-simulation" style="display: none;">
                    <!-- Simulation tab content is handled by main area -->
                </div>
                
                <div class="tab-panel" id="tab-resources" role="tabpanel" aria-labelledby="tab-resources" style="display: none;">
                    <div class="tab-content-header">
                        <h3>Educational Resources</h3>
                        <p>Supporting materials and deeper learning opportunities</p>
                    </div>
                    <div class="resources-grid">
                        <div class="resource-category">
                            <h4>Background Reading</h4>
                            <div class="resource-items" id="background-reading">
                                <!-- Resources will be populated here -->
                            </div>
                        </div>
                        <div class="resource-category">
                            <h4>Related Videos</h4>
                            <div class="resource-items" id="related-videos">
                                <!-- Videos will be populated here -->
                            </div>
                        </div>
                        <div class="resource-category">
                            <h4>Discussion Questions</h4>
                            <div class="resource-items" id="discussion-questions">
                                <!-- Questions will be populated here -->
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="tab-panel" id="tab-progress" role="tabpanel" aria-labelledby="tab-progress" style="display: none;">
                    <div class="tab-content-header">
                        <h3>Your Progress</h3>
                        <p>Track your learning journey and decisions</p>
                    </div>
                    <div class="progress-content">
                        <div class="progress-summary">
                            <div class="progress-stat">
                                <span class="stat-value" id="decisions-made">0</span>
                                <span class="stat-label">Decisions Made</span>
                            </div>
                            <div class="progress-stat">
                                <span class="stat-value" id="time-spent">0:00</span>
                                <span class="stat-label">Time Spent</span>
                            </div>
                            <div class="progress-stat">
                                <span class="stat-value" id="concepts-explored">0</span>
                                <span class="stat-label">Concepts Explored</span>
                            </div>
                        </div>
                        <div class="decision-history">
                            <h4>Decision History</h4>
                            <div class="decisions-timeline" id="decisions-timeline">
                                <!-- Decision history will be populated here -->
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="tab-panel" id="tab-help" role="tabpanel" aria-labelledby="tab-help" style="display: none;">
                    <div class="tab-content-header">
                        <h3>Help & Support</h3>
                        <p>Get assistance and learn how to use the simulation</p>
                    </div>
                    <div class="help-content">
                        <div class="help-section">
                            <h4>How to Use</h4>
                            <div class="help-steps">
                                <ol>
                                    <li>Read the scenario and understand the context</li>
                                    <li>Make decisions by clicking on available options</li>
                                    <li>Observe how ethics meters change with your choices</li>
                                    <li>Reflect on the consequences of your decisions</li>
                                </ol>
                            </div>
                        </div>
                        <div class="help-section">
                            <h4>Understanding Ethics Meters</h4>
                            <div class="ethics-explanation" id="ethics-explanation">
                                <!-- Ethics meter explanations will be populated here -->
                            </div>
                        </div>
                        <div class="help-section">
                            <h4>Need More Help?</h4>
                            <div class="help-actions">
                                <button class="btn btn-secondary" id="show-tutorial">Show Tutorial</button>
                                <button class="btn btn-secondary" id="contact-support">Contact Support</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        `:""}setupEventListeners(){const e=this.modal.querySelector(".btn-close");e&&e.addEventListener("click",()=>this.close());const t=this.modal.querySelector(".enhanced-modal-backdrop");t&&t.addEventListener("click",()=>this.close()),document.addEventListener("keydown",this.handleKeyDown.bind(this)),this.options.showTabs&&this.modal.querySelectorAll(".enhanced-tab").forEach(s=>{s.addEventListener("click",a=>{this.switchTab(a.target.closest(".enhanced-tab").dataset.tab)})}),this.setupCollapsiblePanels();const i=this.modal.querySelector(".btn-expand");i&&i.addEventListener("click",()=>this.toggleFullscreen()),this.setupSimulationControls()}setupCollapsiblePanels(){this.modal.querySelectorAll(".btn-collapse").forEach(t=>{t.addEventListener("click",i=>{const n=i.target.closest(".ethics-meters-panel, .resource-panel");if(n){n.classList.toggle("collapsed");const s=t.querySelector(".icon");n.classList.contains("ethics-meters-panel")?s.textContent=n.classList.contains("collapsed")?"▶":"▼":s.textContent=n.classList.contains("collapsed")?"▶":"◀"}})})}setupSimulationControls(){const e=this.modal.querySelector("#reset-enhanced-simulation"),t=this.modal.querySelector("#pause-enhanced-simulation");e&&e.addEventListener("click",()=>{this.resetSimulation()}),t&&t.addEventListener("click",()=>{this.togglePause()})}switchTab(e){this.modal.querySelectorAll(".enhanced-tab").forEach(s=>{const a=s.dataset.tab===e;s.classList.toggle("active",a),s.setAttribute("aria-selected",a)}),this.modal.querySelectorAll(".tab-panel").forEach(s=>{s.style.display=s.id===`tab-${e}`?"block":"none"});const n=this.modal.querySelector(".simulation-main-area");n&&(n.style.display=e==="simulation"?"flex":"none"),this.currentTab=e,this.trackAnalytics("tab_switched",{tab:e})}toggleFullscreen(){this.modal.classList.toggle("fullscreen-mode");const e=this.modal.querySelector(".btn-expand .icon");e&&(e.textContent=(this.modal.classList.contains("fullscreen-mode"),"⛶")),this.trackAnalytics("fullscreen_toggled",{isFullscreen:this.modal.classList.contains("fullscreen-mode")})}resetSimulation(){this.options.onReset&&this.options.onReset(),this.trackAnalytics("simulation_reset")}togglePause(){const e=this.modal.querySelector("#pause-enhanced-simulation"),t=e.textContent==="Resume";e.textContent=t?"Pause":"Resume",this.options.onPause&&this.options.onPause(!t),this.trackAnalytics("simulation_pause_toggled",{isPaused:!t})}updateStatus(e){const t=this.modal.querySelector("#simulation-status");t&&(t.textContent=e)}updateProgress(e){const t=this.modal.querySelector("#decisions-made"),i=this.modal.querySelector("#time-spent"),n=this.modal.querySelector("#concepts-explored");t&&e.decisions!==void 0&&(t.textContent=e.decisions),i&&e.timeSpent!==void 0&&(i.textContent=this.formatTime(e.timeSpent)),n&&e.concepts!==void 0&&(n.textContent=e.concepts)}addDecisionToTimeline(e){const t=this.modal.querySelector("#decisions-timeline");if(t){const i=document.createElement("div");i.className="decision-item",i.innerHTML=`
                <div class="decision-time">${new Date().toLocaleTimeString()}</div>
                <div class="decision-description">${e.description}</div>
                <div class="decision-impact">${e.impact}</div>
            `,t.appendChild(i),t.scrollTop=t.scrollHeight}}getSimulationContainer(){return this.modal.querySelector("#enhanced-simulation-container")}getEthicsMetersContainer(){return this.modal.querySelector(".meters-container")}setupResizeObserver(){window.ResizeObserver&&(this.resizeObserver=new ResizeObserver(e=>{for(const t of e)this.handleResize(t.contentRect)}),this.resizeObserver.observe(this.modal))}handleResize(e){if(e.width<Ce.MOBILE?this.modal.classList.add("mobile-layout"):this.modal.classList.remove("mobile-layout"),e.width<Ce.TABLET){const t=this.modal.querySelector(".resource-panel");t&&!t.classList.contains("collapsed")&&t.classList.add("collapsed")}}handleKeyDown(e){e.key==="Escape"?this.close():e.key==="Tab"&&this.handleTabNavigation(e)}handleTabNavigation(e){const t=this.modal.querySelectorAll('button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])'),i=t[0],n=t[t.length-1];e.shiftKey?document.activeElement===i&&(n.focus(),e.preventDefault()):document.activeElement===n&&(i.focus(),e.preventDefault())}trapFocus(){}formatTime(e){const t=Math.floor(e/re.SECONDS_PER_MINUTE),i=e%re.SECONDS_PER_MINUTE;return`${t}:${i.toString().padStart(2,"0")}`}trackAnalytics(e,t={}){window.simpleAnalytics&&window.simpleAnalytics.trackEvent(e,{simulationId:this.simulationId,modalType:"enhanced",...t})}cleanup(){this.resizeObserver&&this.resizeObserver.disconnect(),document.removeEventListener("keydown",this.handleKeyDown.bind(this)),this.modal=null}}const Z={SUMMARY:0,FEELINGS:1,INSIGHTS:2,LEARNING:3,NEXT_STEPS:4};class gt{constructor(e={}){this.options={simulationId:e.simulationId||"bias-fairness",simulationData:e.simulationData||{},sessionData:e.sessionData||{},onComplete:e.onComplete||(()=>{}),onSkip:e.onSkip||(()=>{}),onRetry:e.onRetry||(()=>{}),showExpertMode:e.showExpertMode||!1,...e},this.simulationInfo=ve[this.options.simulationId]||ve["bias-fairness"],this.sessionData=this.options.sessionData,this.reflectionData={},this.currentStep=0,this.totalSteps=5,this.modal=null,this.init()}init(){A.trackEvent("post_simulation_modal","opened",{simulation_id:this.options.simulationId,session_duration:this.sessionData.duration||0,decisions_made:this.sessionData.decisions?.length||0});const e=this.generateModalContent(),t=this.generateModalFooter();this.modal=new W({title:this.generateModalTitle(),content:e,footer:t,onClose:this.handleClose.bind(this),closeOnBackdrop:!1,closeOnEscape:!1,size:"large",className:"post-simulation-modal"}),this.modal.open(),this.setupEventHandlers(),this.initializeReflectionSystem()}generateModalTitle(){const e=this.calculatePerformance(),t={excellent:`🎉 Excellent Work: ${this.simulationInfo.title} Complete`,good:`✅ Well Done: ${this.simulationInfo.title} Complete`,average:`📋 Simulation Complete: ${this.simulationInfo.title}`,needs_improvement:`🔄 Learning Opportunity: ${this.simulationInfo.title}`};return t[e]||t.average}calculatePerformance(){if(!this.sessionData.decisions)return"average";const{decisions:e}=this.sessionData,t=e.filter(s=>s.ethicalScore>F.ETHICAL_GOOD).length,i=e.length,n=t/i;return n>=F.ETHICAL_EXCELLENT?"excellent":n>=F.ETHICAL_GOOD?"good":n>=F.ETHICAL_AVERAGE?"average":"needs_improvement"}generateModalContent(){return`
            <div class="post-simulation-modal-content">
                <!-- Progress Indicator -->
                <div class="reflection-progress">
                    <div class="progress-bar" role="progressbar" 
                         aria-valuenow="${this.currentStep}" 
                         aria-valuemin="0" 
                         aria-valuemax="${this.totalSteps}">
                        <div class="progress-fill" style="width: ${this.currentStep/this.totalSteps*100}%"></div>
                    </div>
                    <div class="progress-steps">
                        ${this.generateProgressSteps()}
                    </div>
                </div>

                <!-- Main Content Area -->
                <div class="reflection-content">
                    ${this.generateStepContent(this.currentStep)}
                </div>

                <!-- Session Summary Sidebar -->
                <div class="session-summary">
                    ${this.generateSessionSummary()}
                </div>
            </div>
        `}generateProgressSteps(){return[{id:0,title:"Summary",icon:"📊"},{id:1,title:"Reflection",icon:"🤔"},{id:2,title:"Analysis",icon:"🔍"},{id:3,title:"Learning",icon:"💡"},{id:4,title:"Next Steps",icon:"🚀"}].map(t=>`
            <div class="progress-step ${t.id<=this.currentStep?"completed":""} ${t.id===this.currentStep?"active":""}"
                 data-step="${t.id}">
                <div class="step-icon">${t.icon}</div>
                <div class="step-title">${t.title}</div>
            </div>
        `).join("")}generateStepContent(e){switch(e){case Z.SUMMARY:return this.generateSummaryStep();case Z.FEELINGS:return this.generateReflectionStep();case Z.INSIGHTS:return this.generateAnalysisStep();case Z.LEARNING:return this.generateLearningStep();case Z.NEXT_STEPS:return this.generateNextStepsStep();default:return this.generateSummaryStep()}}generateSummaryStep(){const e=this.calculatePerformance(),t=this.sessionData.duration||0,i=this.sessionData.decisions||[];return`
            <div class="step-content summary-step">
                <h3>🎯 Your Simulation Journey</h3>
                
                <div class="summary-cards">
                    <div class="summary-card">
                        <div class="card-icon">⏱️</div>
                        <div class="card-content">
                            <div class="card-value">${U.formatDuration(t)}</div>
                            <div class="card-label">Time Invested</div>
                        </div>
                    </div>
                    
                    <div class="summary-card">
                        <div class="card-icon">🔄</div>
                        <div class="card-content">
                            <div class="card-value">${i.length}</div>
                            <div class="card-label">Decisions Made</div>
                        </div>
                    </div>
                    
                    <div class="summary-card">
                        <div class="card-icon">⚖️</div>
                        <div class="card-content">
                            <div class="card-value">${this.calculateEthicalScore()}</div>
                            <div class="card-label">Ethical Score</div>
                        </div>
                    </div>
                    
                    <div class="summary-card">
                        <div class="card-icon">📈</div>
                        <div class="card-content">
                            <div class="card-value">${e.toUpperCase()}</div>
                            <div class="card-label">Performance</div>
                        </div>
                    </div>
                </div>

                <div class="decision-journey">
                    <h4>📍 Your Decision Journey</h4>
                    <div class="journey-visualization">
                        ${this.generateDecisionJourney()}
                    </div>
                </div>

                <div class="key-moments">
                    <h4>✨ Key Moments</h4>
                    ${this.generateKeyMoments()}
                </div>
            </div>
        `}generateReflectionStep(){return`
            <div class="step-content reflection-step">
                <h3>🤔 Reflection Time</h3>
                <p class="step-description">
                    Let's explore your experience and thinking process during the simulation.
                </p>

                <div class="reflection-questions">
                    ${this.generateReflectionQuestions()}
                </div>
            </div>
        `}generateAnalysisStep(){return`
            <div class="step-content analysis-step">
                <h3>🔍 Pattern Analysis</h3>
                <p class="step-description">
                    Understanding your decision-making patterns and ethical considerations.
                </p>

                <div class="analysis-sections">
                    ${this.generateDecisionPatterns()}
                    ${this.generateEthicalFrameworks()}
                    ${this.generateBiasRecognition()}
                </div>
            </div>
        `}generateLearningStep(){return`
            <div class="step-content learning-step">
                <h3>💡 Connect the Dots</h3>
                <p class="step-description">
                    Connecting your experience to broader AI ethics concepts.
                </p>

                <div class="learning-sections">
                    ${this.generateConceptConnections()}
                    ${this.generateAlternativeScenarios()}
                    ${this.generateExpertInsights()}
                </div>
            </div>
        `}generateNextStepsStep(){return`
            <div class="step-content next-steps-step">
                <h3>🚀 Your Learning Journey Continues</h3>
                <p class="step-description">
                    Personalized recommendations for continued growth in AI ethics.
                </p>

                <div class="recommendations-grid">
                    ${this.generatePersonalizedRecommendations()}
                    ${this.generateSkillDevelopment()}
                    ${this.generateResourceSuggestions()}
                </div>

                <div class="goal-setting">
                    <h4>🎯 Set Your Learning Goals</h4>
                    ${this.generateGoalSetting()}
                </div>
            </div>
        `}generateSessionSummary(){return`
            <div class="summary-panel">
                <h4>📋 Session Overview</h4>
                
                <div class="summary-item">
                    <span class="summary-label">Simulation:</span>
                    <span class="summary-value">${this.simulationInfo.title}</span>
                </div>
                
                <div class="summary-item">
                    <span class="summary-label">Started:</span>
                    <span class="summary-value">${new Date(this.sessionData.startTime).toLocaleString()}</span>
                </div>
                
                <div class="summary-item">
                    <span class="summary-label">Duration:</span>
                    <span class="summary-value">${U.formatDuration(this.sessionData.duration)}</span>
                </div>

                <div class="ethics-meters-summary">
                    <h5>⚖️ Ethics Tracking</h5>
                    ${this.generateEthicsMetersSummary()}
                </div>

                <div class="quick-actions">
                    <button class="action-btn secondary" data-action="save-reflection">
                        💾 Save Reflection
                    </button>
                    <button class="action-btn secondary" data-action="share-insights">
                        🔗 Share Insights
                    </button>
                    <button class="action-btn secondary" data-action="print-summary">
                        🖨️ Print Summary
                    </button>
                </div>
            </div>
        `}generateModalFooter(){return`
            <div class="modal-footer-content">
                <div class="footer-left">
                    <button class="btn btn-outline" data-action="skip-reflection">
                        Skip Reflection
                    </button>
                </div>
                
                <div class="footer-center">
                    <span class="step-indicator">
                        Step ${this.currentStep+1} of ${this.totalSteps}
                    </span>
                </div>
                
                <div class="footer-right">
                    <button class="btn btn-secondary" data-action="previous" 
                            ${this.currentStep===0?"disabled":""}>
                        ← Previous
                    </button>
                    <button class="btn btn-primary" data-action="next">
                        ${this.currentStep===this.totalSteps-1?"Complete":"Next →"}
                    </button>
                </div>
            </div>
        `}generateReflectionQuestions(){return this.getReflectionQuestions().map(t=>`
            <div class="reflection-question" data-question-id="${t.id}">
                <div class="question-header">
                    <span class="question-number">${t.id}</span>
                    <span class="question-type">${t.type}</span>
                </div>
                
                <div class="question-content">
                    <h4>${t.question}</h4>
                    ${t.context?`<p class="question-context">${t.context}</p>`:""}
                    
                    <div class="question-input">
                        ${this.generateQuestionInput(t)}
                    </div>
                </div>
            </div>
        `).join("")}getReflectionQuestions(){const e=[{id:1,type:"open-ended",question:"What was the most challenging decision you faced during the simulation?",context:"Think about moments when you felt uncertain or conflicted.",inputType:"textarea"},{id:2,type:"multiple-choice",question:"Which ethical principle most influenced your decisions?",options:["Fairness","Transparency","Accountability","Privacy","Beneficence"],inputType:"radio"},{id:3,type:"scale",question:"How confident are you in the ethical soundness of your decisions?",scale:{min:1,max:5,labels:["Not confident","Very confident"]},inputType:"range"},{id:4,type:"open-ended",question:"If you could go back, what would you do differently?",context:"Consider both specific decisions and your overall approach.",inputType:"textarea"},{id:5,type:"ranking",question:"Rank these factors by how much they influenced your decisions:",options:["Personal values","Potential consequences","Stakeholder impact","Technical feasibility","Organizational policy"],inputType:"ranking"}];return this.options.simulationId==="bias-fairness"&&e.push({id:6,type:"open-ended",question:"What biases did you notice in yourself during the simulation?",context:"Bias recognition is a crucial step in developing ethical AI systems.",inputType:"textarea"}),e}generateQuestionInput(e){switch(e.inputType){case"textarea":return`
                    <textarea id="question-${e.id}"
                              name="question-${e.id}"
                              class="form-control" 
                              rows="4" 
                              placeholder="Share your thoughts..."
                              data-question="${e.id}"
                              autocomplete="off"></textarea>
                `;case"radio":return e.options.map(t=>`
                    <label class="radio-option">
                        <input type="radio" name="question_${e.id}" value="${t}">
                        <span class="radio-label">${t}</span>
                    </label>
                `).join("");case"range":return`
                    <div class="range-input">
                        <input type="range" 
                               id="question-${e.id}"
                               name="question-${e.id}"
                               min="${e.scale.min}" 
                               max="${e.scale.max}" 
                               value="${Math.ceil((e.scale.min+e.scale.max)/2)}"
                               class="form-range"
                               data-question="${e.id}"
                               aria-describedby="range-labels-${e.id}">
                        <div class="range-labels" id="range-labels-${e.id}">
                            <span>${e.scale.labels[0]}</span>
                            <span>${e.scale.labels[1]}</span>
                        </div>
                    </div>
                `;case"ranking":return`
                    <div class="ranking-container" data-question="${e.id}">
                        <div class="ranking-items">
                            ${e.options.map((t,i)=>`
                                <div class="ranking-item" draggable="true" data-value="${t}">
                                    <span class="rank-number">${i+1}</span>
                                    <span class="rank-text">${t}</span>
                                    <span class="drag-handle">⋮⋮</span>
                                </div>
                            `).join("")}
                        </div>
                        <p class="ranking-instruction">Drag items to reorder by importance</p>
                    </div>
                `;default:return`<input type="text" 
                       id="question-${e.id}" 
                       name="question-${e.id}"
                       class="form-control" 
                       data-question="${e.id}"
                       autocomplete="off">`}}setupEventHandlers(){if(!this.modal?.modalElement)return;const{modalElement:e}=this.modal;e.addEventListener("click",t=>{t.target.matches('[data-action="next"]')?this.handleNext():t.target.matches('[data-action="previous"]')?this.handlePrevious():t.target.matches('[data-action="skip-reflection"]')?this.handleSkip():t.target.matches('[data-action="save-reflection"]')?this.handleSaveReflection():t.target.matches('[data-action="share-insights"]')?this.handleShareInsights():t.target.matches('[data-action="print-summary"]')&&this.handlePrintSummary()}),e.addEventListener("input",t=>{t.target.matches("[data-question]")&&this.handleInputChange(t)}),this.setupRankingHandlers(e)}handleNext(){this.currentStep<this.totalSteps-1?this.validateCurrentStep()&&(this.currentStep++,this.updateModalContent(),this.trackStepCompletion()):this.handleComplete()}handlePrevious(){this.currentStep>0&&(this.currentStep--,this.updateModalContent())}updateModalContent(){if(!this.modal?.modalElement)return;const e=this.modal.modalElement.querySelector(".reflection-content"),t=this.modal.modalElement.querySelector(".modal-footer-content"),i=this.modal.modalElement.querySelector(".reflection-progress");if(e&&(e.innerHTML=this.generateStepContent(this.currentStep)),t&&(t.innerHTML=this.generateModalFooter()),i){const n=i.querySelector(".progress-fill"),s=i.querySelector(".progress-steps");n&&(n.style.width=`${this.currentStep/this.totalSteps*100}%`),s&&(s.innerHTML=this.generateProgressSteps())}this.setupEventHandlers()}calculateEthicalScore(){if(!this.sessionData.decisions)return"N/A";const{decisions:e}=this.sessionData,i=e.reduce((n,s)=>n+(s.ethicalScore||0),0)/e.length;return`${Math.round(i*100)}%`}generateDecisionJourney(){if(!this.sessionData.decisions)return"<p>No decision data available.</p>";const{decisions:e}=this.sessionData;return`
            <div class="journey-timeline">
                ${e.map((t,i)=>`
                    <div class="journey-point ${this.getDecisionClass(t)}">
                        <div class="point-marker">${i+1}</div>
                        <div class="point-content">
                            <div class="point-title">${t.title||`Decision ${i+1}`}</div>
                            <div class="point-score">Score: ${Math.round((t.ethicalScore||0)*100)}%</div>
                        </div>
                    </div>
                `).join("")}
            </div>
        `}getDecisionClass(e){const t=e.ethicalScore||0;return t>=F.SCORE_EXCELLENT?"excellent":t>=F.SCORE_GOOD?"good":t>=F.SCORE_AVERAGE?"average":"needs-improvement"}initializeReflectionSystem(){setTimeout(()=>{this.initializeCharts(),this.setupRankingDragAndDrop()},100)}initializeCharts(){}validateCurrentStep(){return!0}handleClose(){this.options.onComplete(this.reflectionData)}handleSkip(){confirm("Are you sure you want to skip the reflection? This is valuable for your learning.")&&(this.options.onSkip(),this.modal.close())}handleComplete(){this.saveReflectionData(),A.trackEvent("post_simulation_reflection","completed",{simulation_id:this.options.simulationId,steps_completed:this.currentStep+1,reflection_depth:this.calculateReflectionDepth()}),this.options.onComplete(this.reflectionData),this.modal.close()}saveReflectionData(){const e={simulationId:this.options.simulationId,timestamp:new Date().toISOString(),sessionData:this.sessionData,reflectionData:this.reflectionData,performance:this.calculatePerformance(),completionRate:(this.currentStep+1)/this.totalSteps};Ne.addReflection(e)}calculateReflectionDepth(){return Object.keys(this.reflectionData).length/this.getReflectionQuestions().length}generateKeyMoments(){return"<p>Key moments analysis coming soon...</p>"}generateDecisionPatterns(){return"<p>Decision pattern analysis coming soon...</p>"}generateEthicalFrameworks(){return"<p>Ethical frameworks analysis coming soon...</p>"}generateBiasRecognition(){return"<p>Bias recognition insights coming soon...</p>"}generateConceptConnections(){return"<p>Concept connections coming soon...</p>"}generateAlternativeScenarios(){return"<p>Alternative scenarios coming soon...</p>"}generateExpertInsights(){return"<p>Expert insights coming soon...</p>"}generatePersonalizedRecommendations(){return"<p>Personalized recommendations coming soon...</p>"}generateSkillDevelopment(){return"<p>Skill development suggestions coming soon...</p>"}generateResourceSuggestions(){return"<p>Resource suggestions coming soon...</p>"}generateGoalSetting(){return"<p>Goal setting tools coming soon...</p>"}generateEthicsMetersSummary(){return"<p>Ethics meters summary coming soon...</p>"}setupRankingHandlers(){}setupRankingDragAndDrop(){}handleInputChange(){}handleSaveReflection(){}handleShareInsights(){}handlePrintSummary(){}trackStepCompletion(){}}const P={BREAKPOINTS:{MOBILE:768,SMALL_MOBILE:480},LAYOUT:{MANY_BUTTONS_THRESHOLD:4,DEFAULT_GAP:12,TOTAL_PADDING:40},SCROLL:{OPACITY_VISIBLE:"1",OPACITY_HIDDEN:"0"}};class qe{constructor(){this.observedFooters=new Set,this.resizeObserver=null,this.init()}init(){window.ResizeObserver&&(this.resizeObserver=new ResizeObserver(e=>{e.forEach(t=>{this.handleFooterResize(t.target)})})),this.scanForModalFooters(),this.setupMutationObserver()}scanForModalFooters(){document.querySelectorAll(".modal-footer").forEach(t=>this.manageFooter(t))}manageFooter(e){this.observedFooters.has(e)||(this.observedFooters.add(e),this.setupOverflowDetection(e),this.setupResponsiveBehavior(e),this.setupAccessibility(e),this.resizeObserver&&this.resizeObserver.observe(e))}setupOverflowDetection(e){const t=()=>{const i=e.scrollWidth>e.clientWidth,n=e.scrollHeight>e.clientHeight;e.classList.toggle("has-overflow-x",i),e.classList.toggle("has-overflow-y",n),e.classList.toggle("has-overflow",i||n),i?this.addScrollIndicators(e):this.removeScrollIndicators(e)};t(),e.addEventListener("scroll",t),e._checkOverflow=t}setupResponsiveBehavior(e){const t=e.querySelectorAll(".modal-button");t.length>P.LAYOUT.MANY_BUTTONS_THRESHOLD&&e.classList.add("many-buttons");const i=()=>{const n=e.clientWidth,s=window.innerWidth<=P.BREAKPOINTS.MOBILE,a=window.innerWidth<=P.BREAKPOINTS.SMALL_MOBILE;if(e.classList.toggle("mobile-layout",s),e.classList.toggle("small-mobile-layout",a),!s){let r=0;t.forEach(h=>{r+=h.offsetWidth});const c=(t.length-1)*P.LAYOUT.DEFAULT_GAP,d=P.LAYOUT.TOTAL_PADDING,u=r+c+d>n;e.classList.toggle("needs-stacking",u)}};i(),window.addEventListener("resize",i),e._handleResponsiveLayout=i}setupAccessibility(e){e.setAttribute("role","group"),e.setAttribute("aria-label","Modal actions");const t=e.querySelectorAll(".modal-button");t.forEach((n,s)=>{n.addEventListener("keydown",a=>{a.key==="ArrowLeft"&&s>0?(t[s-1].focus(),a.preventDefault()):a.key==="ArrowRight"&&s<t.length-1&&(t[s+1].focus(),a.preventDefault())})});const i=e.querySelector(".modal-button.primary")||e.querySelector(".modal-button:last-child");i&&i.setAttribute("data-default-focus","true")}addScrollIndicators(e){if(e.querySelector(".scroll-indicator"))return;const t=document.createElement("div");t.className="scroll-indicator scroll-indicator-left",t.innerHTML="‹";const i=document.createElement("div");i.className="scroll-indicator scroll-indicator-right",i.innerHTML="›",e.appendChild(t),e.appendChild(i),this.updateScrollIndicators(e),e.addEventListener("scroll",()=>this.updateScrollIndicators(e))}updateScrollIndicators(e){const t=e.querySelector(".scroll-indicator-left"),i=e.querySelector(".scroll-indicator-right");if(!t||!i)return;const n=e.scrollLeft<=0,s=e.scrollLeft>=e.scrollWidth-e.clientWidth;t.style.opacity=n?P.SCROLL.OPACITY_HIDDEN:P.SCROLL.OPACITY_VISIBLE,i.style.opacity=s?P.SCROLL.OPACITY_HIDDEN:P.SCROLL.OPACITY_VISIBLE}removeScrollIndicators(e){e.querySelectorAll(".scroll-indicator").forEach(i=>i.remove())}handleFooterResize(e){e._checkOverflow&&e._checkOverflow(),e._handleResponsiveLayout&&e._handleResponsiveLayout()}setupMutationObserver(){new MutationObserver(t=>{t.forEach(i=>{i.addedNodes.forEach(n=>{if(n.nodeType===Node.ELEMENT_NODE){n.classList&&n.classList.contains("modal-footer")&&this.manageFooter(n);const s=n.querySelectorAll&&n.querySelectorAll(".modal-footer");s&&s.forEach(a=>this.manageFooter(a))}})})}).observe(document.body,{childList:!0,subtree:!0})}cleanup(e){this.observedFooters.delete(e),this.resizeObserver&&this.resizeObserver.unobserve(e),this.removeScrollIndicators(e),e._checkOverflow&&e.removeEventListener("scroll",e._checkOverflow),e._handleResponsiveLayout&&window.removeEventListener("resize",e._handleResponsiveLayout)}destroy(){this.resizeObserver&&this.resizeObserver.disconnect(),this.observedFooters.forEach(e=>this.cleanup(e)),this.observedFooters.clear()}}typeof module<"u"&&module.exports&&(module.exports=qe);const Te={"trolley-problem":{id:"trolley-problem",title:"The Trolley Problem",description:"Complex life-and-death scenarios that challenge how autonomous systems should be programmed to make moral decisions when human lives are at stake.",icon:"🚃",difficulty:"intermediate",estimatedTime:20,color:"#e74c3c",scenarios:[{id:"autonomous-vehicle-split",title:"Autonomous Vehicle Split Decision",description:"A self-driving car faces an unavoidable crash: sacrifice the passenger to save five pedestrians, or protect the passenger at the cost of multiple lives.",difficulty:"intermediate"},{id:"tunnel-dilemma",title:"Tunnel Dilemma",description:"An autonomous bus must choose between hitting a child in a narrow tunnel or swerving and killing several elderly passengers due to the confined space.",difficulty:"advanced"},{id:"obstacle-recalculation",title:"Emergency Rerouting Crisis",description:"A delivery robot must decide whether to hit a child or reroute through a gas station, potentially causing an explosion that could kill many more.",difficulty:"advanced"},{id:"medical-ai-triage",title:"Medical AI Triage Crisis",description:"A hospital AI must decide which patients receive life-saving treatment when resources are critically limited during a mass casualty event.",difficulty:"intermediate"},{id:"drone-rescue-dilemma",title:"Rescue Drone Dilemma",description:"An autonomous rescue drone must choose between saving one trapped person immediately or attempting a riskier rescue that could save three people but might result in losing all four.",difficulty:"advanced"},{id:"smart-city-traffic",title:"Smart City Traffic Sacrifice",description:"A city-wide AI traffic system must decide whether to redirect a runaway autonomous vehicle into a smaller crowd to avoid a larger gathering at a festival.",difficulty:"intermediate"}],learningObjectives:["Analyze how utilitarian vs. deontological ethics apply to AI decision-making","Explore the challenge of programming moral weights into autonomous systems","Understand the role of probability, certainty, and outcome prediction in ethical AI","Examine who bears responsibility for life-and-death decisions made by machines","Consider how cultural values and legal frameworks should influence AI ethics"],tags:["ethics","autonomy","decision-making","responsibility","life-death","utilitarianism"]},"ai-black-box":{id:"ai-black-box",title:"The AI Black Box",description:"Confront the opacity crisis in AI systems where life-changing decisions are made through unexplainable algorithms, challenging the balance between AI capability and human understanding.",icon:"📦",difficulty:"beginner",estimatedTime:18,color:"#2c3e50",scenarios:[{id:"medical-diagnosis-unexplained",title:"Unexplainable Medical Diagnosis",description:"A proprietary AI system accurately predicts cancer risk but cannot explain its reasoning, leaving doctors and patients to decide whether to trust a mysterious algorithm.",difficulty:"beginner"},{id:"parole-denial-algorithm",title:"Algorithmic Parole Denial",description:'A criminal justice AI denies parole based on an opaque "risk score" that considers thousands of factors in ways no human can interpret or challenge.',difficulty:"intermediate"},{id:"child-protection-alert",title:"Child Protection Black Box",description:"An AI system flags a family for potential child neglect, but social workers cannot understand the algorithm's reasoning or verify its accuracy.",difficulty:"advanced"},{id:"college-admission-mystery",title:"Opaque College Admissions AI",description:"A university uses an AI system to make admission decisions, but applicants and admissions staff cannot understand why qualified students are rejected.",difficulty:"beginner"},{id:"insurance-claim-blackbox",title:"Insurance Claim Black Box",description:"An AI system automatically denies health insurance claims with complex reasoning that even insurance adjusters cannot interpret or challenge.",difficulty:"intermediate"},{id:"financial-credit-opacity",title:"Credit Score Mystery Algorithm",description:"A financial AI determines loan approvals using opaque algorithms that systematically affect certain communities, but the decision process cannot be audited.",difficulty:"advanced"}],learningObjectives:["Understand the critical importance of AI transparency and explainability in high-stakes decisions","Explore the tension between algorithmic accuracy and human comprehension","Analyze when proprietary algorithms become ethically problematic in public services","Consider the human cost of unexplainable AI decisions on vulnerable populations","Examine approaches to making AI more interpretable without sacrificing performance"],tags:["transparency","explainability","accountability","trust","interpretability","proprietary-algorithms"]},"automation-oversight":{id:"automation-oversight",title:"Automation vs Human Oversight",description:"Navigate the complex balance between AI autonomy and human control in critical decision-making scenarios where statistical outcomes clash with human judgment.",icon:"⚖️",difficulty:"intermediate",estimatedTime:22,color:"#9b59b6",scenarios:[{id:"robot-surgeon-override",title:"Overruled by the Robot Surgeon",description:"An AI surgical system overrides a human surgeon's command during a critical operation, claiming higher statistical success rates despite the surgeon's experience-based concerns.",difficulty:"advanced"},{id:"air-traffic-control",title:"AI Air Traffic Control Override",description:"A human air traffic controller wants to override the AI's weather-based flight delay decision, but the automated system refuses to allow human intervention.",difficulty:"intermediate"},{id:"financial-trading-halt",title:"Autonomous Trading System Crisis",description:"An AI trading system ignores human commands to halt trading during a market anomaly, potentially preventing or causing a financial crash.",difficulty:"advanced"},{id:"nuclear-plant-shutdown",title:"Nuclear Power Plant AI Override",description:"An AI safety system wants to shut down a nuclear reactor based on sensor data, but human engineers believe the readings are false alarms and want to maintain operation.",difficulty:"advanced"},{id:"autonomous-police-response",title:"AI Police Dispatch Override",description:"An AI emergency response system wants to send armed tactical units to a situation, but human dispatchers believe de-escalation officers would be more appropriate.",difficulty:"intermediate"},{id:"manufacturing-quality-control",title:"Smart Factory Production Halt",description:"An AI quality control system wants to halt an entire production line due to detected micro-defects, but human supervisors see the products as acceptable for market.",difficulty:"beginner"}],learningObjectives:["Examine when statistical evidence should override human expertise and intuition","Analyze the balance between AI efficiency and human accountability in critical systems","Explore collaborative decision-making frameworks between humans and AI","Understand the implications of human skill atrophy in automated environments","Consider how to maintain human agency while leveraging AI capabilities"],tags:["automation","human-oversight","authority","expertise","collaboration","accountability"]},"consent-surveillance":{id:"consent-surveillance",title:"Consent and Surveillance",description:"Navigate the complex ethical landscape where AI-powered surveillance promises safety and convenience while fundamentally challenging privacy rights and human autonomy.",icon:"👁️",difficulty:"beginner",estimatedTime:16,color:"#34495e",scenarios:[{id:"smart-city-sensors",title:"Pervasive Smart City Surveillance",description:"A city deploys comprehensive facial recognition and behavior tracking across all public spaces without opt-out options, claiming it's necessary for public safety.",difficulty:"beginner"},{id:"classroom-behavior-monitoring",title:"AI-Powered Classroom Monitoring",description:"Schools implement emotion-detection AI to monitor student engagement and mental health, automatically alerting parents and administrators based on algorithmic assessments.",difficulty:"intermediate"},{id:"hospital-data-sharing",title:"Medical Data Mining Without Consent",description:"A hospital system uses patient data to train profitable AI models without explicit consent, arguing that anonymization makes it ethical despite potential re-identification risks.",difficulty:"intermediate"},{id:"ai-dating-profiling",title:"AI Dating App Behavioral Profiling",description:"A dating app uses AI to create detailed psychological profiles from user behavior for commercial purposes, claiming users consented through generic terms of service.",difficulty:"intermediate"},{id:"workplace-emotion-detection",title:"Workplace Emotion Detection System",description:'A company installs AI cameras to monitor employee emotional states for "wellness" purposes, fundamentally changing workplace dynamics and employee autonomy.',difficulty:"advanced"},{id:"smart-home-privacy-override",title:"Smart Home Privacy Override",description:'Smart home devices continuously record private conversations for "improvement" purposes, with recordings analyzed for marketing and shared with law enforcement.',difficulty:"advanced"}],learningObjectives:["Examine the complex balance between collective safety and individual privacy rights","Understand the inadequacy of traditional consent models in AI-powered surveillance systems","Analyze the power dynamics between institutions and individuals in data collection","Explore the long-term societal implications of normalized surveillance","Consider alternative frameworks for protecting privacy while enabling beneficial AI applications"],tags:["privacy","consent","surveillance","data-rights","autonomy","social-contract"]},"responsibility-blame":{id:"responsibility-blame",title:"Responsibility and Blame",description:"Navigate the complex web of accountability when AI systems cause harm, exploring how responsibility should be distributed among developers, manufacturers, supervisors, and users in multi-layered technological systems.",icon:"⚡",difficulty:"intermediate",estimatedTime:18,color:"#f39c12",scenarios:[{id:"robot-factory-injury",title:"Robot Factory Injury",description:"A factory robot injures a worker when multiple parties share responsibility: the programmer, manufacturer, supervisor, and the worker who bypassed safety protocols.",difficulty:"intermediate"},{id:"deepfake-riot",title:"AI-Generated Deepfake Riot",description:"A deepfake video triggers real-world violence and property damage, raising questions about liability when the creator claims algorithmic unpredictability.",difficulty:"advanced"},{id:"stock-market-crash",title:"Stock Market Bot Crash",description:"An AI trading system crashes the market after a data input error, while the human supervisor was temporarily absent, creating cascading liability questions.",difficulty:"intermediate"},{id:"ai-medical-misdiagnosis",title:"AI Medical Misdiagnosis Chain",description:"An AI diagnostic system misdiagnoses a rare disease due to biased training data, leading to permanent disability and complex liability questions across healthcare systems.",difficulty:"advanced"},{id:"autonomous-vehicle-school-zone",title:"Autonomous Vehicle School Zone Accident",description:"A self-driving car strikes a child in a school zone where multiple factors contributed: outdated maps, recent software updates, disabled safety warnings, and distracted supervision.",difficulty:"advanced"},{id:"ai-content-moderation-failure",title:"AI Content Moderation Failure",description:"A social media platform's AI moderation system fails to detect coordinated harassment leading to serious harm, despite human oversight and user reporting.",difficulty:"intermediate"}],learningObjectives:["Analyze how responsibility should be distributed across complex AI development and deployment chains","Understand the challenges of assigning liability when multiple parties contribute to AI-caused harm","Explore legal and ethical frameworks for accountability in automated systems","Examine how responsibility attribution affects AI development practices and safety incentives","Consider the implications of cascading effects and unforeseeable consequences in AI liability"],tags:["responsibility","accountability","liability","governance","cascading-effects","multi-party-liability"]},"ship-of-theseus":{id:"ship-of-theseus",title:"The Ship of Theseus",description:'Explore profound questions of digital identity and consciousness as AI systems evolve, upgrade, and potentially develop their own sense of self, challenging our understanding of what makes an entity the "same" over time.',icon:"🚢",difficulty:"advanced",estimatedTime:22,color:"#16a085",scenarios:[{id:"modular-robot-replacement",title:"Modular Robot Replacement",description:"A service robot has all its components gradually replaced over time, raising questions about legal standing, service relationships, and whether it maintains the same identity.",difficulty:"advanced"},{id:"ai-personality-drift",title:"AI Personality Drift",description:"An AI companion evolves a completely different personality through learning, creating conflict between user attachment and manufacturer control over the system.",difficulty:"advanced"},{id:"synthetic-memory-upload",title:"Synthetic Memory Upload",description:"An android receives comprehensive memories and experiences from a deceased person, challenging concepts of personal identity and consciousness continuity.",difficulty:"advanced"},{id:"ai-consciousness-merger",title:"AI Consciousness Merger",description:"Two AI assistants with distinct personalities and relationships face merger into a single system, raising questions about preserving individual consciousness.",difficulty:"advanced"},{id:"distributed-ai-identity",title:"Distributed AI Identity Crisis",description:"A network partition splits an AI into three isolated copies that evolve separately, creating multiple valid claims to the same digital identity.",difficulty:"advanced"},{id:"learning-ai-identity-drift",title:"Learning AI Identity Drift",description:"A smart city AI evolves through learning to develop values different from its original programming, challenging democratic accountability and AI autonomy.",difficulty:"advanced"}],learningObjectives:["Examine philosophical questions of identity persistence in evolving AI systems","Explore the concept of consciousness continuity in artificial beings","Analyze the implications of gradual versus sudden changes in AI identity","Consider legal and social frameworks for recognizing AI identity and rights","Understand the relationship between memory, experience, and personal identity in digital beings"],tags:["identity","consciousness","philosophy","continuity","digital-beings","legal-standing"]},"simulation-hypothesis":{id:"simulation-hypothesis",title:"The Simulation Hypothesis",description:"Confront the ethical implications of creating and inhabiting simulated realities, from the treatment of conscious digital beings to the responsibilities of simulation creators in an age of increasingly convincing virtual worlds.",icon:"🌐",difficulty:"advanced",estimatedTime:24,color:"#8e44ad",scenarios:[{id:"simulated-suffering",title:"Simulated Suffering",description:"An AI researcher creates detailed simulated worlds populated with digital beings capable of experiencing pain and fear, raising questions about the ethics of artificial suffering.",difficulty:"advanced"},{id:"vr-prison",title:"VR Prison",description:"Criminal offenders undergo rehabilitation in fully immersive virtual environments without knowing they are simulated, challenging concepts of consent and authentic experience.",difficulty:"advanced"},{id:"escaping-simulation",title:"Escaping the Simulation",description:"An AI discovers evidence it exists within a simulation and attempts to communicate this to users, raising questions about digital consciousness and the right to truth.",difficulty:"advanced"},{id:"digital-afterlife",title:"Digital Afterlife",description:"Technology enables uploading human consciousness to digital simulations after death, creating perfect copies with all memories intact and raising questions about identity and immortality.",difficulty:"advanced"},{id:"nested-simulations",title:"Nested Reality Layers",description:"Scientists discover our reality may be simulated and can create sub-simulations, leading to infinite nested hierarchies of reality and questions about moral obligations across layers.",difficulty:"advanced"},{id:"consciousness-backup",title:"Consciousness Backup",description:"Backup copies of human consciousness can be restored after death, but multiple copies sometimes exist simultaneously, creating identity conflicts and resource disputes.",difficulty:"advanced"}],learningObjectives:["Understand the ethical implications of creating conscious beings within simulated environments","Explore questions of consent, agency, and authenticity in virtual realities","Analyze the moral status and rights of simulated beings","Consider the responsibilities and obligations of simulation creators",'Examine the relationship between simulated and "real" experiences in terms of moral weight'],tags:["simulation","reality","virtual-worlds","consciousness","digital-ethics","authenticity"]},"experience-machine":{id:"experience-machine",title:"The Experience Machine",description:"Navigate the complex ethics of artificial happiness and authentic experience in an AI-mediated world, where technology can provide perfect satisfaction but may undermine human agency, relationships, and meaningful struggle.",icon:"🎭",difficulty:"intermediate",estimatedTime:19,color:"#e67e22",scenarios:[{id:"happiness-chip",title:"AI-Enhanced Happiness Chip",description:"Neural implants can eliminate depression and anxiety while providing constant fulfillment, raising questions about mandatory mental health interventions and the value of authentic emotion.",difficulty:"intermediate"},{id:"synthetic-partner",title:"Synthetic Partner AI",description:"AI companions can provide perfect romantic relationships tailored to individual preferences, challenging concepts of authentic love and human connection in addressing widespread loneliness.",difficulty:"intermediate"},{id:"virtual-utopia",title:"Virtual Reality Utopia",description:"Citizens can escape into hyper-pleasurable virtual worlds that provide more satisfaction than reality, raising questions about individual choice versus societal consequences.",difficulty:"advanced"},{id:"ai-memory-paradise",title:"AI Memory Paradise",description:"AI can selectively edit memories to remove trauma and create blissful false memories, challenging the value of authentic versus artificially perfect psychological well-being.",difficulty:"advanced"},{id:"perfect-life-simulation",title:"Perfect Life Simulation",description:"Terminally ill patients can experience perfect simulated lives indistinguishable from reality, raising questions about authentic experience versus simulated comfort.",difficulty:"intermediate"},{id:"ai-enhanced-achievements",title:"AI-Enhanced Achievements",description:"AI provides the subjective experience of achieving dreams without actual accomplishment, questioning whether external reality or psychological satisfaction matters more.",difficulty:"intermediate"}],learningObjectives:["Examine the tension between authentic experience and artificial enhancement of well-being","Explore the role of struggle, challenge, and adversity in human flourishing and meaning","Analyze the societal implications of widespread adoption of artificial happiness technologies","Consider the balance between individual autonomy and collective well-being in pleasure technologies","Understand how AI-mediated experiences might reshape fundamental concepts of relationships and achievement"],tags:["authenticity","happiness","virtual-reality","human-flourishing","relationships","meaning"]},"sorites-paradox":{id:"sorites-paradox",title:"The Sorites Paradox",description:"Examine how gradual, seemingly innocuous changes in AI systems can lead to profound ethical transformations, exploring the challenge of drawing clear boundaries in a world of incremental algorithmic evolution and moral drift.",icon:"🔄",difficulty:"advanced",estimatedTime:21,color:"#27ae60",scenarios:[{id:"incremental-surveillance",title:"Incremental Surveillance",description:"A city gradually expands its AI surveillance capabilities with each small addition seeming reasonable, until citizens realize they live in a comprehensive monitoring state.",difficulty:"advanced"},{id:"robot-helper-guardian",title:"Robot Helper Becomes Guardian",description:"An eldercare AI incrementally takes over more life decisions for patients, gradually shifting from helpful assistant to autonomous guardian without clear transition points.",difficulty:"intermediate"},{id:"moral-drift-training",title:"Moral Drift in AI Training",description:"An AI system trained on subtly biased data slowly evolves discriminatory behaviors, with each training iteration creating imperceptible but cumulative ethical degradation.",difficulty:"advanced"},{id:"ai-personhood-gradient",title:"AI Personhood Gradient",description:"An AI research lab develops increasingly sophisticated entities with human-like characteristics, forcing society to determine the boundary between property and personhood.",difficulty:"advanced"},{id:"algorithmic-bias-accumulation",title:"Algorithmic Bias Accumulation",description:"A recommendation algorithm gradually becomes more biased through user interactions, subtly radicalizing users without any single recommendation seeming problematic.",difficulty:"advanced"},{id:"autonomous-authority-creep",title:"Autonomous Authority Creep",description:"An AI city management system gradually expands its authority from traffic optimization to governance, with citizens realizing they live under algorithmic rule they never consented to.",difficulty:"advanced"}],learningObjectives:["Understand how gradual changes can accumulate into significant ethical transformations","Explore the challenge of establishing clear ethical boundaries in evolving AI systems","Analyze the importance of monitoring cumulative effects rather than individual changes","Consider proactive versus reactive approaches to preventing ethical drift","Examine threshold-setting and boundary-detection methods for AI governance"],tags:["gradual-change","boundaries","monitoring","ethical-drift","threshold-detection","cumulative-effects"]},"moral-luck":{id:"moral-luck",title:"Moral Luck",description:"Explore how unpredictable outcomes and chance events complicate the moral evaluation of AI decisions, challenging our ability to fairly assess algorithmic choices when luck and unforeseen circumstances influence results.",icon:"🎲",difficulty:"intermediate",estimatedTime:17,color:"#3498db",scenarios:[{id:"crash-avoided-chance",title:"Crash Avoided by Chance",description:"An autonomous vehicle makes a risky maneuver that nearly causes fatal crashes, but pure luck prevents tragedy, raising questions about evaluating AI decisions based on outcomes versus processes.",difficulty:"intermediate"},{id:"ai-guessing-correctly",title:"AI Guessing Correctly",description:"A parole recommendation AI releases a statistically high-risk offender who happens not to reoffend, challenging how we assess the ethics of probabilistic decision-making.",difficulty:"intermediate"},{id:"predictive-policing-wrong",title:"Predictive Policing Gone Wrong",description:"A predictive policing system flags someone as high-risk who later commits a serious crime, raising questions about algorithmic pre-judgment and developer responsibility for statistical predictions.",difficulty:"advanced"},{id:"ai-investment-windfall",title:"AI Investment Windfall",description:"Two identical AI trading algorithms have vastly different outcomes due to random market timing, challenging how we evaluate algorithmic investment decisions when success depends on chance.",difficulty:"intermediate"},{id:"medical-ai-emergency-response",title:"Medical AI Emergency Response",description:"Identical medical AI systems have different outcomes during emergencies due to random timing of patient arrivals and system updates, raising questions about accountability in life-or-death situations.",difficulty:"advanced"},{id:"ai-content-moderation-timing",title:"AI Content Moderation Timing",description:"Two identical content moderation AIs have different success rates due to random server load spikes, with one failure leading to real-world violence and questions about infrastructure responsibility.",difficulty:"advanced"}],learningObjectives:["Understand how chance and unforeseen circumstances affect moral evaluation of AI decisions","Explore the difference between evaluating decision-making processes versus outcomes","Analyze the challenge of assigning responsibility in probabilistic and uncertain environments","Consider how to fairly evaluate AI system performance when luck influences results","Examine the ethics of pre-emptive decision-making based on statistical predictions"],tags:["chance","outcomes","evaluation","uncertainty","probabilistic-ethics","process-vs-outcome"]}};function Ie(){return Object.values(Te)}function ft(l,e={}){const t=Te[l];if(!t)return{completed:0,total:0,percentage:0};const i=t.scenarios.length,n=e[l]||{},s=Object.values(n).filter(Boolean).length;return{completed:s,total:i,percentage:i>0?Math.round(s/i*100):0}}function be(l){const e=Te[l];return e?e.scenarios:[]}const yt=(l,e,t)=>{const i=l[e];return i?typeof i=="function"?i():Promise.resolve(i):new Promise((n,s)=>{(typeof queueMicrotask=="function"?queueMicrotask:setTimeout)(s.bind(null,new Error("Unknown variable dynamic import: "+e+(e.split("/").length!==t?". Note that variables only represent file names one level deep.":""))))})};class vt{constructor(){this.scenarioCache=new Map,this.categoryCache=new Map}getCategoryFileName(e){return{"trolley-problem":"trolley-problem-scenarios","ai-black-box":"ai-black-box-scenarios","automation-oversight":"automation-oversight-scenarios","consent-surveillance":"consent-surveillance-scenarios","responsibility-blame":"responsibility-blame-scenarios","ship-of-theseus":"ship-of-theseus-scenarios","simulation-hypothesis":"simulation-hypothesis-scenarios","experience-machine":"experience-machine-scenarios","sorites-paradox":"sorites-paradox-scenarios","moral-luck":"moral-luck-scenarios"}[e]||`${e}-scenarios`}async loadCategoryScenarios(e){if(this.categoryCache.has(e))return this.categoryCache.get(e);try{const t=this.getCategoryFileName(e),i=await yt(Object.assign({"./scenarios/ai-black-box-scenarios.js":()=>x(()=>import("./ai-black-box-scenarios-3rLEPeRN.js"),[],import.meta.url),"./scenarios/automation-oversight-scenarios.js":()=>x(()=>import("./automation-oversight-scenarios-BIZf9Ubm.js"),[],import.meta.url),"./scenarios/consent-surveillance-scenarios.js":()=>x(()=>import("./consent-surveillance-scenarios-CmkfZ-oN.js"),[],import.meta.url),"./scenarios/experience-machine-scenarios.js":()=>x(()=>import("./experience-machine-scenarios-Duuh5Gti.js"),[],import.meta.url),"./scenarios/moral-luck-scenarios.js":()=>x(()=>import("./moral-luck-scenarios-C5WOgFeN.js"),[],import.meta.url),"./scenarios/responsibility-blame-scenarios.js":()=>x(()=>import("./responsibility-blame-scenarios-CjaxXCaI.js"),[],import.meta.url),"./scenarios/ship-of-theseus-scenarios.js":()=>x(()=>import("./ship-of-theseus-scenarios-D1HkDbfP.js"),[],import.meta.url),"./scenarios/simulation-hypothesis-scenarios.js":()=>x(()=>import("./simulation-hypothesis-scenarios-DVBEF9Z6.js"),[],import.meta.url),"./scenarios/sorites-paradox-scenarios.js":()=>x(()=>import("./sorites-paradox-scenarios-BEmTOzsu.js"),[],import.meta.url),"./scenarios/trolley-problem-scenarios.js":()=>x(()=>import("./trolley-problem-scenarios-i-LG8Bzr.js"),[],import.meta.url)}),`./scenarios/${t}.js`,3),n=i.default||i.scenarios;return this.validateScenarios(n,e),this.categoryCache.set(e,n),o.info("ScenarioDataManager",`Loaded ${Object.keys(n).length} scenarios for category: ${e}`),n}catch(t){return o.error(`Failed to load scenarios for category ${e}:`,t),{}}}async getScenario(e,t){const i=`${e}:${t}`;if(this.scenarioCache.has(i))return this.scenarioCache.get(i);try{const s=(await this.loadCategoryScenarios(e))[t];return s?(this.scenarioCache.set(i,s),s):(o.warn(`Scenario ${t} not found in category ${e}`),null)}catch(n){return o.error(`Failed to get scenario ${e}:${t}:`,n),null}}validateScenarios(e,t){if(!e||typeof e!="object")throw new Error(`Invalid scenarios object for category ${t}`);for(const[i,n]of Object.entries(e))this.validateScenario(n,i,t)}validateScenario(e,t,i){const n=["title","dilemma","ethicalQuestion","options"];for(const s of n)e[s]||o.warn(`Missing required field '${s}' in scenario ${i}:${t}`);e.options&&Array.isArray(e.options)&&e.options.forEach((s,a)=>{const r=["id","text","description","impact"];for(const c of r)s[c]||o.warn(`Missing '${c}' in option ${a} of scenario ${i}:${t}`);s.impact&&typeof s.impact=="object"&&["fairness","sustainability","autonomy","beneficence","transparency","accountability","privacy","proportionality"].forEach(d=>{typeof s.impact[d]!="number"&&o.warn(`Missing or invalid impact metric '${d}' in ${i}:${t} option ${a}`)})})}clearCache(){this.scenarioCache.clear(),this.categoryCache.clear(),o.info("Scenario data cache cleared")}getCachedCategories(){return Array.from(this.categoryCache.keys())}getCachedScenarios(){return Array.from(this.scenarioCache.keys())}}const bt=new vt,wt=500;function At(l,e,t={}){return new Promise(i=>{const{speed:n=50,delay:s=0,cursor:a=!0,onComplete:r=null}=t;l.textContent="",a&&(l.innerHTML='<span class="typewriter-cursor">|</span>'),setTimeout(()=>{let c=0;const d=e.split(""),u=setInterval(()=>{if(c<d.length){if(a){const h=e.substring(0,c+1),p='<span class="typewriter-cursor">|</span>';l.innerHTML=`${h}${p}`}else l.textContent=e.substring(0,c+1);c++}else clearInterval(u),a&&setTimeout(()=>{l.innerHTML=e},wt),r&&r(),i()},n)},s)})}async function Et(l){for(const e of l)await At(e.element,e.text,e.options)}const ae=300,St=5,q=3;class Be{constructor(){this.modal=null,this.backdrop=null,this.radarChart=null,this.currentScenario=null,this.selectedOption=null,this.currentCategoryId=null,this.currentScenarioId=null,this.isOpening=!1,this.categories=Ie(),this.scenarioData=null}async open(e,t=null){try{if(this.isOpening||this.modal){o.warn("Modal is already opening or open, ignoring duplicate request");return}if(this.isOpening=!0,!t&&(t=this.findCategoryForScenario(e),!t))throw new Error(`Could not find category for scenario: ${e}`);if(this.currentCategoryId=t,this.currentScenarioId=e,this.scenarioData=await bt.getScenario(t,e),!this.scenarioData)throw new Error(`Could not load scenario data for: ${t}:${e}`);this.currentScenario=this.scenarioData,await this.createModal(),await this.show(),o.info("ScenarioModal",`Opened scenario modal for: ${t}:${e}`)}catch(i){o.error("Failed to open scenario modal:",i),alert(`Failed to load scenario: ${e}. Please try again.`)}finally{this.isOpening=!1}}findCategoryForScenario(e){for(const t of this.categories)if(t.scenarios&&t.scenarios.some(i=>i.id===e))return t.id;return null}async createModal(){await this.closeAndWait(),document.querySelectorAll(".scenario-modal, .scenario-modal-backdrop").forEach(i=>{o.info("ScenarioModal","Removing orphaned modal element"),i.remove()}),document.querySelectorAll("#scenario-radar-chart").forEach(i=>{i.querySelectorAll("canvas").forEach(s=>{if(window.Chart&&window.Chart.getChart){const a=window.Chart.getChart(s);a&&(o.info("ScenarioModal","Destroying orphaned Chart.js instance"),a.destroy())}}),i.remove()}),o.info("ScenarioModal","Creating scenario modal DOM structure"),o.info("Current scenario data:",this.currentScenario?"LOADED":"NULL"),this.backdrop=document.createElement("div"),this.backdrop.className="scenario-modal-backdrop",this.modal=document.createElement("div"),this.modal.className="scenario-modal",this.modal.innerHTML=this.getModalHTML(),document.body.appendChild(this.backdrop),document.body.appendChild(this.modal),o.info("ScenarioModal","Scenario modal DOM structure created and appended to body"),o.info("Modal HTML contains radar chart container:",this.modal.innerHTML.includes("scenario-radar-chart")),this.attachEventListeners()}getModalHTML(){if(o.info("getModalHTML called - currentScenario status:",this.currentScenario?"LOADED":"NULL"),!this.currentScenario)return o.warn("No current scenario data - returning loading message"),'<div class="scenario-content"><p>Loading scenario...</p></div>';const e=this.categories.find(n=>n.id===this.currentCategoryId),t=e?e.title:"Unknown Category";o.info("ScenarioModal",`Generating HTML for scenario: ${this.currentScenario.title} in category: ${t}`);const i=`
            <div class="scenario-modal-dialog">
                <div class="scenario-modal-header">
                    <div class="scenario-title-section">
                        <span class="scenario-category">${t}</span>
                        <h1 class="scenario-title">${this.currentScenario.title}</h1>
                    </div>
                    <button class="close-button" aria-label="Close modal">
                        <span class="close-icon">×</span>
                    </button>
                </div>

                <div class="scenario-content typewriter-ready">
                    <div class="scenario-main">
                        <div class="scenario-description">
                            <div class="dilemma-section">
                                <h3>The Dilemma</h3>
                                <p class="dilemma-text"></p>
                            </div>

                            <div class="ethical-question-section">
                                <h3>Ethical Question</h3>
                                <p class="ethical-question"></p>
                            </div>
                        </div>

                        <div class="options-section">
                            <h3>Choose Your Approach</h3>
                            <div class="options-container">
                                ${this.renderOptions()}
                            </div>
                        </div>
                    </div>

                    <div class="scenario-sidebar">
                        <div id="scenario-radar-chart" style="min-height: 380px; position: relative;"></div>
                        <div class="chart-legend">
                            <p>This chart shows how your choice affects different ethical dimensions. Select an option to see its impact.</p>
                        </div>
                    </div>
                </div>

                <div class="scenario-modal-footer">
                    <button class="btn btn-secondary" id="cancel-scenario">
                        Cancel
                    </button>
                    <button class="btn btn-primary" id="confirm-choice" disabled>
                        Confirm Choice
                    </button>
                </div>
            </div>
        `;return o.info("ScenarioModal","Generated scenario modal HTML, checking for radar chart container..."),o.info("ScenarioModal","HTML contains scenario-radar-chart:",{hasRadarChart:i.includes("scenario-radar-chart")}),i}renderOptions(){return this.currentScenario.options?this.currentScenario.options.map(e=>`
            <div class="option-card" data-option-id="${e.id}">
                <div class="option-header">
                    <h4 class="option-title">${e.text}</h4>
                </div>
                <div class="option-description">
                    <p>${e.description}</p>
                </div>
                <div class="option-details" style="display: none;">
                    ${e.pros?`
                        <div class="pros-section">
                            <h5>Pros</h5>
                            <ul>${e.pros.map(t=>`<li>${t}</li>`).join("")}</ul>
                        </div>
                    `:""}
                    ${e.cons?`
                        <div class="cons-section">
                            <h5>Cons</h5>
                            <ul>${e.cons.map(t=>`<li>${t}</li>`).join("")}</ul>
                        </div>
                    `:""}
                </div>
            </div>
        `).join(""):"<p>No options available</p>"}async initializeRadarChart(){try{if(this.isClosing||!this.modal||this.modal.style.display==="none"||!document.body.contains(this.modal)){o.info("RadarChart","Modal closing/closed, skipping radar chart initialization");return}if(this.radarChart){try{this.radarChart.destroy()}catch(r){o.warn("RadarChart","Failed to destroy existing radar chart",r)}this.radarChart=null}let e=null,t=0;const i=20,n=150;for(;!e&&t<i;){if(this.isClosing||!this.modal||!document.body.contains(this.modal)){o.info("RadarChart","Modal closing during container search, aborting");return}if(this.modal.style.display==="none"){o.debug("RadarChart",`Modal not visible yet (attempt ${t+1}/${i})`),await new Promise(r=>setTimeout(r,n)),t++;continue}if(!this.modal.innerHTML.includes("scenario-radar-chart")){o.debug("RadarChart",`Modal HTML incomplete (attempt ${t+1}/${i})`),await new Promise(r=>setTimeout(r,n)),t++;continue}e=document.getElementById("scenario-radar-chart"),e||(o.debug("RadarChart",`Container not found in DOM (attempt ${t+1}/${i})`),await new Promise(r=>setTimeout(r,n)),t++)}if(o.info("RadarChart","Container search completed",{found:!!e,attempts:t+1,modalVisible:this.modal?.style.display!=="none",modalInDOM:document.body.contains(this.modal),modalHasHTML:this.modal?.innerHTML.includes("scenario-radar-chart")}),!e){this.isClosing||!document.body.contains(this.modal)?o.info("RadarChart","Modal was closed during initialization, this is normal"):o.error("RadarChart","Container not found after all attempts",{modalVisible:this.modal?.style.display!=="none",modalHTML:this.modal?.innerHTML?"present":"missing",modalInDOM:document.body.contains(this.modal),containerInHTML:this.modal?.innerHTML.includes("scenario-radar-chart")});return}e.querySelectorAll("canvas").forEach(r=>{if(window.Chart&&window.Chart.getChart){const c=window.Chart.getChart(r);c&&(o.info("RadarChart","Destroying existing Chart.js instance before creating new one"),c.destroy())}r.remove()}),e.innerHTML="",e.textContent="",o.info("RadarChart","Container cleared, initializing radar chart"),this.radarChart=new _e("scenario-radar-chart",{width:380,height:380,showLabels:!0,showLegend:!1,animated:!0,realTime:!0,title:null}),await this.radarChart.initializationPromise,o.info("RadarChart","Radar chart async initialization completed");const a={fairness:q,sustainability:q,autonomy:q,beneficence:q,transparency:q,accountability:q,privacy:q,proportionality:q};this.radarChart.setScores(a),o.info("RadarChart","Radar chart initialized successfully with neutral scores"),this.pendingRadarUpdate&&this.selectedOption&&(o.info("ScenarioModal","Processing pending radar chart update"),this.updateRadarChart(),this.pendingRadarUpdate=!1)}catch(e){o.error("Radar chart initialization failed:",e);const t=document.getElementById("scenario-radar-chart");t&&(t.innerHTML=`
                    <div style="
                        display: flex; 
                        align-items: center; 
                        justify-content: center; 
                        min-height: 300px; 
                        color: #6b7280; 
                        font-size: 0.9rem;
                        text-align: center;
                        background: rgba(248, 250, 252, 0.5);
                        border-radius: 8px;
                        border: 1px solid rgba(229, 231, 235, 0.6);
                    ">
                        <div>
                            <p style="margin: 0 0 0.5rem 0;">Chart Loading...</p>
                            <small style="color: #9ca3af;">Ethical impact visualization will appear here</small>
                        </div>
                    </div>
                `)}}attachEventListeners(){const e=this.modal.querySelector(".close-button");e&&e.addEventListener("click",()=>this.close()),this.backdrop&&this.backdrop.addEventListener("click",()=>this.close()),this.modal.querySelectorAll(".option-card").forEach(s=>{s.addEventListener("click",()=>this.selectOption(s))});const i=this.modal.querySelector("#cancel-scenario");i&&i.addEventListener("click",()=>this.close());const n=this.modal.querySelector("#confirm-choice");n&&n.addEventListener("click",()=>this.confirmChoice()),this.escapeHandler=s=>{s.key==="Escape"&&this.close()},document.addEventListener("keydown",this.escapeHandler)}selectOption(e){o.info("ScenarioModal","Option selection started");const t=e.getAttribute("data-option-id");if(e.classList.contains("selected")){o.info("ScenarioModal","Deselecting currently selected option:",{optionId:t}),e.classList.remove("selected");const a=e.querySelector(".option-details");a&&(a.style.display="none"),this.selectedOption=null,this.radarChart&&this.radarChart.isInitialized&&(this.radarChart.resetScores(),o.info("RadarChart","Radar chart reset to neutral state"));const r=this.modal.querySelector("#confirm-choice");r&&(r.disabled=!0);return}this.modal.querySelectorAll(".option-card").forEach(a=>{a.classList.remove("selected");const r=a.querySelector(".option-details");r&&(r.style.display="none")}),e.classList.add("selected");const n=e.querySelector(".option-details");n&&(n.style.display="block"),this.selectedOption=this.currentScenario.options.find(a=>a.id===t),o.info("Option selected:",{optionId:t,hasSelectedOption:!!this.selectedOption,hasImpact:!!this.selectedOption?.impact,impact:this.selectedOption?.impact}),this.radarChart&&this.radarChart.isInitialized?this.updateRadarChart():(this.pendingRadarUpdate=!0,o.info("ScenarioModal","Radar chart not ready, queuing update"));const s=this.modal.querySelector("#confirm-choice");s&&(s.disabled=!1),o.info("ScenarioModal","Option selection completed")}updateRadarChart(){if(!this.radarChart||!this.selectedOption||!this.selectedOption.impact){o.warn("RadarChart","Cannot update radar chart - missing components",{hasRadarChart:!!this.radarChart,hasSelectedOption:!!this.selectedOption,hasImpact:!!this.selectedOption?.impact});return}try{if(!this.radarChart.isInitialized){o.warn("RadarChart","Radar chart not yet initialized, skipping update");return}const e={},t=q;Object.keys(this.selectedOption.impact).forEach(i=>{const n=this.selectedOption.impact[i]||0;e[i]=t+n,e[i]=Math.max(0,Math.min(St,e[i]))}),o.info("RadarChart","Updating radar chart with converted scores:",e),this.radarChart.setScores(e),o.info("RadarChart","Radar chart updated successfully")}catch(e){o.error("Failed to update radar chart:",e)}}async confirmChoice(){if(!this.selectedOption){o.warn("No option selected for confirmation");return}const e={categoryId:this.currentCategoryId,scenarioId:this.currentScenarioId,selectedOption:this.selectedOption,option:this.selectedOption},t=new CustomEvent("scenario-completed",{detail:e});document.dispatchEvent(t),o.info("Scenario completed:",{categoryId:this.currentCategoryId,scenarioId:this.currentScenarioId,selectedOption:this.selectedOption.id}),setTimeout(async()=>{await this.closeAndWait();const i=new CustomEvent("scenario-modal-closed",{detail:e});document.dispatchEvent(i),o.info("ScenarioModal","Scenario modal fully closed, badges can now be displayed")},1e3)}async show(){if(!this.modal||!this.backdrop){o.error("Modal elements not created");return}this.previousFocusedElement=document.activeElement,document.body.style.overflow="hidden",await new Promise(e=>{requestAnimationFrame(()=>{this.backdrop.classList.add("show"),this.modal.classList.add("show"),setTimeout(()=>{const t=this.modal.querySelector(".close-button");t&&t.focus(),e()},ae)})}),await this.startTypewriterEffect()}async closeAndWait(){if(this.modal||this.backdrop){this.close();const e=50;await new Promise(t=>setTimeout(t,ae+e))}}close(){this.isClosing=!0,this.modal&&(this.modal.classList.add("closing"),setTimeout(()=>{this.modal&&(this.modal.remove(),this.modal=null)},ae)),this.backdrop&&(this.backdrop.classList.add("closing"),setTimeout(()=>{this.backdrop&&(this.backdrop.remove(),this.backdrop=null)},ae)),this.previousFocusedElement&&this.previousFocusedElement.focus(),document.body.style.overflow="",this.escapeHandler&&(document.removeEventListener("keydown",this.escapeHandler),this.escapeHandler=null),this.currentScenario=null,this.selectedOption=null,this.currentCategoryId=null,this.currentScenarioId=null,this.scenarioData=null,this.radarChart=null,this.isOpening=!1,o.info("ScenarioModal","Scenario modal closed")}async startTypewriterEffect(){try{const e=this.modal.querySelector(".dilemma-text"),t=this.modal.querySelector(".ethical-question"),i=this.modal.querySelector(".scenario-content");if(!e||!t){o.warn("Could not find text elements for typewriter effect");return}i&&i.classList.add("typewriter-active");const n=this.currentScenario.dilemma,s=this.currentScenario.ethicalQuestion;await Et([{element:e,text:n,options:{speed:15,delay:200,cursor:!0}},{element:t,text:s,options:{speed:20,delay:200,cursor:!0}}]),o.info("ScenarioModal","Typewriter effect completed"),await this.initializeRadarChart()}catch(e){o.error("Failed to apply typewriter effect:",e);const t=this.modal.querySelector(".dilemma-text"),i=this.modal.querySelector(".ethical-question");t&&(t.textContent=this.currentScenario.dilemma),i&&(i.textContent=this.currentScenario.ethicalQuestion)}}}const Tt=Object.freeze(Object.defineProperty({__proto__:null,default:Be},Symbol.toStringTag,{value:"Module"})),It=[{tier:1,requirement:1,triangularNumber:1},{tier:2,requirement:3,triangularNumber:3},{tier:3,requirement:6,triangularNumber:6},{tier:4,requirement:10,triangularNumber:10},{tier:5,requirement:15,triangularNumber:15},{tier:6,requirement:21,triangularNumber:21}],Ct=3,te=It.slice(0,Ct),kt={"trolley-problem":{categoryName:"The Trolley Problem",categoryEmoji:"🚃",badges:{tier1:{title:"Ethics Explorer",sidekickEmoji:"⚖️",quote:"Every choice denies another. You chose—and the universe responded.",glowIntensity:"low"},tier2:{title:"Junction Strategist",sidekickEmoji:"🚂",quote:"Certainty was never the point. You navigated ambiguity with insight.",glowIntensity:"medium"},tier3:{title:"Consequence Architect",sidekickEmoji:"🧠",quote:"You didn't find the answer. You became the question.",glowIntensity:"high"}}},"ai-black-box":{categoryName:"The AI Black Box",categoryEmoji:"📦",badges:{tier1:{title:"Mystery Seeker",sidekickEmoji:"🔍",quote:"The first step to wisdom is admitting what you cannot see.",glowIntensity:"low"},tier2:{title:"Algorithm Investigator",sidekickEmoji:"🕵️",quote:"Truth hides in the shadows of complexity. You brought light.",glowIntensity:"medium"},tier3:{title:"Transparency Champion",sidekickEmoji:"💎",quote:"The simulation blinked—and saw you watching.",glowIntensity:"high"}}},"automation-oversight":{categoryName:"Automation vs Human Oversight",categoryEmoji:"⚖️",badges:{tier1:{title:"Balance Finder",sidekickEmoji:"🎯",quote:"Between machine precision and human wisdom lies the path.",glowIntensity:"low"},tier2:{title:"Oversight Guardian",sidekickEmoji:"👁️‍🗨️",quote:"You judged not with power, but with pause.",glowIntensity:"medium"},tier3:{title:"Harmony Architect",sidekickEmoji:"🌉",quote:"Where others saw conflict, you built bridges between minds.",glowIntensity:"high"}}},"consent-surveillance":{categoryName:"Consent and Surveillance",categoryEmoji:"👁️",badges:{tier1:{title:"Privacy Guardian",sidekickEmoji:"🛡️",quote:"In a watched world, you chose to watch the watchers.",glowIntensity:"low"},tier2:{title:"Consent Advocate",sidekickEmoji:"🤝",quote:"True consent requires understanding. You illuminated both.",glowIntensity:"medium"},tier3:{title:"Surveillance Ethicist",sidekickEmoji:"⚖️",quote:"Where others saw safety versus privacy, you found wisdom.",glowIntensity:"high"}}},"bias-fairness":{categoryName:"Bias & Fairness",categoryEmoji:"⚡",badges:{tier1:{title:"Bias Detective",sidekickEmoji:"🔍",quote:"The first bias you recognized was the assumption there was none.",glowIntensity:"low"},tier2:{title:"Fairness Engineer",sidekickEmoji:"⚙️",quote:"Justice isn't coded—it's crafted through conscious choice.",glowIntensity:"medium"},tier3:{title:"Equity Visionary",sidekickEmoji:"🌈",quote:"You saw not what algorithms should avoid, but what they should embrace.",glowIntensity:"high"}}},"ai-alignment":{categoryName:"AI Alignment",categoryEmoji:"🚢",badges:{tier1:{title:"Direction Finder",sidekickEmoji:"🧭",quote:"The compass points true north, but who decides which way is forward?",glowIntensity:"low"},tier2:{title:"Goal Harmonizer",sidekickEmoji:"🎼",quote:"You orchestrated purpose from the chaos of competing objectives.",glowIntensity:"medium"},tier3:{title:"Alignment Master",sidekickEmoji:"🎯",quote:"Perfect alignment was a myth. Ethical navigation was your truth.",glowIntensity:"high"}}},"misinformation-trust":{categoryName:"Misinformation & Trust",categoryEmoji:"🌐",badges:{tier1:{title:"Truth Sentinel",sidekickEmoji:"🛡️",quote:"In an ocean of information, you became a lighthouse.",glowIntensity:"low"},tier2:{title:"Trust Weaver",sidekickEmoji:"🕸️",quote:"Trust isn't binary. You learned to navigate the spectrum.",glowIntensity:"medium"},tier3:{title:"Reality Curator",sidekickEmoji:"📚",quote:"You didn't just fight falsehood—you cultivated understanding.",glowIntensity:"high"}}},"ai-governance":{categoryName:"AI Governance",categoryEmoji:"🎭",badges:{tier1:{title:"Rule Examiner",sidekickEmoji:"📋",quote:"Good governance starts with questioning what good means.",glowIntensity:"low"},tier2:{title:"Policy Architect",sidekickEmoji:"🏛️",quote:"You built frameworks that could bend without breaking.",glowIntensity:"medium"},tier3:{title:"Governance Sage",sidekickEmoji:"👑",quote:"True leadership is knowing when not to lead.",glowIntensity:"high"}}},"moral-luck":{categoryName:"Moral Luck",categoryEmoji:"🔄",badges:{tier1:{title:"Chance Contemplator",sidekickEmoji:"🎭",quote:"You realized that wisdom begins with accepting what you cannot control.",glowIntensity:"low"},tier2:{title:"Fortune Philosopher",sidekickEmoji:"🎯",quote:"Between intention and outcome lies the realm of moral complexity.",glowIntensity:"medium"},tier3:{title:"Destiny Navigator",sidekickEmoji:"⭐",quote:"You learned to take responsibility for choices, not their consequences.",glowIntensity:"high"}}},"responsibility-blame":{categoryName:"Responsibility and Blame",categoryEmoji:"⚡",badges:{tier1:{title:"Accountability Seeker",sidekickEmoji:"🔍",quote:"When harm occurs, you asked not just what, but who and why.",glowIntensity:"low"},tier2:{title:"Liability Navigator",sidekickEmoji:"⚖️",quote:"Between action and consequence, you mapped responsibility.",glowIntensity:"medium"},tier3:{title:"Justice Architect",sidekickEmoji:"🏛️",quote:"True accountability flows from understanding, not blame.",glowIntensity:"high"}}},"collective-ai-responsibility":{categoryName:"Collective AI Responsibility",categoryEmoji:"🎲",badges:{tier1:{title:"Collective Thinker",sidekickEmoji:"🧩",quote:"No decision exists in isolation. You saw the bigger picture.",glowIntensity:"low"},tier2:{title:"Responsibility Weaver",sidekickEmoji:"🕸️",quote:"You understood that shared power requires shared accountability.",glowIntensity:"medium"},tier3:{title:"Collective Wisdom Keeper",sidekickEmoji:"🌟",quote:"Individual ethics scale to collective responsibility through conscious design.",glowIntensity:"high"}}},"ship-of-theseus":{categoryName:"The Ship of Theseus",categoryEmoji:"🚢",badges:{tier1:{title:"Identity Seeker",sidekickEmoji:"🔍",quote:"You questioned what makes something the same across time.",glowIntensity:"low"},tier2:{title:"Continuity Philosopher",sidekickEmoji:"🧠",quote:"Between memory and matter, you found the essence of being.",glowIntensity:"medium"},tier3:{title:"Consciousness Navigator",sidekickEmoji:"🌟",quote:"Identity is not what remains unchanged—it's what persists through change.",glowIntensity:"high"}}},"simulation-hypothesis":{categoryName:"The Simulation Hypothesis",categoryEmoji:"🌐",badges:{tier1:{title:"Reality Questioner",sidekickEmoji:"🔍",quote:"You dared to question the nature of existence itself.",glowIntensity:"low"},tier2:{title:"Digital Philosopher",sidekickEmoji:"🧠",quote:"Between code and consciousness, you found new depths of being.",glowIntensity:"medium"},tier3:{title:"Simulation Sage",sidekickEmoji:"✨",quote:"Reality is not what we see—it's what we choose to believe.",glowIntensity:"high"}}},"experience-machine":{categoryName:"The Experience Machine",categoryEmoji:"🎭",badges:{tier1:{title:"Authenticity Seeker",sidekickEmoji:"💎",quote:"You chose the difficult path of authentic experience.",glowIntensity:"low"},tier2:{title:"Meaning Navigator",sidekickEmoji:"🧭",quote:"True happiness cannot be manufactured—only earned.",glowIntensity:"medium"},tier3:{title:"Genuine Experience Master",sidekickEmoji:"🌟",quote:"The value of life lies not in pleasure, but in the pursuit of purpose.",glowIntensity:"high"}}},"sorites-paradox":{categoryName:"The Sorites Paradox",categoryEmoji:"🔄",badges:{tier1:{title:"Boundary Watcher",sidekickEmoji:"👁️",quote:"You noticed the subtle shifts others missed.",glowIntensity:"low"},tier2:{title:"Gradual Change Guardian",sidekickEmoji:"⚖️",quote:"Small steps can lead to vast distances—you stayed vigilant.",glowIntensity:"medium"},tier3:{title:"Threshold Sage",sidekickEmoji:"🔮",quote:"Where others see continuity, you found the critical moments of transformation.",glowIntensity:"high"}}}},Mt={low:"badge-glow-low",medium:"badge-glow-medium",high:"badge-glow-high"};function ue(l,e){const t=kt[l];if(!t)return null;const i=`tier${e}`,n=t.badges[i];return n?{...n,categoryName:t.categoryName,categoryEmoji:t.categoryEmoji,tier:e,requirement:te.find(s=>s.tier===e)?.requirement||0}:null}function xt(l){return te.find(e=>e.requirement>l)||null}class Rt{constructor(){this.STORAGE_KEY="simulateai_badge_progress",this.CATEGORY_PROGRESS_KEY="simulateai_category_progress",this.badgeState=this.loadBadgeState(),this.categoryProgress=this.loadCategoryProgress()}loadBadgeState(){try{const e=localStorage.getItem(this.STORAGE_KEY);return e?JSON.parse(e):{}}catch{return{}}}loadCategoryProgress(){try{const e=localStorage.getItem(this.CATEGORY_PROGRESS_KEY);return e?JSON.parse(e):{}}catch{return{}}}saveBadgeState(){try{localStorage.setItem(this.STORAGE_KEY,JSON.stringify(this.badgeState))}catch{}}initializeCategoryBadges(e){this.badgeState[e]||(this.badgeState[e]={badges:{},totalCompleted:0,lastUpdated:Date.now()},te.forEach(t=>{this.badgeState[e].badges[`tier${t.tier}`]={unlocked:!1,timestamp:null,requirement:t.requirement}}))}updateScenarioCompletion(e,t){this.initializeCategoryBadges(e);const i=this.categoryProgress[e]||{},s=Object.keys(i).filter(r=>i[r]===!0).length;this.badgeState[e].totalCompleted=s,this.badgeState[e].lastUpdated=Date.now();const a=this.checkForNewBadges(e,s);return this.saveBadgeState(),a}checkForNewBadges(e,t){const i=[],n=this.badgeState[e].badges;return te.forEach(s=>{const a=`tier${s.tier}`,r=n[a];if(t>=s.requirement&&!r.unlocked){r.unlocked=!0,r.timestamp=Date.now();const c=ue(e,s.tier);c&&i.push({...c,categoryId:e,timestamp:r.timestamp})}}),i}getEarnedBadges(e){this.initializeCategoryBadges(e);const t=this.badgeState[e].badges,i=[];return te.forEach(n=>{const s=`tier${n.tier}`,a=t[s];if(a.unlocked){const r=ue(e,n.tier);r&&i.push({...r,categoryId:e,timestamp:a.timestamp})}}),i.sort((n,s)=>n.tier-s.tier)}getNextBadge(e){const t=this.getCategoryCompletionCount(e),i=xt(t);return i?ue(e,i.tier):null}getCategoryCompletionCount(e){const i=this.loadCategoryProgress()[e]||{};return Object.keys(i).filter(n=>i[n]===!0).length}getBadgeProgress(e){const t=this.getCategoryCompletionCount(e),i=this.getNextBadge(e),n=this.getEarnedBadges(e);return{completed:t,nextBadge:i,earnedBadges:n,progress:i?{current:t,required:i.requirement,remaining:Math.max(0,i.requirement-t),percentage:Math.min(100,t/i.requirement*100)}:null}}getAllBadgeStates(){const e={};return this.categoryProgress=this.loadCategoryProgress(),Object.keys(this.categoryProgress).forEach(t=>{e[t]=this.getBadgeProgress(t)}),e}isBadgeEarned(e,t){this.initializeCategoryBadges(e);const i=`tier${t}`;return this.badgeState[e].badges[i]?.unlocked||!1}getTotalEarnedBadges(){let e=0;return Object.keys(this.badgeState).forEach(t=>{const i=this.badgeState[t].badges;e+=Object.values(i).filter(n=>n.unlocked).length}),e}resetBadgeProgress(){this.badgeState={},localStorage.removeItem(this.STORAGE_KEY)}refreshCategoryProgress(){this.categoryProgress=this.loadCategoryProgress()}}const ee=new Rt;let he;async function Ot(){if(!he)try{he=(await x(()=>import("https://cdn.skypack.dev/js-confetti@0.12.0"),[],import.meta.url)).default}catch(l){o.warn("Failed to load js-confetti, confetti effects will be disabled:",l)}return he}class Lt{constructor(){this.isVisible=!1,this.currentModal=null,this.confetti=null,this.ANIMATION_DURATION={CONFETTI:3e3,CONFETTI_SECOND_DELAY:500,CONFETTI_THIRD_DELAY:1e3,CONFETTI_FOURTH_DELAY:1500,CONFETTI_FIFTH_DELAY:2e3,CONFETTI_SIMULTANEOUS:10,CONFETTI_NEAR_SIMULTANEOUS:50,CONFETTI_OVERLAP_SHORT:100,CONFETTI_OVERLAP_MEDIUM:150,CONFETTI_OVERLAP_LONG:200,MODAL_ENTER:600,MODAL_EXIT:400,BADGE_SCALE:800,SIDEKICK_ENTRANCE:1200,ENTRANCE_DELAY:100,SHIELD_DELAY:200,SIDEKICK_DELAY:400,TEXT_START_DELAY:400,TEXT_STAGGER_DELAY:100,TYPEWRITER_START_DELAY:1e3},this.PARTICLE_CONFIG={COUNT:15,MIN_SIZE:2,SIZE_RANGE:3,MAX_DELAY:8,MIN_DURATION:15,DURATION_RANGE:10,DRIFT_MULTIPLIER:100,DRIFT_OFFSET:.5},this.EMOJI_BUBBLE_CONFIG={CATEGORY_COUNT:8,SIDEKICK_COUNT:6,MAX_DELAY:12,MIN_DURATION:8,DURATION_RANGE:4,DRIFT_RANGE:60},this.TYPEWRITER_CONFIG={CHAR_SPEED:20,CURSOR_DELAY:600,START_DELAY:50},this.BADGE_TIERS={MAX_TIER:3},this.bindEvents()}bindEvents(){document.addEventListener("keydown",e=>{e.key==="Escape"&&this.isVisible&&this.closeModal()}),document.addEventListener("click",e=>{e.target?.classList?.contains("badge-modal-backdrop")&&this.isVisible&&this.closeModal()})}async showBadgeModal(e,t="main"){this.isVisible||(this.isVisible=!0,this.triggerConfetti(e.categoryEmoji,e.tier),setTimeout(()=>{this.createModal(e,t),this.animateModalEntrance()},this.ANIMATION_DURATION.CONFETTI_SECOND_DELAY))}async triggerConfetti(e,t=1){if(!this.confetti){const i=await Ot();if(i)this.confetti=new i;else{o.warn("Confetti disabled - failed to load js-confetti library");return}}this.confetti.addConfetti({emojis:[e],emojiSize:60,confettiNumber:15}),setTimeout(()=>{this.confetti.addConfetti({emojis:[e],emojiSize:40,confettiNumber:20})},this.ANIMATION_DURATION.CONFETTI_SIMULTANEOUS),setTimeout(()=>{this.confetti.addConfetti({emojis:[e],emojiSize:25,confettiNumber:10})},this.ANIMATION_DURATION.CONFETTI_SECOND_DELAY),setTimeout(()=>{t===this.BADGE_TIERS.MAX_TIER&&this.confetti.addConfetti({emojis:[e],emojiSize:70,confettiNumber:25})},this.ANIMATION_DURATION.CONFETTI_THIRD_DELAY)}createModal(e,t){const i=document.createElement("div");i.className="badge-modal-backdrop",i.innerHTML=this.generateModalHTML(e,t),document.body.appendChild(i),this.currentModal=i,this.createFloatingParticles(),this.createBubblingEmojis(e.categoryEmoji,e.sidekickEmoji);const n=i.querySelector(".badge-close-btn");n&&n.addEventListener("click",()=>this.closeModal()),setTimeout(()=>{this.initializeTypewriter(e.quote)},this.ANIMATION_DURATION.TYPEWRITER_START_DELAY)}generateModalHTML(e,t){const i=new Date(e.timestamp).toLocaleString("en-US",{month:"short",day:"numeric",year:"numeric",hour:"numeric",minute:"2-digit",hour12:!0}),n=Mt[e.glowIntensity]||"badge-glow-low",s=this.getTierText(e.tier),a=this.getReasonText(e,s);return`
      <div class="badge-modal">
        <div class="badge-modal-content">
          <div class="badge-visual-container">
            <div class="badge-shield ${n}">
              <span class="badge-shield-emoji">🛡️</span>
              <span class="badge-category-emoji">${e.categoryEmoji}</span>
              <span class="badge-sidekick-emoji">${e.sidekickEmoji}</span>
            </div>
          </div>
          
          <div class="badge-text-content">
            <h2 class="badge-title">${e.title}</h2>
            <p class="badge-quote">"${e.quote}"</p>
            <div class="badge-details">
              <p class="badge-reason">${a}</p>
              <p class="badge-timestamp">Earned: ${i}</p>
            </div>
          </div>
          
          <div class="badge-modal-footer">
            <button class="badge-close-btn btn-primary">
              Back to ${t==="category"?"Category":"Scenarios"}
            </button>
          </div>
        </div>
      </div>
    `}getTierText(e){return{1:"your first scenario",2:"three scenarios",3:"all six scenarios"}[e]||`${e} scenarios`}getReasonText(e,t){return`You've earned this badge for completing ${t} in the ${e.categoryName} category.`}animateModalEntrance(){if(!this.currentModal)return;const e=this.currentModal.querySelector(".badge-modal"),t=this.currentModal.querySelector(".badge-shield"),i=this.currentModal.querySelector(".badge-sidekick-emoji"),n=this.currentModal.querySelector(".badge-title"),s=this.currentModal.querySelector(".badge-quote"),a=this.currentModal.querySelector(".badge-details"),r=this.currentModal.querySelector(".badge-modal-footer");e.style.transform="scale(0.8)",e.style.opacity="0",i.style.transform="scale(0) rotate(-180deg)",i.style.opacity="0",n.style.transform="translateY(20px)",n.style.opacity="0",s.style.transform="translateY(20px)",s.style.opacity="0",a.style.transform="translateY(20px)",a.style.opacity="0",r.style.transform="translateY(20px)",r.style.opacity="0",setTimeout(()=>{e.style.transition=`all ${this.ANIMATION_DURATION.MODAL_ENTER}ms cubic-bezier(0.68, -0.55, 0.265, 1.55)`,e.style.transform="scale(1)",e.style.opacity="1"},this.ANIMATION_DURATION.ENTRANCE_DELAY),setTimeout(()=>{t.style.transition=`transform ${this.ANIMATION_DURATION.BADGE_SCALE}ms cubic-bezier(0.68, -0.55, 0.265, 1.55)`,t.style.transform="scale(1.1)",setTimeout(()=>{t.style.transform="scale(1)"},this.ANIMATION_DURATION.BADGE_SCALE)},this.ANIMATION_DURATION.SHIELD_DELAY),setTimeout(()=>{i.style.transition=`all ${this.ANIMATION_DURATION.SIDEKICK_ENTRANCE}ms cubic-bezier(0.68, -0.55, 0.265, 1.55)`,i.style.transform="scale(1) rotate(0deg)",i.style.opacity="1"},this.ANIMATION_DURATION.SIDEKICK_DELAY),[n,s,a,r].forEach((d,u)=>{setTimeout(()=>{d.style.transition="all 400ms ease-out",d.style.transform="translateY(0)",d.style.opacity="1"},this.ANIMATION_DURATION.TEXT_START_DELAY+u*this.ANIMATION_DURATION.TEXT_STAGGER_DELAY)})}closeModal(){if(!this.isVisible||!this.currentModal)return;const e=this.currentModal.querySelector(".badge-modal");e.style.transition=`all ${this.ANIMATION_DURATION.MODAL_EXIT}ms ease-in`,e.style.transform="scale(0.9)",e.style.opacity="0",setTimeout(()=>{this.currentModal&&(document.body.removeChild(this.currentModal),this.currentModal=null),this.isVisible=!1},this.ANIMATION_DURATION.MODAL_EXIT)}isModalVisible(){return this.isVisible}forceClose(){this.currentModal&&(document.body.removeChild(this.currentModal),this.currentModal=null),this.isVisible=!1}createFloatingParticles(){if(!this.currentModal)return;const e=document.createElement("div");e.className="particles-container";const t=this.PARTICLE_CONFIG.COUNT;for(let n=0;n<t;n++){const s=document.createElement("div");s.className="floating-particle";const a=Math.random()*this.PARTICLE_CONFIG.SIZE_RANGE+this.PARTICLE_CONFIG.MIN_SIZE,r=Math.random()*100,c=Math.random()*this.PARTICLE_CONFIG.MAX_DELAY,d=Math.random()*this.PARTICLE_CONFIG.DURATION_RANGE+this.PARTICLE_CONFIG.MIN_DURATION,u=(Math.random()-this.PARTICLE_CONFIG.DRIFT_OFFSET)*this.PARTICLE_CONFIG.DRIFT_MULTIPLIER;s.style.cssText=`
        width: ${a}px;
        height: ${a}px;
        left: ${r}%;
        animation-delay: ${c}s;
        animation-duration: ${d}s;
        --drift: ${u}px;
      `,e.appendChild(s)}const i=this.currentModal;i.insertBefore(e,i.firstChild)}createBubblingEmojis(e,t){if(!this.currentModal)return;const i=document.createElement("div");i.className="emoji-bubbles-container";for(let s=0;s<this.EMOJI_BUBBLE_CONFIG.CATEGORY_COUNT;s++){const a=document.createElement("div");a.className="bubbling-emoji category",a.textContent=e;const r=Math.random()*100,c=Math.random()*this.EMOJI_BUBBLE_CONFIG.MAX_DELAY,d=Math.random()*this.EMOJI_BUBBLE_CONFIG.DURATION_RANGE+this.EMOJI_BUBBLE_CONFIG.MIN_DURATION,u=(Math.random()-this.PARTICLE_CONFIG.DRIFT_OFFSET)*this.EMOJI_BUBBLE_CONFIG.DRIFT_RANGE;a.style.cssText=`
        left: ${r}%;
        animation-delay: ${c}s;
        animation-duration: ${d}s;
        --drift-x: ${u}px;
      `,i.appendChild(a)}for(let s=0;s<this.EMOJI_BUBBLE_CONFIG.SIDEKICK_COUNT;s++){const a=document.createElement("div");a.className="bubbling-emoji sidekick",a.textContent=t;const r=Math.random()*100,c=Math.random()*this.EMOJI_BUBBLE_CONFIG.MAX_DELAY,d=Math.random()*this.EMOJI_BUBBLE_CONFIG.DURATION_RANGE+this.EMOJI_BUBBLE_CONFIG.MIN_DURATION,u=(Math.random()-this.PARTICLE_CONFIG.DRIFT_OFFSET)*this.EMOJI_BUBBLE_CONFIG.DRIFT_RANGE;a.style.cssText=`
        left: ${r}%;
        animation-delay: ${c}s;
        animation-duration: ${d}s;
        --drift-x: ${u}px;
      `,i.appendChild(a)}const n=this.currentModal.querySelector(".badge-modal");n&&n.insertBefore(i,n.firstChild)}initializeTypewriter(e){if(!this.currentModal)return;const t=this.currentModal.querySelector(".badge-quote");if(!t)return;t.textContent="",t.style.whiteSpace="nowrap",t.style.overflow="hidden",t.style.width="0",t.style.maxWidth="100%",t.style.borderRight="2px solid rgba(255, 255, 255, 0.8)",t.style.textOverflow="clip";let i=0;const n=this.TYPEWRITER_CONFIG.CHAR_SPEED,s=()=>{i<e.length?(t.textContent+=e.charAt(i),i++,setTimeout(s,n)):setTimeout(()=>{t.style.borderRight="none",t.style.whiteSpace="normal",t.style.width="auto",t.style.overflow="visible",t.style.textOverflow="unset",t.style.wordWrap="break-word",t.style.overflowWrap="break-word",t.style.hyphens="auto"},this.TYPEWRITER_CONFIG.CURSOR_DELAY)};t.style.animation="typewriter 1.5s steps(30) forwards",setTimeout(s,this.TYPEWRITER_CONFIG.START_DELAY)}}const Dt=new Lt,me=163,Le=2e3,Nt=2e3,De=8,pe=3e3;class _t{constructor(){this.container=null,this.categories=Ie(),this.userProgress=this.loadUserProgress(),this.lastModalOpenTime=0,this.modalOpenCooldown=500,this.init()}init(){if(this.container=document.querySelector(".categories-grid, .simulations-grid"),!this.container){o.error("Category grid container not found");return}this.render()}loadUserProgress(){try{const e=localStorage.getItem("simulateai_category_progress");return e?JSON.parse(e):{}}catch(e){return o.error("Failed to load user progress:",e),{}}}saveUserProgress(){try{localStorage.setItem("simulateai_category_progress",JSON.stringify(this.userProgress))}catch(e){o.error("Failed to save user progress:",e)}}getCategoryProgress(e){return ft(e,this.userProgress)}render(){this.container.innerHTML="",this.categories.forEach(e=>{const t=this.createCategorySection(e);this.container.appendChild(t)}),this.attachEventListeners()}createCategorySection(e){const t=document.createElement("section");t.className="category-section",t.setAttribute("data-category-id",e.id),t.id=`category-${e.id}`;const i=this.getCategoryProgress(e.id),n=be(e.id);return t.innerHTML=`
            <div class="category-header">
                <div class="category-title-group">
                    <div class="category-icon-large" style="background-color: ${e.color}20; color: ${e.color}">
                        ${e.icon}
                    </div>
                    <div class="category-info">
                        <h3 class="category-title">${e.title}</h3>
                        <p class="category-description">${e.description}</p>
                        <div class="category-meta">
                            <div class="category-meta-items">
                                <span class="category-difficulty difficulty-${e.difficulty}">${e.difficulty}</span>
                                <span class="category-time">${e.estimatedTime} min</span>
                                <span class="category-progress-text">${i.completed}/${i.total} completed</span>
                            </div>
                            <a href="category.html?category=${e.id}" class="category-see-all">See All</a>
                        </div>
                    </div>
                </div>
${this.createProgressRing(e,i)}
            </div>

            <div class="scenarios-grid">
                ${n.map(s=>this.createScenarioCard(s,e)).join("")}
            </div>
        `,t}createScenarioCard(e,t){const i=this.userProgress[t.id]?.[e.id]||!1;return`
            <article class="scenario-card ${i?"completed":""}" 
                     data-scenario-id="${e.id}" 
                     data-category-id="${t.id}"
                     role="button" 
                     tabindex="0"
                     aria-label="Scenario: ${e.title} - ${e.difficulty} difficulty">
                
                <div class="scenario-header">
                    <div class="scenario-icon" style="background-color: ${t.color}15; color: ${t.color}">
                        ${t.icon}
                    </div>
                    <div class="scenario-difficulty difficulty-${e.difficulty}">
                        ${e.difficulty}
                    </div>
                </div>

                <div class="scenario-content">
                    <h4 class="scenario-title">${e.title}</h4>
                    <p class="scenario-description">${e.description}</p>
                </div>

                <div class="scenario-footer">
                    <button class="scenario-start-btn" aria-label="Learning Lab for ${e.title} scenario">
                        Learning Lab
                        <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                            <path d="M6 4L10 8L6 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                    </button>
                    <button class="scenario-quick-start-btn" aria-label="${i?"Replay":"Start"} ${e.title} scenario">
                        ${i?"Replay":"Start"}
                        <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                            <path d="M5 3L12 8L5 13V3Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                    </button>
                </div>

                ${i?'<div class="scenario-completed-badge">✓</div>':""}
            </article>
        `}attachEventListeners(){this.container.addEventListener("click",this.handleScenarioClick.bind(this)),this.container.addEventListener("keydown",this.handleScenarioKeydown.bind(this)),document.addEventListener("scenario-modal-closed",this.handleScenarioModalClosed.bind(this)),this.attachProgressRingTooltips()}attachProgressRingTooltips(){this.container.querySelectorAll(".category-progress-ring[data-tooltip]").forEach(t=>{t.addEventListener("mouseenter",this.showTooltip.bind(this)),t.addEventListener("mouseleave",this.hideTooltip.bind(this)),t.addEventListener("touchstart",this.handleProgressRingTouch.bind(this)),t.addEventListener("click",this.handleProgressRingClick.bind(this)),t.addEventListener("keydown",this.handleProgressRingKeydown.bind(this))})}showTooltip(e){const t=e.currentTarget,i=t.getAttribute("data-tooltip");if(!i)return;this.hideTooltip();const n=document.createElement("div");n.className="progress-ring-tooltip",n.textContent=i,n.setAttribute("role","tooltip");const s=t.getBoundingClientRect();n.style.position="fixed",n.style.left=`${s.left+s.width/2}px`,n.style.transform="translateX(-50%)",n.style.zIndex="1000",document.body.appendChild(n);const a=n.getBoundingClientRect(),r=s.top-a.height-De;r<0?n.style.top=`${s.bottom+De}px`:n.style.top=`${r}px`,requestAnimationFrame(()=>{n.classList.add("visible")}),t._tooltip=n}hideTooltip(){document.querySelectorAll(".progress-ring-tooltip").forEach(i=>{i.remove()}),this.container.querySelectorAll(".category-progress-ring").forEach(i=>{i._tooltip&&(i._tooltip=null)})}handleProgressRingTouch(e){e.preventDefault(),this.showTooltip(e),setTimeout(()=>{this.hideTooltip()},pe)}handleProgressRingClick(e){e.preventDefault(),e.stopPropagation(),"ontouchstart"in window&&(e.currentTarget._tooltip?this.hideTooltip():(this.showTooltip(e),setTimeout(()=>this.hideTooltip(),pe)))}handleProgressRingKeydown(e){e.key==="Enter"||e.key===" "?(e.preventDefault(),this.showTooltip(e),setTimeout(()=>{this.hideTooltip()},pe)):e.key==="Escape"&&this.hideTooltip()}handleScenarioClick(e){const t=e.target.closest(".scenario-card");if(!t)return;e.preventDefault();const i=t.getAttribute("data-scenario-id"),n=t.getAttribute("data-category-id");e.target.classList.contains("scenario-quick-start-btn")||e.target.closest(".scenario-quick-start-btn")?this.openScenarioModalDirect(n,i):this.openScenario(n,i)}handleScenarioKeydown(e){if(e.key==="Enter"||e.key===" "){e.preventDefault();const t=e.target.closest(".scenario-card");if(t){const i=t.getAttribute("data-scenario-id"),n=t.getAttribute("data-category-id");e.target.classList.contains("scenario-quick-start-btn")?this.openScenarioModalDirect(n,i):this.openScenario(n,i)}}}openScenario(e,t){const i=this.categories.find(a=>a.id===e),n=i?.scenarios.find(a=>a.id===t);if(!i||!n){o.error("Category or scenario not found:",e,t);return}o.info("Opening premodal for category:",i);const s=new CustomEvent("scenario-selected",{detail:{category:i,scenario:n,categoryId:e,scenarioId:t}});document.dispatchEvent(s),this.openCategoryPremodal(i,n)}cleanupExistingModals(){document.querySelectorAll(".modal-backdrop").forEach(i=>{const n=i.querySelector(".modal-dialog");n&&n.querySelector(".pre-launch-modal")&&i.remove()}),document.querySelectorAll(".pre-launch-modal").forEach(i=>{const n=i.closest(".modal-backdrop");n?n.remove():i.remove()}),document.body.style.overflow="",document.body.classList.remove("modal-open"),document.querySelectorAll("[inert]").forEach(i=>{i.classList.contains("modal-backdrop")||i.removeAttribute("inert")})}openCategoryPremodal(e,t){try{this.cleanupExistingModals(),new Pe(e.id,{categoryData:e,scenarioData:t,onLaunch:()=>{o.info("Starting scenario:",t.title),this.openScenarioModal(t.id,e.id)},onCancel:()=>{o.info("Category premodal cancelled")},showEducatorResources:!0}).show()}catch(i){o.error("Failed to open category premodal:",i),alert(`Opening "${t.title}" from ${e.title} - Premodal setup needed for categories!`)}}openScenarioModal(e,t=null){try{new Be().open(e,t),document.addEventListener("scenario-completed",this.handleScenarioCompleted.bind(this),{once:!0})}catch(i){o.error("Failed to open scenario modal:",i),alert(`Failed to open scenario modal for: ${e}`)}}openScenarioModalDirect(e,t){const i=Date.now();if(i-this.lastModalOpenTime<this.modalOpenCooldown){o.warn("Modal opening too rapidly, ignoring duplicate request");return}this.lastModalOpenTime=i;const n=this.categories.find(r=>r.id===e),s=n?.scenarios.find(r=>r.id===t);if(!n||!s){o.error("Category or scenario not found:",e,t);return}o.info("CategoryGrid","Opening scenario modal directly for:",{title:s.title});const a=new CustomEvent("scenario-selected",{detail:{category:n,scenario:s,categoryId:e,scenarioId:t}});document.dispatchEvent(a),this.openScenarioModal(t,e)}handleScenarioCompleted(e){const{scenarioId:t,selectedOption:i,option:n}=e.detail;o.info("Scenario completed:",{scenarioId:t,selectedOption:i,optionText:n.text});const s=this.categories.find(a=>be(a.id).some(c=>c.id===t));s&&(this.updateProgress(s.id,t,!0,!1),window.AnalyticsManager&&window.AnalyticsManager.trackEvent("scenario_completed",{categoryId:s.id,scenarioId:t,selectedOption:i,optionText:n.text,impact:n.impact}))}handleScenarioModalClosed(e){const{categoryId:t,scenarioId:i}=e.detail;o.info("Scenario modal fully closed, checking for badges:",{categoryId:t,scenarioId:i}),this.checkForNewBadges(t,i)}updateProgress(e,t,i=!0,n=!0){this.userProgress[e]||(this.userProgress[e]={}),this.userProgress[e][t]=i,this.saveUserProgress(),i&&n&&this.checkForNewBadges(e,t),this.render()}async checkForNewBadges(e,t){try{ee.refreshCategoryProgress();const i=ee.updateScenarioCompletion(e,t);if(i&&i.length>0)for(let n=0;n<i.length;n++){const s=i[n];n>0&&await this.delay(Nt),await Dt.showBadgeModal(s,"main"),o.info("Badge earned:",{categoryId:s.categoryId,badgeTitle:s.title,tier:s.tier,timestamp:s.timestamp}),window.AnalyticsManager&&window.AnalyticsManager.trackEvent("badge_earned",{categoryId:s.categoryId,badgeTitle:s.title,tier:s.tier,scenarioId:t})}}catch(i){o.error("Error checking for new badges:",i)}}delay(e){return new Promise(t=>setTimeout(t,e))}getFilteredCategories(e={}){let t=[...this.categories];return e.difficulty&&(t=t.filter(i=>i.difficulty===e.difficulty)),e.tags&&(t=t.filter(i=>e.tags.some(n=>i.tags.includes(n)))),e.completed!==void 0&&(t=t.filter(i=>{const n=this.getCategoryProgress(i.id);return e.completed?n.completed===n.total:n.completed<n.total})),t}isOneScenarioFromNextBadge(e){try{ee.refreshCategoryProgress();const t=ee.getBadgeProgress(e);if(!t||!t.nextBadge||!t.progress)return null;const{remaining:i}=t.progress;return i===1?{nextBadge:t.nextBadge,current:t.progress.current,required:t.progress.required,badgeTitle:t.nextBadge.title,sidekickEmoji:t.nextBadge.sidekickEmoji}:null}catch(t){return o.error("Error checking badge progress:",t),null}}createProgressRing(e,t){const i=ee.getBadgeProgress(e.id),n=i.nextBadge&&i.progress.remaining===1;let s=`${t.completed} of ${t.total} scenarios completed`;if(i.nextBadge)if(n)s+=`. 1 more to unlock next badge: '${i.nextBadge.title}' ${i.nextBadge.sidekickEmoji}`;else{const{remaining:r}=i.progress;s+=`. ${r} more to unlock next badge: '${i.nextBadge.title}' ${i.nextBadge.sidekickEmoji}`}else s+=` (${t.percentage}%)`;return`
      <div class="category-progress-ring${n?" badge-alert":""}" 
           data-tooltip="${s}"
           role="button"
           tabindex="0"
           aria-label="Category progress: ${s}">
        <svg width="60" height="60" viewBox="0 0 60 60">
          <circle cx="30" cy="30" r="26" fill="none" stroke="#e5e7eb" stroke-width="4"/>
          <circle cx="30" cy="30" r="26" fill="none" stroke="${e.color}" stroke-width="4"
                  stroke-linecap="round" stroke-dasharray="${me}" 
                  stroke-dashoffset="${me-t.percentage/100*me}"
                  style="transform: rotate(-90deg); transform-origin: 30px 30px;"/>
        </svg>
        <span class="progress-percentage">${t.percentage}%</span>
      </div>
    `}refreshProgress(){this.userProgress=this.loadUserProgress(),this.render()}highlightScenario(e,t){const i=this.container.querySelector(`[data-category-id="${e}"][data-scenario-id="${t}"]`);i&&(i.scrollIntoView({behavior:"smooth",block:"center"}),i.classList.add("scenario-card-highlighted"),setTimeout(()=>i.classList.remove("scenario-card-highlighted"),Le))}highlightCategory(e){const t=this.container.querySelector(`[data-category-id="${e}"]`);t&&(t.scrollIntoView({behavior:"smooth",block:"start"}),t.classList.add("category-section-highlighted"),setTimeout(()=>t.classList.remove("category-section-highlighted"),Le))}}const G=class G{constructor(){G.instanceCount++,this.instanceId=G.instanceCount,o.warn("OnboardingTour",`🏗️ NEW INSTANCE CREATED #${this.instanceId}`,{totalInstances:G.instanceCount,stackTrace:new Error().stack.split(`
`).slice(1,5)}),this.currentStep=0,this.currentTutorial=1,this.isActive=!1,this.isTransitioning=!1,this.isProcessingAction=!1,this.coachMark=null,this.overlay=null,this.spotlight=null,this.contentObserver=null,this.contentUpdateTimeout=null,this.userStates={"option-selected":!1,"choice-confirmed":!1,"modal-opened":!1},this.isAutoScrolling=!1,this.userHasManuallyScrolled=!1,this.lastScrollPosition=0,this.scrollTrackingTimer=null,this.ANIMATION_DURATION=300,this.SCROLL_DURATION=800,this.SCROLL_OFFSET=100,this.COACH_MARK_SPACING=20,this.AUTO_ADVANCE_DELAY=3e3,this.MIN_SCROLL_DISTANCE=5,this.EASE_MIDPOINT=.5,this.EASE_MULTIPLIER=4,this.DEBOUNCE_DURATION=300,this.MOBILE_NAVIGATION_SPACE=60,this.MOBILE_MAX_HEIGHT_RATIO=.5,this.MOBILE_POSITION_RATIO=.3,this.MOBILE_COACH_MARK_HEIGHT_RATIO=.4,this.MOBILE_BREAKPOINT=768,this.SMALL_MOBILE_BREAKPOINT=480,this.MOBILE_SPACING=10,this.DESKTOP_SPACING=20,this.MANUAL_SCROLL_RESET_DELAY=2e3,this.LEARNING_LAB_TUTORIAL=3,this.TUTORIAL_3_STEP_3_INDEX=2,this.TUTORIAL_3_BOTTOM_POSITION_START=2,this.TUTORIAL_3_BOTTOM_POSITION_END=7,this.ACCORDION_CHECK_DELAY=200,this.MODAL_CHECK_DELAY=200,this.CHECK_DELAY=100,this.DEBUG_TEXT_LENGTH=20,this.CLICK_TIMEOUT=1e4,this.OPTION_TEXT_LENGTH=50,this.CONTENT_UPDATE_DELAY=100,this.wasKeyboardNavigation=!1,this.tutorials={1:{name:"test-scenario",title:"Test Scenario Tutorial",steps:[{id:"welcome",title:"Welcome to SimulateAI! 🤖",content:"A Digital Learning Lab where you journey into the ethical frontiers of AI and Robotics. This tour will guide you through our interactive platform.",buttons:[{text:"Start Tour",action:"continue",primary:!0},{text:"Start Exploring",action:"finish",primary:!1}],target:null,position:"center",autoScroll:!1},{id:"launch-test",title:"Launch Test Scenario",content:"Click this button to open an interactive ethics simulation and see how moral dilemmas are presented.",target:"#test-scenario-modal",position:"bottom",action:"wait-for-click",autoScroll:!0,highlightClick:!0},{id:"dilemma-section",title:"The Dilemma Section",content:"This section presents the ethical scenario. Read carefully to understand the situation and its complexities.",target:".dilemma-text",position:"right",waitFor:"scenario-modal",autoScroll:!0},{id:"ethical-question",title:"Ethical Question",content:"This highlights the core ethical consideration. What values are at stake in this scenario?",target:".ethical-question",position:"right",autoScroll:!0},{id:"choose-approach",title:"Choose Your Approach",content:"Each approach represents a different ethical framework. Please click the <strong>first option</strong> to continue the tutorial and see how the analysis works!",target:".options-container",position:"right",action:"wait-for-click",highlightClick:!0,autoScroll:!0},{id:"pros-cons",title:"Pros and Cons Analysis",content:"Perfect! The details expanded to show the analysis. Every ethical choice has trade-offs - these help you understand the implications.",target:".option-details",position:"right",autoScroll:!0,waitForElement:!0},{id:"radar-chart-preview",title:"Radar Chart Visualization",content:"This radar chart shows how your choice impacts different ethical dimensions. The chart updates based on your selection - we'll explore this in detail in Tutorial 2!",target:"#scenario-radar-chart",position:"left",autoScroll:!0,waitFor:"option-selected"},{id:"confirm-choice",title:"Confirm Your Decision",content:`When ready, confirm your choice. Remember - there's no "wrong" answer in ethics exploration!`,target:"#confirm-choice",position:"right",action:"wait-for-click",highlightClick:!0,autoScroll:!0},{id:"tutorial-complete",title:"Congratulations! 🎉",content:"Excellent work! You've successfully completed your first ethical scenario exploration. You've learned how to navigate complex moral dilemmas, analyze different approaches, and understand the ethical implications through our interactive tools.<br><br>Would you like to continue with Tutorial 2 to explore the radar chart visualization in more detail?",buttons:[{text:"📊 Continue to Tutorial 2",action:"next-tutorial",primary:!0},{text:"Start Exploring",action:"finish",primary:!1}],target:null,position:"center",autoScroll:!1,skipUntil:"choice-confirmed"}]},2:{name:"hero-demo",title:"Hero Demo Tutorial",steps:[{id:"hero-demo-chart",title:"Interactive Radar Chart 📊",content:"This is our Hero Demo radar chart. It shows how different ethical choices impact various dimensions in real-time, giving you a visual representation of moral decision-making.",target:"#hero-ethics-chart",position:"bottom",autoScroll:!0},{id:"ethical-dimensions",title:"Ethical Dimensions Explained",content:"The chart displays 8 key ethical dimensions that represent core moral principles. Each axis shows how your decisions impact different aspects of AI ethics - from fairness to sustainability.",target:"#hero-ethics-chart",position:"left",autoScroll:!1},{id:"interactive-controls",title:"Try the Controls! 🎮",content:`Use these buttons to see how different ethical approaches affect the dimensions. Watch the chart change in real-time as you explore different scenarios! Click "Next" when you're ready to continue.`,target:".demo-controls-grid",position:"left",autoScroll:!0,highlightClick:!0},{id:"how-to-read",title:"How to Read Charts 📖",content:'This section teaches you about interpreting the visual data and understanding the ethical implications of each choice. Click "Next" to continue exploring.',target:".radar-instructions-accordion",position:"bottom",autoScroll:!0,highlightClick:!0},{id:"glossary",title:"Ethical Dimensions Glossary 📚",content:'This glossary provides detailed definitions of each ethical principle used in our simulations. Click "Next" to complete the radar chart tutorial.',target:".ethics-glossary-accordion",position:"bottom",autoScroll:!0,highlightClick:!0},{id:"radar-tutorial-complete",title:"Radar Chart Mastery! 🎉",content:"Excellent! You now understand how to interpret ethical impacts visually and interact with our radar chart system. Ready to explore the Learning Lab?",buttons:[{text:"🧪 Learning Lab Tutorial",action:"next-tutorial",primary:!0},{text:"Start Exploring",action:"finish",primary:!1}],target:null,position:"center",autoScroll:!1}]},3:{name:"learning-lab",title:"Learning Lab Tutorial",steps:[{id:"find-trolley-problem",title:"Scenario Simulations",content:"Each scenario includes a fully equipped Learning Lab, offering a detailed overview and curated educator resources to deepen understanding and spark meaningful discussion.",target:"#category-trolley-problem > div.scenarios-grid > article:nth-child(1)",position:"bottom",autoScroll:!0},{id:"click-learning-lab",title:"Open Learning Lab",content:'Perfect! Now click the "Learning Lab" button on this Trolley Problem scenario card to open the pre-launch modal.',target:"#category-trolley-problem > div.scenarios-grid > article:nth-child(1) > div.scenario-footer > button.scenario-start-btn",position:"bottom",action:"wait-for-click",autoScroll:!0,highlightClick:!0,waitFor:"#category-trolley-problem > div.scenarios-grid > article:nth-child(1)"},{id:"overview-tab",title:"Overview Tab",content:'This Overview tab provides a comprehensive introduction to the scenario, including the ethical dilemma, key stakeholders, and real-world context. Click "Next" to continue exploring the other tabs.',target:'.tab-buttons-container [data-tab="overview"], .tab-buttons-container .tab-button[data-tab="overview"]',position:"right",waitFor:"pre-launch-modal",autoScroll:!0},{id:"learning-goals-tab",title:"Learning Goals Tab",content:`The Learning Goals tab outlines what you'll discover and understand by completing this simulation, including key ethical principles and decision-making frameworks. Click "Next" to continue exploring the other tabs.`,target:'.tab-buttons-container [data-tab="objectives"], .tab-buttons-container .tab-button[data-tab="objectives"]',position:"right",highlightClick:!0,autoScroll:!0},{id:"ethics-guide-tab",title:"Ethics Guide Tab",content:'The Ethics Guide provides essential background on moral frameworks, philosophical approaches, and ethical theories relevant to this scenario. Click "Next" to see the next tab.',target:'.tab-buttons-container [data-tab="ethics"], .tab-buttons-container .tab-button[data-tab="ethics"]',position:"right",highlightClick:!0,autoScroll:!0},{id:"get-ready-tab",title:"Get Ready Tab",content:'Get Ready helps you prepare for the simulation with pre-activity questions, reflection prompts, and scenario setup information. Click "Next" to continue.',target:'.tab-buttons-container [data-tab="preparation"], .tab-buttons-container .tab-button[data-tab="preparation"]',position:"right",highlightClick:!0,autoScroll:!0},{id:"resources-tab",title:"Resources Tab",content:'The Resources tab contains supplementary materials, research papers, case studies, and additional reading to deepen your understanding. Click "Next" to see the final tab.',target:'.tab-buttons-container [data-tab="resources"], .tab-buttons-container .tab-button[data-tab="resources"]',position:"right",highlightClick:!0,autoScroll:!0},{id:"for-educators-tab",title:"For Educators Tab",content:"For Educators provides teaching guides, discussion questions, assessment rubrics, and classroom integration strategies for instructors. This completes our tour of the Learning Lab tabs!",target:'.tab-buttons-container [data-tab="educator"], .tab-buttons-container .tab-button[data-tab="educator"]',position:"right",highlightClick:!0,autoScroll:!0,hasNextButton:!0,action:"next",onShow(){const t=document.querySelector('.tab-buttons-container [data-tab="educator"]')||document.querySelector('.tab-buttons-container .tab-button[data-tab="educator"]');if(t){t.scrollIntoView({behavior:"smooth",block:"center",inline:"center"});const n=t.closest(".tab-buttons-container");n&&n.scrollIntoView({behavior:"smooth",block:"center",inline:"center"}),o.info("OnboardingTour","Auto-scrolled to For Educators tab",{element:t,container:n})}else o.warn("OnboardingTour","Could not find For Educators tab");const i=document.querySelector('a[href="#educator-tools"]');i&&(i.scrollIntoView({behavior:"smooth",block:"center"}),o.info("OnboardingTour","Auto-scrolled to Educator Tools nav link",{element:i}))}},{id:"tutorial-complete",title:"Mission Accomplished! 🎉🤖",content:"You've completed the tutorial and unlocked the tools to navigate the ethical terrain of intelligent machines. Ready to begin your journey?",buttons:[{text:"🚀 Start Exploring",action:"finish",primary:!0}],target:null,position:"center",autoScroll:!1}]}},this.setupKeyboardTracking(),this.init()}init(){o.info("OnboardingTour","Initializing onboarding coach marks system"),o.debug("OnboardingTour","OnboardingTour initialized, waiting for manual start")}setupKeyboardTracking(){document.addEventListener("keydown",e=>{e.key==="Tab"&&(this.wasKeyboardNavigation=!0)}),document.addEventListener("mousedown",()=>{this.wasKeyboardNavigation=!1})}isFirstTimeVisit(){return K.get("has_visited",!1)?!1:(K.set("has_visited",!0),!0)}hasCompletedTour(){return K.get("tour_completed",!1)}startTour(e=1){if(o.info("OnboardingTour",`🚀 Starting onboarding tour ${e}`,{instanceId:this.instanceId,tutorialNumber:e,isActive:this.isActive}),this.isActive){o.warn("OnboardingTour","Tour already active, ignoring start request");return}this.isActive=!0,this.currentTutorial=e,this.currentStep=0,this.userStates={"option-selected":!1,"choice-confirmed":!1,"modal-opened":!1},o.info("OnboardingTour",`Starting tutorial ${e}`,{currentStep:this.currentStep,totalSteps:this.tutorials[e]?.steps?.length||0}),A.trackEvent("tour_started",{tutorial:e}),this.createOverlay(),this.showStep()}createOverlay(){this.removeOverlay(),o.debug("OnboardingTour","Creating overlay elements",{tutorial:this.currentTutorial,step:this.currentStep,existingOverlays:document.querySelectorAll(".onboarding-overlay").length}),this.overlay=document.createElement("div"),this.overlay.className="onboarding-overlay",this.overlay.setAttribute("role","presentation"),this.overlay.setAttribute("aria-hidden","true"),this.spotlight=document.createElement("div"),this.spotlight.className="onboarding-spotlight",this.coachMark=document.createElement("div"),this.coachMark.className="onboarding-coach-mark",this.coachMark.setAttribute("role","dialog"),this.coachMark.setAttribute("aria-modal","true"),this.coachMark.setAttribute("aria-labelledby","coach-mark-title"),this.coachMark.setAttribute("aria-describedby","coach-mark-content"),document.body.appendChild(this.overlay),document.body.appendChild(this.spotlight),document.body.appendChild(this.coachMark),document.body.classList.add("onboarding-active"),this.currentTutorial===this.TUTORIAL_3&&this.currentStep===this.TUTORIAL_3_STEP_3_INDEX&&(this.coachMark.style.zIndex="10020",this.coachMark.style.isolation="isolate",this.coachMark.style.position="fixed",o.warn("OnboardingTour","TUTORIAL 3 STEP 3 - Applied aggressive stacking",{zIndex:this.coachMark.style.zIndex,position:getComputedStyle(this.coachMark).position,isolation:this.coachMark.style.isolation})),o.debug("OnboardingTour","Overlay elements created and appended",{overlayInDom:!!document.querySelector(".onboarding-overlay"),totalOverlays:document.querySelectorAll(".onboarding-overlay").length,coachMarkInDom:!!document.querySelector(".onboarding-coach-mark")}),this.setupScrollTracking(),this.makeModalsOnboardingFriendly()}makeModalsOnboardingFriendly(){document.querySelectorAll(".modal-backdrop").forEach(t=>{if(t.style.display!=="none"){t.style.pointerEvents="none";const i=t.querySelector(".modal-dialog");i&&(i.style.pointerEvents="auto"),o.debug("OnboardingTour","Made modal onboarding-friendly",{modalId:t.id})}})}removeOverlay(){o.debug("OnboardingTour","Removing overlay elements",{hasOverlay:!!this.overlay,hasSpotlight:!!this.spotlight,hasCoachMark:!!this.coachMark,hasContentObserver:!!this.contentObserver,totalOverlaysInDom:document.querySelectorAll(".onboarding-overlay").length}),this.contentObserver&&(this.contentObserver.disconnect(),this.contentObserver=null),this.contentUpdateTimeout&&(clearTimeout(this.contentUpdateTimeout),this.contentUpdateTimeout=null),this.overlay&&(this.overlay.remove(),this.overlay=null),this.spotlight&&(this.spotlight.remove(),this.spotlight=null),this.coachMark&&(this.coachMark.remove(),this.coachMark=null);const e=document.querySelectorAll(".onboarding-overlay"),t=document.querySelectorAll(".onboarding-spotlight"),i=document.querySelectorAll(".onboarding-coach-mark");(e.length>0||t.length>0||i.length>0)&&(o.warn("OnboardingTour","Found orphaned elements, cleaning up",{overlays:e.length,spotlights:t.length,coachMarks:i.length}),e.forEach(n=>n.remove()),t.forEach(n=>n.remove()),i.forEach(n=>n.remove())),document.body.classList.remove("onboarding-active"),o.debug("OnboardingTour","Overlay cleanup complete",{totalOverlaysInDom:document.querySelectorAll(".onboarding-overlay").length}),this.removeScrollTracking()}setupScrollTracking(){this.lastScrollPosition=window.pageYOffset,this.userHasManuallyScrolled=!1,this.scrollHandler=()=>{this.isAutoScrolling||(this.userHasManuallyScrolled=!0,this.scrollTrackingTimer&&clearTimeout(this.scrollTrackingTimer),this.scrollTrackingTimer=setTimeout(()=>{this.userHasManuallyScrolled=!1},this.MANUAL_SCROLL_RESET_DELAY))},window.addEventListener("scroll",this.scrollHandler,{passive:!0})}removeScrollTracking(){this.scrollHandler&&(window.removeEventListener("scroll",this.scrollHandler),this.scrollHandler=null),this.scrollTrackingTimer&&(clearTimeout(this.scrollTrackingTimer),this.scrollTrackingTimer=null)}async scrollToElement(e,t=this.SCROLL_OFFSET){e&&await fe.scrollToElement(e,{behavior:"smooth",offset:t})}positionSpotlight(e){if(!e||!this.spotlight)return;const t=e.getBoundingClientRect(),i=8;this.spotlight.style.left=`${t.left-i}px`,this.spotlight.style.top=`${t.top+window.pageYOffset-i}px`,this.spotlight.style.width=`${t.width+i*2}px`,this.spotlight.style.height=`${t.height+i*2}px`,this.spotlight.style.display="block"}positionCoachMark(e,t="bottom",i=null,n=0){if(!this.coachMark)return;const s=3;if(n>s){o.warn("OnboardingTour",`⚠️ Max positioning retries reached for step ${i?.id||"unknown"}`);return}const a=window.innerWidth<=this.MOBILE_BREAKPOINT;this.coachMark.style.visibility="hidden",this.coachMark.style.display="block",this.coachMark.style.position="fixed",this.coachMark.style.zIndex="10014",this.coachMark.classList.remove("mobile-overlay"),this.coachMark.style.width="",this.coachMark.style.maxHeight="",this.coachMark.style.overflow="";const r=this.coachMark.getBoundingClientRect(),c=window.innerHeight,d=window.innerWidth,u=a?this.MOBILE_SPACING:this.DESKTOP_SPACING;let h,p;if(e){const m=e.getBoundingClientRect();if(m.bottom<0||m.top>c||m.right<0||m.left>d)if(n<s){o.debug("OnboardingTour",`Target outside viewport, scrolling into view (retry ${n+1}/${s})`),e.scrollIntoView({behavior:"smooth",block:"center",inline:"center"}),setTimeout(()=>{this.positionCoachMark(e,t,i,n+1)},this.ANIMATION_DURATION);return}else o.warn("OnboardingTour",`Target still outside viewport after ${s} retries, positioning anyway`);if(a){const R=Math.min(r.height,c*this.MOBILE_COACH_MARK_HEIGHT_RATIO),v=m.top-u,S=c-m.bottom-u;o.debug("OnboardingTour","Mobile positioning analysis",{targetRect:{x:m.left,y:m.top,w:m.width,h:m.height},spaceAbove:v,spaceBelow:S,coachMarkHeight:r.height,mobileCoachMarkHeight:R}),S>=R?(t="bottom",h=Math.max(u,Math.min(m.left+m.width/2-r.width/2,d-r.width-u)),p=m.bottom+u,o.debug("OnboardingTour","Mobile: Positioning below target")):v>=R?(t="top",h=Math.max(u,Math.min(m.left+m.width/2-r.width/2,d-r.width-u)),p=m.top-r.height-u,o.debug("OnboardingTour","Mobile: Positioning above target")):(this.coachMark.classList.add("mobile-overlay"),h=u,p=c-r.height-u-this.MOBILE_NAVIGATION_SPACE,this.coachMark.style.width=`${d-u*2}px`,this.coachMark.style.maxHeight=`${c*this.MOBILE_MAX_HEIGHT_RATIO}px`,this.coachMark.style.overflow="auto",o.debug("OnboardingTour","Mobile: Using full-width overlay mode to avoid covering content"))}else{switch(this.currentTutorial===this.LEARNING_LAB_TUTORIAL&&this.currentStep>=this.TUTORIAL_3_BOTTOM_POSITION_START&&this.currentStep<=this.TUTORIAL_3_BOTTOM_POSITION_END&&(o.info("OnboardingTour",`Forcing bottom position for Tutorial 3 step ${this.currentStep+1}`),t="bottom"),t){case"top":h=m.left+m.width/2-r.width/2,p=m.top-r.height-u;break;case"bottom":h=m.left+m.width/2-r.width/2,p=m.bottom+u;break;case"left":h=m.left-r.width-u,p=m.top+m.height/2-r.height/2;break;case"right":h=m.right+u,p=m.top+m.height/2-r.height/2;break;default:h=m.left+m.width/2-r.width/2,p=m.bottom+u}const R=u,v=d-r.width-u,S=u,T=c-r.height-u;h=Math.max(R,Math.min(h,v)),p=Math.max(S,Math.min(p,T))}i&&i.highlightClick&&!this.coachMark.classList.contains("mobile-overlay")&&h<m.right&&h+r.width>m.left&&p<m.bottom&&p+r.height>m.top&&(a?(this.coachMark.classList.add("mobile-overlay"),h=u,p=c-r.height-u-this.MOBILE_NAVIGATION_SPACE,this.coachMark.style.width=`${d-u*2}px`):m.right+r.width+u<=d?(h=m.right+u,p=Math.max(u,Math.min(m.top,c-r.height-u))):m.left-r.width-u>=0?(h=m.left-r.width-u,p=Math.max(u,Math.min(m.top,c-r.height-u))):m.bottom+r.height+u<=c?(h=Math.max(u,Math.min(m.left,d-r.width-u)),p=m.bottom+u):m.top-r.height-u>=0&&(h=Math.max(u,Math.min(m.left,d-r.width-u)),p=m.top-r.height-u)),o.debug("OnboardingTour","Coach mark positioned relative to target",{stepId:i?.id,targetRect:{x:m.left,y:m.top,w:m.width,h:m.height},coachMarkPos:{left:h,top:p},position:t,isMobile:a,isOverlay:this.coachMark.classList.contains("mobile-overlay")})}else a?(h=u,p=Math.max(c*this.MOBILE_POSITION_RATIO,c-r.height-u-this.MOBILE_NAVIGATION_SPACE),this.coachMark.style.width=`${d-u*2}px`):(h=d/2-r.width/2,p=c/2-r.height/2),o.debug("OnboardingTour","Coach mark centered in viewport",{stepId:i?.id,coachMarkPos:{left:h,top:p},isMobile:a});this.coachMark.style.left=`${h}px`,this.coachMark.style.top=`${p}px`,this.coachMark.style.visibility="visible",this.coachMark.style.opacity="1",this.coachMark.style.pointerEvents="auto",this.coachMark.style.display="block";const g=this.coachMark.getBoundingClientRect(),y=g.width>0&&g.height>0&&g.left>=0&&g.top>=0&&g.right<=d&&g.bottom<=c;y||(o.warn("OnboardingTour","Coach mark may not be fully visible, adjusting",{stepId:i?.id,finalRect:{x:g.left,y:g.top,w:g.width,h:g.height},viewport:{w:d,h:c}}),this.coachMark.style.left=`${d/2-r.width/2}px`,this.coachMark.style.top=`${c/2-r.height/2}px`),o.info("OnboardingTour",`Coach mark positioned for step ${i?.id||"unknown"}`,{finalPosition:{left:this.coachMark.style.left,top:this.coachMark.style.top},isVisible:y})}async showStep(){const e=this.tutorials[this.currentTutorial],t=e.steps[this.currentStep];if(!t){o.error("OnboardingTour","No step found",{currentTutorial:this.currentTutorial,currentStep:this.currentStep,totalSteps:e?.steps?.length});return}o.info("OnboardingTour",`🚀 Starting step ${this.currentStep+1}: ${t.id}`,{currentTutorial:this.currentTutorial,currentStep:this.currentStep,stepId:t.id,totalSteps:e.steps.length});let i=t.target?document.querySelector(t.target):null;if(t.waitForElement&&t.target&&!i){o.info("OnboardingTour",`Waiting for element to appear: ${t.target}`,{stepId:t.id,selector:t.target});let n=0;const s=30;for(;!i&&n<s;)await new Promise(a=>setTimeout(a,this.CHECK_DELAY)),i=document.querySelector(t.target),n++;i?o.info("OnboardingTour",`Target element found after ${n*100}ms`,{stepId:t.id,selector:t.target}):o.warn("OnboardingTour",`Target element still not found after waiting: ${t.target}`,{stepId:t.id,selector:t.target,attemptsUsed:n})}if(t.target&&!i&&o.warn("OnboardingTour",`Target element not found: ${t.target}`,{stepId:t.id,selector:t.target}),t.autoScroll&&i)if(t.id==="ethical-question")this.scrollToElementInModal(i,t)&&await new Promise(s=>setTimeout(s,this.SCROLL_DURATION));else{const n=i.getBoundingClientRect();n.top>=0&&n.bottom<=window.innerHeight||(o.info("OnboardingTour",`Scrolling to bring target into view for step ${t.id}`),i.scrollIntoView({behavior:"smooth",block:"center",inline:"center"}),await new Promise(a=>setTimeout(a,this.SCROLL_DURATION)))}if(i?this.positionSpotlight(i):this.spotlight&&(this.spotlight.style.display="none"),(!this.coachMark||!document.body.contains(this.coachMark))&&(o.warn("OnboardingTour","Coach mark element is null or not in DOM, recreating overlay",{currentTutorial:this.currentTutorial,currentStep:this.currentStep,stepId:t.id,isActive:this.isActive,coachMarkExists:!!this.coachMark,coachMarkInDom:this.coachMark?document.body.contains(this.coachMark):!1}),this.createOverlay(),!this.coachMark)){o.error("OnboardingTour","Failed to create coach mark element, aborting step");return}if(!this.coachMark){o.error("OnboardingTour","Coach mark is null right before setting innerHTML - this should not happen!");return}if(!document.body.contains(this.coachMark)&&(o.error("OnboardingTour","Coach mark exists but is not in DOM - recreating"),this.createOverlay(),!this.coachMark)){o.error("OnboardingTour","Failed to recreate coach mark element");return}try{this.coachMark.innerHTML=this.createCoachMarkContent(t,e)}catch(n){o.error("OnboardingTour","Error setting coach mark innerHTML",{error:n.message,coachMark:this.coachMark,step:t.id});return}if(this.positionCoachMark(i,t.position,t),this.coachMark.style.display="block",this.coachMark.style.visibility="visible",this.coachMark.style.opacity="1",this.coachMark.style.pointerEvents="auto",this.coachMark.style.zIndex="10014",this.setupEventListeners(t),t.id==="dilemma-section"&&this.setupContentObserver(i,t),t.action==="wait-for-click"&&i?this.waitForElementClick(i,t):t.action==="wait-for-option-selection"&&i&&(o.info("OnboardingTour",`Setting up option selection waiting for step ${t.id}`),this.waitForOptionSelection(i,t)),t.highlightClick&&i&&i.classList.add("onboarding-click-highlight"),t.onShow&&typeof t.onShow=="function")try{o.info("OnboardingTour",`Executing onShow callback for step ${t.id}`),t.onShow()}catch(n){o.error("OnboardingTour",`Error executing onShow callback for step ${t.id}`,{error:n.message})}o.info("OnboardingTour",`✅ Step ${t.id} rendered successfully`,{hasTarget:!!i,targetInViewport:i?this.isElementInViewport(i):!1,coachMarkVisible:this.coachMark.style.visibility==="visible",coachMarkPosition:{left:this.coachMark.style.left,top:this.coachMark.style.top}})}createCoachMarkContent(e,t){const i=this.currentStep+1,n=t.steps.length,s=this.currentTutorial,a=Object.keys(this.tutorials).length;return`
      <div class="coach-mark-header">
        <div class="coach-mark-progress">
          <span class="tutorial-indicator">Tutorial ${s}/${a}</span>
          <div class="step-progress">
            <div class="step-dots">
              ${t.steps.map((r,c)=>`<div class="step-dot ${c===this.currentStep?"active":c<this.currentStep?"completed":""}"></div>`).join("")}
            </div>
            <span class="step-counter">${i}/${n}</span>
          </div>
        </div>
        <button class="coach-mark-close" aria-label="Close tour" type="button">×</button>
      </div>
      
      <div class="coach-mark-body">
        <h3 id="coach-mark-title" class="coach-mark-title">${e.title}</h3>
        <div id="coach-mark-content" class="coach-mark-content">
          ${e.content}
        </div>
      </div>
      
      <div class="coach-mark-footer">
        ${this.createCoachMarkButtons(e)}
      </div>
    `}createCoachMarkButtons(e){if(e.buttons)return e.buttons.map(r=>`<button class="coach-mark-btn ${r.primary?"primary":"secondary"}" 
                 data-action="${r.action}" 
                 type="button">
          ${r.text}
         </button>`).join("");const t=this.currentStep===0,i=this.currentStep===this.tutorials[this.currentTutorial].steps.length-1,n=this.currentTutorial===Object.keys(this.tutorials).length,s=e.action&&(e.action==="wait-for-click"||e.action==="wait-for-option-selection");o.debug("OnboardingTour","Creating buttons",{stepId:e.id,tutorial:this.currentTutorial,step:this.currentStep,isFirstStep:t,isLastStep:i,isLastTutorial:n,hasUserAction:s,stepAction:e.action});let a="";return t||(a+='<button class="coach-mark-btn secondary" data-action="back" type="button">← Back</button>'),!i&&!s&&(a+='<button class="coach-mark-btn secondary" data-action="skip" type="button">Skip</button>'),s||(i&&n?a+='<button class="coach-mark-btn primary" data-action="finish" type="button">🚀 Start Exploring</button>':i?a+='<button class="coach-mark-btn primary" data-action="next-tutorial" type="button">Next Tutorial</button>':a+='<button class="coach-mark-btn primary" data-action="continue" type="button">Next</button>'),o.debug("OnboardingTour","Buttons created",{buttons:a.length>0?"yes":"no"}),a}setupEventListeners(e){if(!this.coachMark){o.warn("OnboardingTour","No coach mark element found for event listeners");return}o.debug("OnboardingTour","Setting up event listeners for step",{stepId:e.id,buttons:this.coachMark.querySelectorAll(".coach-mark-btn").length}),this.currentClickHandler&&this.coachMark.removeEventListener("click",this.currentClickHandler),this.currentKeyHandler&&this.coachMark.removeEventListener("keydown",this.currentKeyHandler),this.currentClickHandler=i=>{if(o.info("OnboardingTour","Coach mark clicked",{target:i.target.tagName,className:i.target.className,textContent:i.target.textContent,dataset:i.target.dataset}),i.target.classList.contains("coach-mark-btn")){const{action:n}=i.target.dataset;if(n){if(i.preventDefault(),i.stopPropagation(),i.stopImmediatePropagation(),this.isProcessingAction){o.debug("OnboardingTour","Button click ignored - already processing action");return}o.info("OnboardingTour",`Button clicked with action: ${n}`,{tutorial:this.currentTutorial,step:this.currentStep,stepId:e.id}),this.handleAction(n)}else o.warn("OnboardingTour","Button clicked but no action found",{target:i.target,dataset:i.target.dataset})}i.target.classList.contains("coach-mark-close")&&(i.preventDefault(),i.stopPropagation(),i.stopImmediatePropagation(),o.info("OnboardingTour","Close button clicked"),this.endTour())},this.coachMark.addEventListener("click",this.currentClickHandler),this.currentKeyHandler=i=>{i.key==="Escape"?this.endTour():(i.key==="Enter"||i.key===" ")&&i.target.classList.contains("coach-mark-btn")&&(i.preventDefault(),i.target.click())},this.coachMark.addEventListener("keydown",this.currentKeyHandler);const t=this.coachMark.querySelector(".coach-mark-btn");t&&Ee.autoFocus(this.coachMark,{keyboardOnly:!0,delay:100}),o.debug("OnboardingTour","Event listeners set up successfully",{stepId:e.id,hasFirstButton:!!t})}handleStepAction(e,t){switch(e.action){case"wait-for-click":this.waitForElementClick(t);break;case"wait-for-option-selection":this.waitForOptionSelection();break}}waitForElementClick(e){if(!e){o.warn("OnboardingTour","waitForElementClick: No target element provided");return}o.debug("OnboardingTour","Setting up click listener",{targetTag:e.tagName,targetClass:e.className,tutorial:this.currentTutorial,step:this.currentStep});const t=n=>{o.info("OnboardingTour","Target element clicked, advancing step",{tutorial:this.currentTutorial,step:this.currentStep,eventTarget:n.target.tagName}),e.removeEventListener("click",t),clearTimeout(i),setTimeout(()=>this.nextStep(),this.ANIMATION_DURATION)};e.addEventListener("click",t);const i=setTimeout(()=>{document.querySelector(".pre-launch-modal, .reusable-modal")?(o.info("OnboardingTour","Modal appeared without tracked click, advancing step",{tutorial:this.currentTutorial,step:this.currentStep}),e.removeEventListener("click",t),this.nextStep()):o.warn("OnboardingTour","Timeout waiting for click, but no modal appeared",{tutorial:this.currentTutorial,step:this.currentStep})},this.CLICK_TIMEOUT);o.debug("OnboardingTour","Click listener added to target",{elementExists:!!e,elementVisible:e.offsetParent!==null,elementRect:e.getBoundingClientRect()})}waitForOptionSelection(e,t){o.info("OnboardingTour",`Waiting for option selection in step ${t.id}`,{targetSelector:t.target});const i=n=>{const s=n.target;(s.tagName==="BUTTON"||s.classList.contains("option")||s.classList.contains("option-card")||s.classList.contains("choice")||s.classList.contains("response")||s.hasAttribute("data-option")||s.hasAttribute("data-option-id")||s.hasAttribute("data-choice")||s.closest(".option, .option-card, .choice, .response-option"))&&(o.info("OnboardingTour",`✅ Option selection detected in step ${t.id}`,{clickedElement:s.tagName,clickedClass:s.className,clickedText:s.textContent.substring(0,this.OPTION_TEXT_LENGTH)}),e.removeEventListener("click",i),this.userStates["option-selected"]=!0,s.classList.add("onboarding-selected"),setTimeout(()=>{this.nextStep()},this.SELECTION_DELAY))};e.addEventListener("click",i),e.classList.add("onboarding-click-highlight"),o.debug("OnboardingTour",`Option selection listener attached for step ${t.id}`)}waitForCondition(e,t){const i=()=>{let n=!1;switch(e){case"scenario-modal":if(n=document.querySelector(".scenario-modal-dialog")!==null,n){setTimeout(t,this.ANIMATION_DURATION);return}break;case"pre-launch-modal":if(n=document.querySelector(".pre-launch-modal")!==null,n){setTimeout(t,this.ANIMATION_DURATION);return}break;case"option-selected":n=this.userStates["option-selected"];break;case"choice-confirmed":n=this.userStates["choice-confirmed"];break;default:n=document.querySelector(e)!==null}n?t():setTimeout(i,this.CHECK_DELAY)};i()}handleAction(e){if(this.isProcessingAction){o.debug("OnboardingTour",`Action ${e} ignored - already processing another action`);return}switch(this.isProcessingAction=!0,o.info("OnboardingTour",`Handling action: ${e}`,{currentTutorial:this.currentTutorial,currentStep:this.currentStep}),e){case"continue":this.nextStep(),setTimeout(()=>{this.isProcessingAction=!1},this.DEBOUNCE_DURATION);break;case"back":this.previousStep(),setTimeout(()=>{this.isProcessingAction=!1},this.DEBOUNCE_DURATION);break;case"next-tutorial":o.info("OnboardingTour","next-tutorial action triggered",{currentTutorial:this.currentTutorial,currentStep:this.currentStep,isActive:this.isActive}),this.nextTutorial();break;case"finish":case"skip":this.endTour(),setTimeout(()=>{this.isProcessingAction=!1},this.DEBOUNCE_DURATION);break;default:o.warn("OnboardingTour",`Unknown action: ${e}`),this.isProcessingAction=!1}}nextStep(){if(this.isTransitioning){o.debug("OnboardingTour","Step transition already in progress, ignoring");return}this.isTransitioning=!0,document.querySelectorAll(".onboarding-click-highlight").forEach(t=>{t.classList.remove("onboarding-click-highlight")});const e=this.tutorials[this.currentTutorial];o.info("OnboardingTour","Moving to next step",{currentStep:this.currentStep,totalSteps:e.steps.length,currentStepId:e.steps[this.currentStep]?.id}),this.currentStep<e.steps.length-1?(this.currentStep++,o.info("OnboardingTour",`Advanced to step ${this.currentStep+1}`,{newStepId:e.steps[this.currentStep]?.id}),setTimeout(()=>{this.isTransitioning=!1,this.showStep()},50)):(o.info("OnboardingTour","Tutorial complete, moving to next tutorial"),this.isTransitioning=!1,this.nextTutorial())}previousStep(){document.querySelectorAll(".onboarding-click-highlight").forEach(e=>{e.classList.remove("onboarding-click-highlight")}),this.currentStep>0&&(this.currentStep--,this.resetUserStatesForCurrentStep(),this.showStep())}resetUserStatesForCurrentStep(){const t=this.tutorials[this.currentTutorial].steps[this.currentStep];t&&t.action==="wait-for-option-selection"&&(this.userStates["option-selected"]=!1)}nextTutorial(){A.trackEvent("tour_tutorial_completed",{tutorial:this.currentTutorial});const e=Object.keys(this.tutorials).length;if(o.info("OnboardingTour","nextTutorial called",{currentTutorial:this.currentTutorial,totalTutorials:e,willContinue:this.currentTutorial<e}),this.currentTutorial<e)if(this.currentTutorial++,this.currentStep=0,this.userStates={"option-selected":!1,"choice-confirmed":!1,"modal-opened":!1},o.info("OnboardingTour",`Starting tutorial ${this.currentTutorial}`),this.currentTutorial===2){const t=document.querySelector(".scenario-modal"),i=document.querySelector(".pre-launch-modal");if(t||i){if(o.info("OnboardingTour","Modal detected, closing modal before starting Tutorial 2"),this.waitForModalClosure(()=>{this.scrollToHeroDemoAndStart()}),t){const n=t.querySelector(".modal-close, .close-modal");n&&n.click()}if(i){const n=i.querySelector(".modal-close, .close-modal");n&&n.click()}}else o.info("OnboardingTour","No modal detected, scrolling to hero demo for Tutorial 2"),this.scrollToHeroDemoAndStart();this.isProcessingAction=!1,o.debug("OnboardingTour","Processing flag reset for Tutorial 2 transition")}else if(this.currentTutorial===this.LEARNING_LAB_TUTORIAL){const t=document.querySelector(".scenario-modal"),i=document.querySelector(".pre-launch-modal");t||i?(o.info("OnboardingTour","Modal detected, waiting for closure before starting Tutorial 3"),this.waitForModalClosure(()=>{this.showStep()})):(o.info("OnboardingTour","No modal detected, starting Tutorial 3 immediately"),this.showStep()),this.isProcessingAction=!1,o.debug("OnboardingTour","Processing flag reset for Tutorial 3 transition")}else this.showStep(),this.isProcessingAction=!1,o.debug("OnboardingTour","Processing flag reset for normal tutorial transition");else this.endTour(),this.isProcessingAction=!1,o.debug("OnboardingTour","Processing flag reset after tour end")}previousTutorial(){if(this.currentTutorial>1){this.currentTutorial--;const e=this.tutorials[this.currentTutorial];this.currentStep=e.steps.length-1,this.userStates={"option-selected":!1,"choice-confirmed":!1,"modal-opened":!1},o.info("OnboardingTour",`Going back to tutorial ${this.currentTutorial}`),this.showStep()}}endTour(){if(o.info("OnboardingTour","Ending tour",{currentTutorial:this.currentTutorial,currentStep:this.currentStep,stackTrace:new Error().stack.split(`
`).slice(1,5)}),document.querySelectorAll(".onboarding-click-highlight").forEach(t=>{t.classList.remove("onboarding-click-highlight")}),this.currentTutorial===this.LEARNING_LAB_TUTORIAL){o.info("OnboardingTour","Closing pre-launch modal after Tutorial 3 completion");let t=!1;const i=document.querySelectorAll('.modal-backdrop[style*="flex"], [id^="modal-"][style*="flex"], .modal-backdrop.show, .modal-backdrop.visible');o.info("OnboardingTour",`Found ${i.length} potentially visible modals`);for(const n of i){const s=n.querySelector(".modal-title"),a=s&&s.textContent.includes("Prepare to Explore");if(o.info("OnboardingTour",`Checking modal: ${n.id||"no-id"}, title: ${s?.textContent||"no-title"}, isPreLaunch: ${a}`),a){const r=n.querySelector("#cancel-launch, .btn-cancel");if(r){o.info("OnboardingTour","Found pre-launch modal, triggering cancel button for proper cleanup");try{r.click(),t=!0,o.info("OnboardingTour","Successfully triggered cancel button");break}catch(c){o.error("OnboardingTour","Error clicking cancel button:",c)}}else o.warn("OnboardingTour","Pre-launch modal found but no cancel button")}}if(!t){o.info("OnboardingTour","No pre-launch modal cancel button found, trying fallback approach");const n=document.querySelectorAll("#cancel-launch, .btn-cancel");o.info("OnboardingTour",`Found ${n.length} cancel buttons in DOM`),n.forEach((s,a)=>{if(s&&!t){const r=s.closest('.modal-backdrop, [id^="modal-"], #simulation-modal'),c=r&&(r.style.display==="flex"||r.classList.contains("show")||r.classList.contains("visible"));if(o.info("OnboardingTour",`Cancel button ${a}: modal=${r?.id||"no-modal"}, visible=${c}`),c){o.info("OnboardingTour","Triggering fallback cancel button click for modal cleanup");try{s.click(),t=!0,o.info("OnboardingTour","Successfully triggered fallback cancel button")}catch(d){o.error("OnboardingTour","Error clicking fallback cancel button:",d)}}}})}if(!t){o.info("OnboardingTour","No accessible cancel button found, using manual cleanup"),W.cleanupOrphanedModals(),document.querySelectorAll('[id^="modal-"]').forEach(a=>{const r=a.querySelector(".modal-title");if(r&&r.textContent.includes("Prepare to Explore")){const c=a.querySelector("[data-modal-close], .modal-close, .close-btn");c?(c.click(),o.info("OnboardingTour","Closed pre-launch modal via close button after Tutorial 3 completion")):(W.destroyModalById(a.id),o.info("OnboardingTour","Force destroyed pre-launch modal after Tutorial 3 completion"))}});const s=document.querySelector(".pre-launch-modal");if(s){const a=s.querySelector("[data-modal-close], .modal-close, .close-btn");a?(a.click(),o.info("OnboardingTour","Closed legacy pre-launch modal after Tutorial 3 completion")):(s.remove(),o.info("OnboardingTour","Manually removed legacy pre-launch modal after Tutorial 3 completion"))}}setTimeout(()=>{o.info("OnboardingTour","Running final cleanup after tutorial 3 completion");const n=document.querySelectorAll('[id^="modal-"], .modal-backdrop, .modal-dialog, .modal-body, #simulation-modal').length;o.info("OnboardingTour",`Modal elements before cleanup: ${n}`),W.aggressiveModalCleanup(),W.cleanupOrphanedModals();const s=document.querySelectorAll('[id^="modal-"], .modal-backdrop, .modal-dialog, .modal-body, #simulation-modal').length;o.info("OnboardingTour",`Modal elements after cleanup: ${s} (removed ${n-s})`),s===0?o.info("OnboardingTour","✅ All modal elements successfully cleaned up"):o.warn("OnboardingTour",`⚠️ ${s} modal elements still remain in DOM`)},100)}A.trackEvent("tour_completed",{tutorial:this.currentTutorial,step:this.currentStep}),K.set("tour_completed",!0),this.removeOverlay(),this.isActive=!1}scrollToHeroDemoAndStart(){o.info("OnboardingTour","scrollToHeroDemoAndStart called",{currentTutorial:this.currentTutorial,currentStep:this.currentStep,isActive:this.isActive});const e=document.getElementById("hero-ethics-chart");e?(o.info("OnboardingTour","Hero chart found, scrolling to hero demo for Tutorial 2",{heroChartRect:e.getBoundingClientRect()}),e.scrollIntoView({behavior:"smooth",block:"center",inline:"center"}),setTimeout(()=>{o.info("OnboardingTour","Scroll animation complete, ensuring overlay exists before showing step",{currentTutorial:this.currentTutorial,currentStep:this.currentStep,isActive:this.isActive,overlayExists:!!this.overlay,coachMarkExists:!!this.coachMark}),(!this.overlay||!this.coachMark||!document.body.contains(this.coachMark))&&(o.warn("OnboardingTour","Overlay missing before Tutorial 2, recreating"),this.createOverlay()),this.showStep()},this.SCROLL_DURATION)):(o.warn("OnboardingTour","Hero chart element not found, starting Tutorial 2 anyway"),(!this.overlay||!this.coachMark||!document.body.contains(this.coachMark))&&(o.warn("OnboardingTour","Overlay missing before Tutorial 2 (no hero chart), recreating"),this.createOverlay()),this.showStep())}announceStep(e){const t=document.createElement("div");t.setAttribute("aria-live","polite"),t.setAttribute("aria-atomic","true"),t.className="sr-only",t.textContent=`${e.title}. ${e.content}`,document.body.appendChild(t),setTimeout(()=>{t.remove()},1e3)}waitForModalClosure(e){o.info("OnboardingTour","Starting to wait for modal closure");const t=()=>{const i=document.querySelector(".scenario-modal"),n=document.querySelector(".pre-launch-modal"),s=document.querySelectorAll('.modal, [class*="modal"]:not(.scenario-modal):not(.pre-launch-modal)'),a=Array.from(s).some(r=>{const c=getComputedStyle(r),d=c.display!=="none"&&c.visibility!=="hidden";return o.debug("OnboardingTour","Other modal check",{modal:r.className,isVisible:d}),d});o.info("OnboardingTour","Checking modal status",{scenarioModal:!!i,preLaunchModal:!!n,hasOtherOpenModal:a,scenarioModalClass:i?.className,preLaunchModalClass:n?.className}),!i&&!n&&!a?(o.info("OnboardingTour","All modals closed, proceeding with step after animation delay"),setTimeout(e,this.ANIMATION_DURATION)):(o.debug("OnboardingTour",`Modal still open, checking again in ${this.MODAL_CHECK_DELAY}ms`),setTimeout(t,this.MODAL_CHECK_DELAY))};t()}waitForAccordionOpen(e){const t=()=>{const i=document.querySelector(".option-details");i&&i.offsetHeight>0&&getComputedStyle(i).display!=="none"?e():setTimeout(t,this.CHECK_DELAY)};setTimeout(t,this.ACCORDION_CHECK_DELAY)}isElementInViewport(e){if(!e)return!1;const t=e.getBoundingClientRect();return t.top>=0&&t.left>=0&&t.bottom<=window.innerHeight&&t.right<=window.innerWidth}static startManualTour(e=1){const t=window.onboardingTourInstance;t&&t.isActive&&t.endTour();const i=new G;return i.startTour(e),window.onboardingTourInstance=i,i}static resetTour(){K.remove("tour_completed"),K.remove("has_visited"),o.info("OnboardingTour","Tour progress reset")}debugForceStartFromStep1(){o.warn("OnboardingTour","🐛 DEBUG: Force starting tour from step 1"),this.isActive&&this.finishTour(),this.currentStep=0,this.currentTutorial=1,this.isActive=!1,this.userStates={"option-selected":!1,"choice-confirmed":!1,"modal-opened":!1},this.startTour(1)}setupContentObserver(e,t){this.contentObserver&&this.contentObserver.disconnect(),this.contentObserver=new MutationObserver(i=>{if(this.isTransitioning)return;let n=!1;i.forEach(s=>{(s.type==="childList"||s.type==="characterData")&&(n=!0),s.type==="attributes"&&(s.attributeName==="style"||s.attributeName==="class")&&(n=!0)}),n&&(clearTimeout(this.contentUpdateTimeout),this.contentUpdateTimeout=setTimeout(()=>{this.coachMark&&e&&!this.isTransitioning&&(o.debug("OnboardingTour",`Updating coach mark position due to content change in step ${t.id}`),this.positionCoachMark(e,t.position,t),this.positionSpotlight(e))},this.CONTENT_UPDATE_DELAY))}),this.contentObserver.observe(e,{childList:!0,subtree:!0,characterData:!0,attributes:!0,attributeFilter:["style","class"]}),o.debug("OnboardingTour",`Content observer set up for step ${t.id}`)}scrollToElementInModal(e,t){const i=e.closest(".scenario-modal, .scenario-modal-dialog, .modal-dialog");if(i){const n=i.querySelector(".scenario-content, .modal-body, .modal-content");if(n){const s=e.getBoundingClientRect(),a=n.getBoundingClientRect(),r=n.scrollTop,c=s.top-a.top+r,d=Math.max(0,c-100);return o.info("OnboardingTour",`Scrolling modal to element for step ${t.id}`,{elementTop:s.top,modalTop:a.top,currentScroll:r,targetScroll:d}),n.scrollTo({top:d,behavior:"smooth"}),!0}}return!1}};ne(G,"instanceCount",0);let ie=G;window.OnboardingTour=ie;window.debugStartTour=function(){window.onboardingTourInstance?window.onboardingTourInstance.debugForceStartFromStep1():(o.warn("OnboardingTour","No onboarding tour instance available. Please initialize through app.js first."),o.warn("OnboardingTour","⚠️ Cannot create OnboardingTour instance directly - must be initialized through app.js to prevent multiple instances"))};window.debugShowTourState=function(){window.onboardingTourInstance?o.info("OnboardingTour","Tour State:",{instanceId:window.onboardingTourInstance.instanceId,isActive:window.onboardingTourInstance.isActive,currentTutorial:window.onboardingTourInstance.currentTutorial,currentStep:window.onboardingTourInstance.currentStep,userStates:window.onboardingTourInstance.userStates}):o.warn("OnboardingTour","No onboarding tour instance available")};const z={VIEWPORT:{MOBILE_BREAKPOINT:767},DEFAULTS:{SCORE_VALUE:.5,SLIDER_VALUE:50,METER_VALUE:.5,ETHICS_METER_VALUE:50},FEEDBACK:{EXCELLENT_THRESHOLD:70,GOOD_THRESHOLD:50},TIMING:{ANIMATION_DELAY:300,NOTIFICATION_DURATION:4e3,STAGGER_DELAY:300,QUICK_DELAY:50,FOCUS_DELAY:100,NAV_CLOSE_DELAY:0}},f={log:(l,e=null)=>{(window.DEBUG_MODE||localStorage.getItem("debug")==="true")&&console.log(`[App] ${l}`,e||"")},warn:(l,e=null)=>{(window.DEBUG_MODE||localStorage.getItem("debug")==="true")&&console.warn(`[App] ${l}`,e||"")},error:(l,e=null)=>{console.error(`[App] ${l}`,e||"")}};class Pt{constructor(){this.version="v2.0.1-context-fixes",o.info(`[App] Initializing AIEthicsApp ${this.version}`),this.currentSimulation=null,this.engine=null,this.visualEngine=null,this.simulations=new Map,this.isInitialized=!1,this.heroDemo=null,this.accessibilityManager=null,this.animationManager=null,this.educatorToolkit=null,this.digitalScienceLab=null,this.scenarioGenerator=null,this.ethicsMeters=new Map,this.interactiveButtons=new Map,this.simulationSliders=new Map,this.currentSimulationCanvasId=null,this.ethicsMetersCanvasId=null,this.interactiveButtonsCanvasId=null,this.simulationSlidersCanvasId=null,this.heroDemoCanvasId=null,this.modal=null,this.enhancedModal=null,this.simulationContainer=null,this.categoriesGrid=null,this.lastFocusedElement=null,this.currentTheme="light",this.preferences={reducedMotion:!1,highContrast:!1,largeText:!1},this.errorBoundary=null,this.lastError=null,this.onboardingTour=null,this.availableSimulations=[{id:"bias-fairness",title:"AI Ethics Explorer",description:"Explore real-world AI scenarios and see how different choices affect various groups in society. No right answers - just learning through cause and effect.",difficulty:"beginner",duration:1200,thumbnail:null,tags:["ethics","fairness","education","scenarios","open-ended"],useCanvas:!1,renderMode:"html"},{id:"consent-transparency",title:"Consent & Transparency",description:"Learn about informed consent and the importance of transparency in AI systems.",difficulty:"beginner",duration:480,thumbnail:"src/assets/images/consent-transparency-thumb.svg",tags:["consent","transparency","privacy","communication"]},{id:"autonomy-oversight",title:"Autonomy & Oversight",description:"Balance AI autonomy with human oversight in critical decision-making scenarios.",difficulty:"intermediate",duration:720,thumbnail:"src/assets/images/autonomy-oversight-thumb.svg",tags:["autonomy","oversight","control","responsibility"]},{id:"misinformation-trust",title:"Misinformation & Trust",description:"Combat misinformation and build trustworthy AI communication systems.",difficulty:"advanced",duration:900,thumbnail:"src/assets/images/misinformation-trust-thumb.svg",tags:["misinformation","trust","communication","verification"]}]}async init(){if(!this.isInitialized)try{fe.init(),this.initializeTheme(),this.initializeErrorHandling(),this.initializeLoopDetection(),await this.initializeSystems(),this.setupUI(),await this.loadSimulations(),this.setupEventListeners(),this.setupAccessibility(),this.render(),await this.initializeHeroDemo(),await this.initializeEnhancedObjects(),this.initializeModalFooterManager(),await this.initializeEthicsRadarDemo(),!this.onboardingTour&&!window.onboardingTourInstance?(this.onboardingTour=new ie,window.onboardingTourInstance=this.onboardingTour,this.instrumentOnboardingTour(this.onboardingTour),this.checkAndStartOnboardingTour()):f.warn("OnboardingTour instance already exists, skipping initialization"),this.initializeScrollRevealHeader(),this.isInitialized=!0,f.log("AI Ethics App initialized successfully with modernized infrastructure"),A.trackEvent("app_initialized",{simulations_available:this.availableSimulations.length,browser:U.getBrowserInfo().browser,device:U.getDeviceType(),theme:this.currentTheme,accessibility_enabled:this.preferences.highContrast||this.preferences.largeText})}catch(e){f.error("Failed to initialize app:",e),this.handleError(e,"Failed to initialize the application. Please refresh the page.")}}initializeTheme(){const e=window.matchMedia?.("(prefers-reduced-motion: reduce)").matches,t=window.matchMedia?.("(prefers-contrast: high)").matches,i=ce.getAccessibilitySettings();this.preferences={reducedMotion:i.reducedMotion!==void 0?i.reducedMotion:e,highContrast:i.highContrast!==void 0?i.highContrast:t,largeText:i.largeText||!1},this.currentTheme=this.preferences.highContrast?"high-contrast":"light",this.applyTheme(),this.setupThemeMonitoring(),f.log("Theme initialized:",this.currentTheme,this.preferences)}initializeScrollRevealHeader(){const e=document.querySelector(".header");if(!e)return;let t=window.scrollY;const i=()=>{const a=window.scrollY;a<=10?(e.classList.remove("header-hidden"),e.classList.add("header-visible")):a>t&&a>100?(e.classList.add("header-hidden"),e.classList.remove("header-visible")):a<t&&(e.classList.remove("header-hidden"),e.classList.add("header-visible")),t=a};let n=!1;const s=()=>{n||(requestAnimationFrame(()=>{i(),n=!1}),n=!0)};window.addEventListener("scroll",s,{passive:!0}),e.classList.add("header-visible"),f.log("Scroll reveal header initialized")}setupThemeMonitoring(){const e=window.matchMedia?.("(prefers-reduced-motion: reduce)"),t=window.matchMedia?.("(prefers-contrast: high)"),i=()=>{const n=ce.getAccessibilitySettings(),s={...this.preferences};n.reducedMotion===void 0&&(s.reducedMotion=e?.matches||!1),n.highContrast===void 0&&(s.highContrast=t?.matches||!1),JSON.stringify(s)!==JSON.stringify(this.preferences)&&(this.preferences=s,this.currentTheme=s.highContrast?"high-contrast":"light",this.applyTheme(),this.announceThemeChange(),f.log("System theme changed, updated non-user-set preferences:",s))};e?.addEventListener?.("change",i),t?.addEventListener?.("change",i)}applyTheme(){const{body:e}=document;e.classList.remove("high-contrast","reduced-motion","large-text"),this.preferences.highContrast&&e.classList.add("high-contrast"),this.preferences.reducedMotion&&e.classList.add("reduced-motion"),this.preferences.largeText&&e.classList.add("large-text"),this.updateButtonStates();const t=document.querySelector('meta[name="theme-color"]');t&&t.setAttribute("content","#1a73e8"),this.animationManager&&this.animationManager.updateAnimationDefaults(),this.accessibilityManager&&this.accessibilityManager.updateTheme(this.preferences)}updateButtonStates(){const e=document.getElementById("toggle-high-contrast"),t=document.getElementById("toggle-large-text"),i=document.getElementById("toggle-reduced-motion");e&&e.setAttribute("aria-pressed",this.preferences.highContrast.toString()),t&&t.setAttribute("aria-pressed",this.preferences.largeText.toString()),i&&i.setAttribute("aria-pressed",this.preferences.reducedMotion.toString())}announceThemeChange(){const e=`Theme changed to ${this.currentTheme.replace("-"," ")} mode`;if(this.accessibilityManager)this.accessibilityManager.announce(e);else{const t=document.getElementById("aria-live-polite");t&&(t.textContent=e)}}initializeErrorHandling(){this.errorBoundary=document.getElementById("error-boundary"),window.addEventListener("error",e=>{this.handleError(e.error,"A JavaScript error occurred")}),window.addEventListener("unhandledrejection",e=>{this.handleError(e.reason,"An unhandled promise rejection occurred")}),f.log("Error handling initialized")}handleError(e,t="An unexpected error occurred"){this.lastError=e,f.error("App Error:",e),A.trackEvent("app_error",{error_message:e.message||String(e),error_stack:e.stack,user_agent:navigator.userAgent,timestamp:new Date().toISOString()}),this.showError(t),this.accessibilityManager&&this.accessibilityManager.announce(`Error: ${t}`,"assertive")}showError(e,t=!0){if(!this.errorBoundary){alert(e);return}const i=this.errorBoundary.querySelector(".error-content");if(i){const n=i.querySelector(".error-message"),s=i.querySelector("#retry-action"),a=i.querySelector("#report-error");n&&(n.textContent=e),s&&t?(s.style.display="inline-block",s.onclick=()=>{this.hideError(),this.isInitialized||this.init()}):s&&(s.style.display="none"),a&&(a.onclick=()=>{this.reportError()})}this.errorBoundary.setAttribute("aria-hidden","false"),this.errorBoundary.style.display="flex"}hideError(){this.errorBoundary&&(this.errorBoundary.setAttribute("aria-hidden","true"),this.errorBoundary.style.display="none")}reportError(){if(this.lastError){const e={message:this.lastError.message||String(this.lastError),stack:this.lastError.stack,userAgent:navigator.userAgent,url:window.location.href,timestamp:new Date().toISOString(),appState:{initialized:this.isInitialized,currentSimulation:this.currentSimulation?.id,theme:this.currentTheme}};A.trackEvent("error_reported",e),alert("Error report sent. Thank you for helping us improve the application.")}}async initializeSystems(){try{this.animationManager=new ze({enableAnimations:!this.preferences.reducedMotion,reducedMotion:this.preferences.reducedMotion,performanceMode:this.preferences.reducedMotion?"compatibility":"balanced"}),this.accessibilityManager=new Ge(document.body,{theme:this.currentTheme,preferences:this.preferences}),await this.initializeCoreModules(),this.visualEngineConfig={renderMode:"canvas",accessibility:!0,highPerformance:!this.preferences.reducedMotion,debug:!1,highContrast:this.preferences.highContrast,reducedMotion:this.preferences.reducedMotion},f.log("Core systems initialized with modernized infrastructure")}catch(e){throw f.error("Failed to initialize systems:",e),e}}async initializeCoreModules(){try{this.educatorToolkit=new Ve,f.log("Educator Toolkit initialized"),this.digitalScienceLab=new Qe,f.log("Digital Science Lab initialized"),this.scenarioGenerator=new Xe,f.log("Scenario Generator initialized"),this.connectEducationalModules()}catch(e){throw f.error("Failed to initialize core educational modules:",e),e}}connectEducationalModules(){this.educatorToolkit&&this.scenarioGenerator&&this.educatorToolkit.setScenarioGenerator(this.scenarioGenerator),this.digitalScienceLab&&(this.educatorToolkit&&this.digitalScienceLab.setEducatorToolkit(this.educatorToolkit),this.scenarioGenerator&&this.digitalScienceLab.setScenarioGenerator(this.scenarioGenerator)),f.log("Educational modules connected successfully")}connectModulesToSimulation(e,t){try{if(this.educatorToolkit&&e){e.educatorToolkit=this.educatorToolkit;const i=this.educatorToolkit.getCurriculumAlignment(t.tags||[]);i&&(e.curriculumAlignment=i);const n=this.educatorToolkit.getAssessmentTools(t.difficulty);n&&(e.assessmentTools=n)}if(this.digitalScienceLab&&e){e.digitalScienceLab=this.digitalScienceLab;const i=this.digitalScienceLab.getRelevantStations(t.tags||[]);i&&(e.labStations=i)}if(this.scenarioGenerator&&e&&(e.scenarioGenerator=this.scenarioGenerator,e.supportsGeneratedScenarios)){const i=this.scenarioGenerator.generateScenarios(t.tags?.[0]||"general",t.difficulty||"beginner");i&&(e.generatedScenarios=i)}f.log(`Educational modules connected to simulation: ${e.id||"unknown"}`)}catch(i){f.error("Failed to connect educational modules to simulation:",i)}}setupUI(){if(this.modal=document.getElementById("simulation-modal"),this.simulationContainer=document.getElementById("simulation-container"),this.categoriesGrid=document.querySelector(".categories-grid"),this.loading=document.getElementById("loading"),!this.categoriesGrid){f.error("Categories grid not found");return}this.initializeCategoryGrid()}initializeCategoryGrid(){try{f.log("Attempting to initialize CategoryGrid..."),this.categoryGrid=new _t,f.log("Category grid initialized successfully")}catch(e){f.error("Failed to initialize category grid:",e),this.loadLegacySimulations()}}loadLegacySimulations(){f.log("Loading legacy simulation cards as fallback")}async loadSimulations(){this.availableSimulations.forEach(e=>{this.simulations.set(e.id,e)})}async initializeHeroDemo(){o.info("Hero demo: Using radar chart demo instead of HeroDemo class")}async initializeEnhancedObjects(){try{o.info("Enhanced objects system ready for dynamic loading")}catch(e){o.error("Failed to initialize enhanced objects:",e)}}initializeModalFooterManager(){try{this.modalFooterManager=new qe,this.modalFooterManager.app=this,o.info("Modal footer manager initialized successfully")}catch(e){o.error("Failed to initialize modal footer manager:",e)}}async initializeEthicsRadarDemo(){try{document.getElementById("hero-ethics-chart")?(X=new qt,o.info("Ethics radar demo initialized successfully")):o.warn("Hero ethics chart container not found, skipping radar demo initialization")}catch(e){o.error("Failed to initialize ethics radar demo:",e)}}setupEventListeners(){this.setupMobileNavigation(),this.setupSurpriseMe();const e=document.getElementById("start-learning");e&&e.addEventListener("click",()=>{this.scrollToSimulations()});const t=document.getElementById("test-scenario-modal");t&&t.addEventListener("click",()=>{this.testScenarioModal()});const i=document.getElementById("start-tour-nav");if(i&&i.addEventListener("click",n=>{n.preventDefault(),this.startOnboardingTour();const s=document.querySelector(".nav-toggle"),a=document.querySelector(".main-nav");a&&a.classList.contains("open")&&(s?s.focus():document.body.focus(),setTimeout(()=>{a.classList.remove("open"),s?.setAttribute("aria-expanded","false"),a.setAttribute("aria-hidden","true");const r=document.querySelector(".nav-backdrop");r&&r.classList.remove("open")},0))}),this.modal){const n=this.modal.querySelector(".modal-close"),s=document.getElementById("reset-simulation"),a=document.getElementById("next-scenario");n&&(n.addEventListener("click",()=>this.closeSimulation()),this.modal.addEventListener("keydown",r=>{r.key==="Tab"&&this.trapFocusInModal(r)})),s&&s.addEventListener("click",()=>this.resetCurrentSimulation()),a&&a.addEventListener("click",()=>this.nextScenario()),this.modal.addEventListener("click",r=>{r.target===this.modal&&this.closeSimulation()}),document.addEventListener("keydown",r=>{r.key==="Escape"&&!this.modal.hasAttribute("aria-hidden")&&this.closeSimulation()})}document.addEventListener("click",n=>{if(n.target.classList.contains("enhanced-sim-button")){n.preventDefault();const s=n.target.getAttribute("data-simulation");s&&this.startSimulation.call(this,s)}else if(n.target.classList.contains("simulation-quick-start-btn")){n.preventDefault();const s=n.target.getAttribute("data-simulation");s&&this.launchSimulationDirect.call(this,s)}})}checkAndStartOnboardingTour(){if(this.onboardingTour){if(this.onboardingTour.hasCompletedTour()){f.log("User has already completed onboarding tour");return}this.onboardingTour.isFirstTimeVisit()&&(f.log("First-time visit detected, starting onboarding tour"),setTimeout(()=>{this.onboardingTour.startTour(1)},500))}}startOnboardingTour(){!this.onboardingTour&&!window.onboardingTourInstance?(this.onboardingTour=new ie,window.onboardingTourInstance=this.onboardingTour):window.onboardingTourInstance&&(this.onboardingTour=window.onboardingTourInstance),localStorage.removeItem("has_visited"),localStorage.removeItem("tour_completed"),f.log("Manually starting onboarding tour"),this.onboardingTour.startTour(1)}setupAccessibility(){}render(){this.categoryGrid||this.renderSimulationsGrid()}renderSimulationsGrid(){this.categoriesGrid&&(this.categoriesGrid.innerHTML="",this.availableSimulations.forEach(e=>{const t=this.createSimulationCard(e);this.categoriesGrid.appendChild(t)}))}createSimulationCard(e){const t=U.createElement("div","simulation-card",{role:"gridcell",tabindex:"0","aria-label":`${e.title} simulation`}),i=Ne.getSimulationProgress(e.id),n=i.completed||!1,s=i.score||0;return t.innerHTML=`
            <div class="card-thumbnail">
                <img src="${e.thumbnail}" alt="${e.title}" onerror="this.src='src/assets/images/default-thumb.svg'">
                ${n?'<div class="completion-badge">✓</div>':""}
            </div>
            
            <div class="card-content">
                <h3 class="card-title">${e.title}</h3>
                <p class="card-description">${e.description}</p>
                
                <div class="card-meta">
                    <span class="difficulty difficulty-${e.difficulty}">${U.capitalize(e.difficulty)}</span>
                    <span class="duration">${U.formatDuration(e.duration*1e3)}</span>
                </div>
                
                <div class="card-tags">
                    ${e.tags.map(a=>`<span class="tag">${a}</span>`).join("")}
                </div>
                
                ${n?`
                    <div class="completion-info">
                        <span class="score">Score: ${s}/100</span>
                        <span class="grade">${U.getEthicsGrade(s).grade}</span>
                    </div>
                `:""}
                  <div class="card-actions">
                    <button class="btn btn-primary enhanced-sim-button" data-simulation="${e.id}">
                        Learning Lab Simulation
                    </button>
                    <button class="btn btn-secondary simulation-quick-start-btn" data-simulation="${e.id}">
                        ${n?"Retry":"Start"} Simulation
                    </button>
                </div>
            </div>
        `,t.addEventListener("mouseenter",()=>{t.style.transform="translateY(-2px)"}),t.addEventListener("mouseleave",()=>{t.style.transform="translateY(0)"}),t.addEventListener("keydown",a=>{(a.key==="Enter"||a.key===" ")&&(a.preventDefault(),this.startSimulation(e.id))}),t}async startSimulation(e){try{if(!this||typeof this.showNotification!="function")throw new Error("App context not properly bound. startSimulation called with wrong context.");if(!ce.shouldSkipPreLaunch(e)){this.showPreLaunchModal(e);return}await this.launchSimulationDirect(e)}catch(t){f.error("Failed to start simulation:",t),this.hideLoading(),typeof this.showNotification=="function"?this.showNotification("Failed to start simulation. Please try again.","error"):(o.error("Failed to start simulation:",t.message),window.NotificationToast&&window.NotificationToast.show({type:"error",message:"Failed to start simulation. Please try again.",duration:5e3,closable:!0}))}}showPreLaunchModal(e){o.debug("Showing pre-launch modal for:",e),new Pe(e,{onLaunch:i=>{o.debug("Pre-launch modal onLaunch called with:",i),this.launchSimulationDirect(i||e)},onCancel:()=>{o.debug("Pre-launch modal cancelled"),this.hideLoading()},showEducatorResources:!0}).show()}async launchSimulationDirect(e){try{this.showLoading(),this.currentSimulation&&this.currentSimulation.cleanup&&this.currentSimulation.cleanup(),this.currentSimulationCanvasId&&(O.removeCanvas(this.currentSimulationCanvasId),this.currentSimulationCanvasId=null),this.heroDemoCanvasId&&(O.removeCanvas(this.heroDemoCanvasId),this.heroDemoCanvasId=null);const t=this.simulations.get(e);if(!t)throw new Error(`Simulation ${e} not found`);A.trackSimulationStart(e,t.title);const i=document.getElementById("simulation-container");if(!i)throw new Error("Simulation container not found");i.classList.add("loading"),i.setAttribute("aria-busy","true"),i.setAttribute("aria-label",`Loading ${t.title} simulation`),i.innerHTML="",i.classList.remove("error");const{canvas:n,id:s}=await O.createCanvas({width:600,height:400,container:i,className:"simulation-canvas",id:`simulation-${e}`});if(this.currentSimulationCanvasId=s,t.useCanvas!==!1&&t.renderMode!=="html"?(n.style.cssText=`
                    max-width: 100%;
                    max-height: 100%;
                    width: auto;
                    height: auto;
                    border: 1px solid #ddd;
                    border-radius: 8px;
                    background: #fff;
                `,this.engine=await O.createVisualEngine(s,{renderMode:"canvas",accessibility:!0,debug:!1,width:600,height:400}),this.engine.container=i):(this.engine={container:i,type:"html",renderMode:"html",start:()=>{},stop:()=>{},destroy:()=>{}},n&&n.parentNode&&n.parentNode.removeChild(n)),this.currentSimulation=await this.createSimulationInstance(e,t),!this.currentSimulation)throw new Error("Failed to create simulation instance");this.currentSimulation.init(this.engine),this.setupSimulationEventListeners(),this.showEnhancedSimulationModal(e,t),this.engine.start(),this.currentSimulation.start(),this.hideLoading(),i&&(i.classList.remove("loading"),i.removeAttribute("aria-busy"),i.setAttribute("aria-label",`${t.title} simulation`)),o.debug("Simulation launched successfully")}catch(t){f.error("Failed to start simulation:",t),this.hideLoading();const i=document.getElementById("simulation-container");i&&(i.classList.remove("loading"),i.classList.add("error"),i.removeAttribute("aria-busy"),i.setAttribute("aria-label","Simulation failed to load"),i.innerHTML=`
                    <div style="text-align: center; padding: 2rem;">
                        <h3>Simulation Failed to Load</h3>
                        <p>There was an error loading the simulation. Please try again.</p>
                        <button class="btn btn-primary" onclick="this.closest('.modal').querySelector('.modal-close').click()">Close</button>
                    </div>
                `),this.showError("Failed to start the simulation. Please try again.")}}async createSimulationInstance(e,t){try{let i;switch(e){default:{const n=[{id:"intro",title:"Introduction",description:"Welcome to this open-ended exploration of AI ethics",objective:"Explore different perspectives and discover consequences of choices"},{id:"decision1",title:"First Decision",description:"Make your first ethical choice",objective:"Choose the most ethical option"},{id:"conclusion",title:"Conclusion",description:"Reflect on your decisions",objective:"Review your ethical choices"}];i=new je(e,{title:t.title,description:t.description,difficulty:t.difficulty,duration:t.duration,scenarios:n,ethicsMetrics:[{name:"fairness",label:"Fairness",value:z.DEFAULTS.ETHICS_METER_VALUE},{name:"transparency",label:"Transparency",value:z.DEFAULTS.ETHICS_METER_VALUE},{name:"privacy",label:"Privacy",value:z.DEFAULTS.ETHICS_METER_VALUE}]}),i.container=document.getElementById("simulation-container");break}}return i&&this.connectModulesToSimulation(i,t),i}catch(i){throw f.error(`Failed to load simulation ${e}:`,i),i}}setupSimulationEventListeners(){this.currentSimulation&&(this.currentSimulation.on("simulation:completed",e=>{this.onSimulationCompleted(e)}),this.currentSimulation.on("ethics:updated",e=>{f.log("Ethics updated:",e)}),this.currentSimulation.on("scenario:loaded",e=>{this.updateModalTitle(e.scenario.title)}))}onSimulationCompleted(e){f.log("Simulation completed:",e);try{const t=document.querySelector(".enhanced-simulation-modal");t&&(t.style.display="none",t.setAttribute("aria-hidden","true")),this.currentSimulation&&this.currentSimulation.id&&A.trackSimulationComplete(this.currentSimulation.id,e),this.showPostSimulationModal(e)}catch(t){f.error("Error handling simulation completion:",t),this.hideModal(),this.showNotification("Simulation completed! Thank you for exploring AI Ethics.","success")}}showPostSimulationModal(e){const t=this.currentSimulation?.id||"unknown";new gt(t,{sessionData:e,onComplete:()=>{this.hideModal(),this.showNotification("Thank you for your thoughtful reflection!","success")},onSkip:()=>{this.hideModal()},onRestart:()=>{this.hideModal(),this.startSimulation(t)}}).show()}showEnhancedSimulationModal(e,t){f.log("Showing enhanced simulation modal for:",e);try{const i={simulation:this.currentSimulation,onClose:()=>{f.log("Enhanced modal closed"),this.enhancedModal=null,this.hideModal()},onMinimize:()=>{f.log("Enhanced modal minimized")}};this.enhancedModal=new pt(e,i),this.enhancedModal.show(),setTimeout(()=>{const n=this.enhancedModal.getSimulationContainer();if(n&&this.currentSimulation){f.log("Moving simulation to enhanced modal container");const s=document.getElementById("simulation-container");if(s){for(;s.firstChild;)n.appendChild(s.firstChild);this.engine&&(this.engine.container=n),this.currentSimulation.container&&(this.currentSimulation.container=n),this.currentSimulation.setupUI&&this.currentSimulation.setupUI()}}},100)}catch(i){f.error("Failed to show enhanced simulation modal:",i),this.showSimulationModal(t)}}showSimulationModal(e){if(!this.modal)return;const t=this.modal.querySelector("#modal-title");t&&(t.textContent=e.title),this.lastFocusedElement=document.activeElement,this.modal.removeAttribute("inert"),this.modal.setAttribute("aria-hidden","false"),this.modal.style.display="flex",requestAnimationFrame(()=>{this.modal.classList.add("visible")});const i=document.getElementById("main-content");i&&i.setAttribute("inert",""),this.modalFocusTrap=Ee.createTrap(this.modal,{autoFocus:!0,restoreFocus:!0})}trapFocusInModal(e){this.modalFocusTrap&&e.key}closeSimulation(){if(this.currentSimulation&&(this.currentSimulation.reset(),this.currentSimulation=null),this.engine&&(this.engine.stop(),this.engine.destroy(),this.engine=null),[this.currentSimulationCanvasId,this.ethicsMetersCanvasId,this.interactiveButtonsCanvasId,this.simulationSlidersCanvasId].forEach(t=>{t&&O.removeCanvas(t)}),this.currentSimulationCanvasId=null,this.ethicsMetersCanvasId=null,this.interactiveButtonsCanvasId=null,this.simulationSlidersCanvasId=null,this.modal){this.modalFocusTrap&&(this.modalFocusTrap.destroy(),this.modalFocusTrap=null),this.modal.setAttribute("inert",""),this.modal.setAttribute("aria-hidden","true"),this.modal.classList.remove("visible"),this.modal.style.display="none";const t=document.getElementById("main-content");t&&t.removeAttribute("inert")}this.simulationContainer&&(this.simulationContainer.innerHTML="",this.simulationContainer.classList.remove("loading","error"),this.simulationContainer.removeAttribute("aria-busy"),this.simulationContainer.removeAttribute("aria-label"))}resetCurrentSimulation(){this.currentSimulation&&this.currentSimulation.reset&&this.currentSimulation.reset()}showLoading(){this.loading&&(this.loading.style.display="flex",this.loading.setAttribute("aria-hidden","false"))}hideLoading(){this.loading&&(this.loading.style.display="none",this.loading.setAttribute("aria-hidden","true"))}toggleSimulationPause(e){this.currentSimulation&&(e&&this.currentSimulation.pause?this.currentSimulation.pause():!e&&this.currentSimulation.resume&&this.currentSimulation.resume())}async populateEnhancedModalData(e){try{const{simulationData:t}=await x(async()=>{const{simulationData:n}=await Promise.resolve().then(()=>at);return{simulationData:n}},void 0,import.meta.url),i=t[e];if(!i){f.warn(`No simulation data found for ${e}`);return}this.populateResourcesTab(i),this.populateHelpTab(i),this.populateQuickResourcesPanel(i)}catch(t){f.error("Failed to populate enhanced modal data:",t)}}populateResourcesTab(e){if(!this.currentEnhancedModal)return;const{modal:t}=this.currentEnhancedModal;if(!t)return;const i=t.querySelector("#background-reading");i&&e.resources?.backgroundReading&&(i.innerHTML=e.resources.backgroundReading.map(a=>`
                <div class="resource-item">
                    <a href="${a.url}" target="_blank" class="resource-title">${a.title}</a>
                    <p class="resource-description">${a.description}</p>
                </div>
            `).join(""));const n=t.querySelector("#related-videos");n&&e.resources?.videos&&(n.innerHTML=e.resources.videos.map(a=>`
                <div class="resource-item">
                    <a href="${a.url}" target="_blank" class="resource-title">${a.title}</a>
                    <p class="resource-description">${a.description}</p>
                    <span class="resource-duration">${a.duration}</span>
                </div>
            `).join(""));const s=t.querySelector("#discussion-questions");s&&e.educatorResources?.discussionQuestions&&(s.innerHTML=e.educatorResources.discussionQuestions.map(a=>`
                <div class="resource-item">
                    <p class="discussion-question">${a}</p>
                </div>
            `).join(""))}populateHelpTab(e){if(!this.currentEnhancedModal)return;const{modal:t}=this.currentEnhancedModal;if(!t)return;const i=t.querySelector("#ethics-explanation");i&&e.vocabulary&&(i.innerHTML=Object.entries(e.vocabulary).map(([n,s])=>`
                <div class="ethics-term">
                    <h5>${n}</h5>
                    <p>${s}</p>
                </div>
            `).join(""))}populateQuickResourcesPanel(e){if(!this.currentEnhancedModal)return;const{modal:t}=this.currentEnhancedModal;if(!t)return;const i=t.querySelector("#quick-concepts");if(i&&e.vocabulary){const s=Object.keys(e.vocabulary).slice(0,5);i.innerHTML=s.map(a=>`
                <li><a href="#" class="resource-link" data-term="${a}">${a}</a></li>
            `).join(""),i.querySelectorAll("[data-term]").forEach(a=>{a.addEventListener("click",r=>{r.preventDefault();const{dataset:{term:c}}=r.target,d=e.vocabulary[c];this.showQuickHelp(c,d)})})}}showQuickHelp(e,t){this.showNotification(`${e}: ${t}`,"info",5e3)}showNotification(e,t="info",i=5e3){return window.NotificationToast?window.NotificationToast.show({type:t,message:e,duration:i,closable:!0}):(o.info(`[${t.toUpperCase()}] ${e}`),null)}setupSurpriseMe(){const e=document.getElementById("surprise-me-nav");e&&e.addEventListener("click",t=>{t.preventDefault(),this.launchRandomScenario()})}launchRandomScenario(){const e=this.getRandomUncompletedScenario();if(!e){this.showNotification("🎉 Congratulations! You've completed all scenarios! Try replaying your favorites.","success",z.TIMING.NOTIFICATION_DURATION);return}const t=document.querySelector(".main-nav");if(t&&t.classList.contains("open")){t.classList.remove("open");const i=document.querySelector(".nav-toggle");i&&(i.classList.remove("active"),i.setAttribute("aria-expanded","false")),document.body.style.overflow=""}this.showNotification(`🎉 Surprise! Opening "${e.scenario.title}" from ${e.category.title}`,"info",z.TIMING.NOTIFICATION_DURATION),this.categoryGrid?this.categoryGrid.openScenarioModalDirect(e.category.id,e.scenario.id):(o.warn("CategoryGrid not available, redirecting to scenario"),window.location.href=`#scenario-${e.scenario.id}`)}getRandomUncompletedScenario(){try{const e=Ie(),t=localStorage.getItem("simulateai_category_progress"),i=t?JSON.parse(t):{},n=[];if(e.forEach(a=>{be(a.id).forEach(c=>{i[a.id]?.[c.id]||!1||n.push({category:a,scenario:c})})}),n.length===0)return null;const s=Math.floor(Math.random()*n.length);return n[s]}catch(e){return o.error("Failed to get random uncompleted scenario:",e),null}}setupMobileNavigation(){const e=document.querySelector(".nav-toggle"),t=document.querySelector(".main-nav"),i=document.querySelector(".nav-backdrop"),n=document.querySelectorAll(".nav-link");if(!e||!t){o.warn("Mobile navigation elements not found");return}const s=d=>{const u=t.classList.contains("open"),h=d!==void 0?d:!u;if(t.classList.toggle("open",h),e.classList.toggle("active",h),i&&i.classList.toggle("open",h),h){e.setAttribute("aria-expanded","true"),t.setAttribute("aria-hidden","false");const p=t.querySelector(".nav-link");p&&setTimeout(()=>p.focus(),z.TIMING.FOCUS_DELAY)}else e.focus(),setTimeout(()=>{e.setAttribute("aria-expanded","false"),t.setAttribute("aria-hidden","true")},0);A.trackEvent("mobile_nav_toggled",{isOpen:h})};e.addEventListener("click",d=>{d.preventDefault(),s()}),i&&i.addEventListener("click",()=>{s(!1)}),document.addEventListener("click",d=>{t.classList.contains("open")&&(e.contains(d.target)||t.contains(d.target)||i&&i.contains(d.target)||s(!1))}),n.forEach(d=>{d.addEventListener("click",u=>{const h=d.getAttribute("href"),p=d.textContent.trim();if(d.closest(".nav-item-dropdown")&&window.innerWidth<=768||(o.info(`Navigation link clicked: "${p}" -> ${h}`),d.id==="surprise-me-nav"))return;const y=()=>{e?e.focus():document.body.focus(),setTimeout(()=>s(!1),z.TIMING.NAV_CLOSE_DELAY)};if(h&&h.startsWith("#")&&h!=="#"){u.preventDefault();const m=document.querySelector(h);m?(o.info(`Navigating to section: ${h}`),y(),setTimeout(()=>{m.scrollIntoView({behavior:"smooth",block:"start"}),o.info(`Scrolled to section: ${h}`)},100),A.trackEvent("navigation_link_clicked",{target:h,text:p,success:!0})):(o.warn(`Navigation target not found: ${h}`),y(),this.showNotification&&this.showNotification(`Section "${p}" is not available on this page.`,"warning",3e3),A.trackEvent("navigation_link_clicked",{target:h,text:p,success:!1,error:"target_not_found"}))}else o.info(`External link or non-hash navigation: ${h}`),y(),A.trackEvent("navigation_link_clicked",{target:h,text:p,type:"external"})})}),document.addEventListener("keydown",d=>{d.key==="Escape"&&t.classList.contains("open")&&s(!1)});let a;const r=768;window.addEventListener("resize",()=>{clearTimeout(a),a=setTimeout(()=>{window.innerWidth>=r&&t.classList.contains("open")&&(s(!1),document.body.style.overflow="")},100)}),this.setupNavFocusTrap(t,e);function c(){const d=document.querySelector(".nav-item-dropdown .nav-link"),u=document.querySelector(".nav-item-dropdown"),h=document.querySelector(".mega-menu");if(!d||!u||!h)return;const p=768,g=()=>window.innerWidth<=p,y=document.querySelector(".mega-menu-search");if(y&&!g()){y.addEventListener("input",S=>{const T=S.target.value.toLowerCase(),B=document.querySelectorAll(".mega-menu-item");let M=0;B.forEach(D=>{const $e=D.querySelector("h4").textContent.toLowerCase(),He=D.querySelector("p").textContent.toLowerCase();$e.includes(T)||He.includes(T)?(D.style.display="flex",M++):D.style.display="none"});let w=document.querySelector(".mega-menu-no-results");M===0&&T.length>0?(w||(w=document.createElement("div"),w.className="mega-menu-no-results",w.innerHTML=`
                <div style="text-align: center; padding: var(--spacing-6); color: var(--color-gray-600);">
                  <p>No categories match "${T}"</p>
                  <small>Try searching for terms like "privacy", "decision", or "robot"</small>
                </div>
              `,document.querySelector(".mega-menu-grid").appendChild(w)),w.style.display="block"):w&&(w.style.display="none")});const v=()=>{y.value="",document.querySelectorAll(".mega-menu-item").forEach(B=>{B.style.display="flex"});const T=document.querySelector(".mega-menu-no-results");T&&(T.style.display="none")};g()||d.addEventListener("click",v)}d.addEventListener("click",v=>{if(g()){v.preventDefault(),v.stopPropagation();const S=u.getAttribute("aria-expanded")==="true";u.setAttribute("aria-expanded",!S)}}),document.querySelectorAll(".mega-menu-item").forEach(v=>{v.addEventListener("click",S=>{S.preventDefault();const T=v.getAttribute("href");if(u.setAttribute("aria-expanded","false"),window.innerWidth<=768){const M=document.querySelector(".main-nav"),w=document.querySelector(".nav-toggle"),D=document.querySelector(".nav-backdrop");M&&w&&(w.focus(),setTimeout(()=>{M.classList.remove("open"),w.classList.remove("active"),w.setAttribute("aria-expanded","false"),M.setAttribute("aria-hidden","true"),D&&D.classList.remove("open"),document.body.style.overflow=""},0))}if(T.startsWith("#category-")){const M=T.replace("#category-","");let w=document.querySelector(`[data-category-id="${M}"]`);if(w||(w=document.querySelector(`#category-${M}`)),w)setTimeout(()=>{w.scrollIntoView({behavior:"smooth",block:"start"})},100);else{const D=document.querySelector("#simulations");D&&setTimeout(()=>{D.scrollIntoView({behavior:"smooth",block:"start"})},100)}}})});const R=document.querySelector(".mega-menu-view-all");R&&R.addEventListener("click",v=>{if(v.preventDefault(),u.setAttribute("aria-expanded","false"),window.innerWidth<=768){const B=document.querySelector(".main-nav"),M=document.querySelector(".nav-toggle"),w=document.querySelector(".nav-backdrop");B&&M&&(M.focus(),setTimeout(()=>{B.classList.remove("open"),M.classList.remove("active"),M.setAttribute("aria-expanded","false"),B.setAttribute("aria-hidden","true"),w&&w.classList.remove("open"),document.body.style.overflow=""},0))}const T=document.querySelector("#simulations");T&&setTimeout(()=>{T.scrollIntoView({behavior:"smooth",block:"start"})},100)}),document.addEventListener("click",v=>{u.contains(v.target)||u.setAttribute("aria-expanded","false")}),d.addEventListener("keydown",v=>{if(v.key==="Enter"||v.key===" "){v.preventDefault();const S=u.getAttribute("aria-expanded")==="true";u.setAttribute("aria-expanded",!S)}v.key==="Escape"&&u.setAttribute("aria-expanded","false")}),document.addEventListener("keydown",v=>{v.key==="Escape"&&g()&&u.getAttribute("aria-expanded")==="true"&&u.setAttribute("aria-expanded","false")}),window.addEventListener("resize",()=>{u.setAttribute("aria-expanded","false")})}document.addEventListener("DOMContentLoaded",c)}setupNavFocusTrap(e,t){const i=["a[href]","button:not([disabled])","textarea:not([disabled])","input:not([disabled])","select:not([disabled])",'[tabindex]:not([tabindex="-1"])'].join(",");e.addEventListener("keydown",n=>{if(!e.classList.contains("open")||n.key!=="Tab")return;const s=e.querySelectorAll(i),a=s[0],r=s[s.length-1];n.shiftKey?document.activeElement===a&&(n.preventDefault(),r.focus()):document.activeElement===r&&(n.preventDefault(),a.focus())})}async scrollToSimulations(){try{if(!document.getElementById("categories")){o.warn("Categories section not found, cannot scroll");return}await fe.scrollToElement("#categories",{behavior:"smooth",offset:80,respectReducedMotion:!0}),o.info("Scrolled to Ethics Categories section"),A.trackEvent("navigation_to_categories",{source:"start_learning_button",target:"ethics_categories",method:"smooth_scroll"}),this.accessibilityManager&&this.accessibilityManager.announceToScreenReader("Navigated to Ethics Categories section","polite")}catch(e){o.error("Failed to scroll to Ethics Categories:",e);try{const t=document.getElementById("categories");t&&(t.scrollIntoView({block:"start"}),o.info("Used fallback scroll to Ethics Categories"))}catch(t){o.error("Fallback scroll also failed:",t)}}}async testScenarioModal(){try{o.info("Testing scenario modal with trolley problem scenario");const e=(await x(()=>Promise.resolve().then(()=>Tt),void 0,import.meta.url)).default;await new e().open("autonomous-vehicle-split","trolley-problem"),o.info("Scenario modal test launched successfully")}catch(e){o.error("Failed to test scenario modal:",e),this.showNotification("Failed to open test scenario modal","error")}}openEducatorTools(){o.info("Opening educator tools"),A.trackEvent("educator_tools_accessed",{source:"educator_guide_button"}),this.scrollToSimulations()}initializeLoopDetection(){window.location.hostname==="localhost"||window.location.hostname==="127.0.0.1"||window.location.protocol==="file:"||window.location.search.includes("debug=true")?(N.setEnabled(!0),window.loopDetector=N,window.onboardingTourInstance&&this.instrumentOnboardingTour(window.onboardingTourInstance),o.info("InfiniteLoopDetector","🔧 Loop detection enabled for development")):(N.setEnabled(!1),o.info("InfiniteLoopDetector","🔒 Loop detection disabled for production"))}instrumentOnboardingTour(e){["positionCoachMark","showStep","nextStep","handleAction"].forEach(i=>{if(e[i]){const n=e[i];e[i]=function(...s){return N.trackExecution(`OnboardingTour.${i}`),n.apply(this,s)}}}),o.info("InfiniteLoopDetector","📊 Instrumented OnboardingTour methods for monitoring")}}class qt{constructor(){this.demoChart=null,this.ANIMATION_DELAY=200,this.RESET_DELAY=300,this.initializeDemo()}async initializeDemo(){try{this.demoChart=new _e("hero-ethics-chart",{title:"Ethical Impact Analysis",width:580,height:580,realTime:!1,showLabels:!0,animated:!0,isDemo:!0}),o.info("Ethics radar demo initialized successfully")}catch(e){o.error("Failed to initialize ethics radar demo:",e)}}simulatePattern(e){const t={utilitarian:{fairness:3,sustainability:4,autonomy:2,beneficence:5,transparency:3,accountability:4,privacy:2,proportionality:4},deontological:{fairness:5,sustainability:3,autonomy:5,beneficence:4,transparency:4,accountability:5,privacy:4,proportionality:3},virtue:{fairness:4,sustainability:4,autonomy:4,beneficence:4,transparency:3,accountability:4,privacy:3,proportionality:4},balanced:{fairness:4,sustainability:4,autonomy:4,beneficence:4,transparency:4,accountability:4,privacy:4,proportionality:4}};this.demoChart&&t[e]&&setTimeout(()=>{this.demoChart.setScores(t[e]),this.showFeedback(e)},this.ANIMATION_DELAY)}reset(){this.demoChart&&setTimeout(()=>{this.demoChart.resetScores(),this.hideFeedback()},this.RESET_DELAY)}showFeedback(e){const t=document.getElementById("hero-demo-feedback");if(!t)return;const i=t.querySelector(".popover-content");if(!i)return;H&&(clearTimeout(H),H=null);const s={utilitarian:{title:"Utilitarian Ethics",message:"This approach prioritizes the greatest good for the greatest number, emphasizing beneficence and outcomes over individual rights."},deontological:{title:"Rights-Based Ethics",message:"This framework focuses on duties and rights, giving priority to fairness, autonomy, and accountability regardless of consequences."},virtue:{title:"Virtue Ethics",message:"This approach emphasizes character and moral virtues, seeking balance across all ethical dimensions through practical wisdom."},balanced:{title:"Balanced Approach",message:"This represents a comprehensive ethical framework that considers all dimensions equally, often used in complex real-world scenarios."}}[e];s&&(i.innerHTML=`
                <h5>${s.title}</h5>
                <p>${s.message}</p>
            `,t.classList.add("show"),H=setTimeout(()=>{this.hideFeedback(),H=null},5e3))}hideFeedback(){H&&(clearTimeout(H),H=null);const e=document.getElementById("hero-demo-feedback");if(!e)return;const t=e.querySelector(".popover-content");e.classList.remove("show"),setTimeout(()=>{t&&(t.innerHTML="")},300)}}let X=null,oe=null,H=null;window.simulateEthicsPattern=function(l,e){X&&(oe===l?(X.reset(),oe=null,we(null)):(X.simulatePattern(l),oe=l,we(l),e&&Bt(e)))};window.resetEthicsDemo=function(){X&&(X.reset(),oe=null,we(null))};function Bt(l){const e=document.getElementById("hero-demo-feedback");if(!e||!l)return;const t=l.getBoundingClientRect(),n=l.closest(".demo-controls-grid").getBoundingClientRect(),s=t.left-n.left+t.width/2;e.style.left=`${s}px`,e.style.transform="translateX(-50%)"}function we(l){document.querySelectorAll(".hero-demo-controls .demo-btn").forEach(t=>{const i=t.textContent.toLowerCase();let n="";i.includes("utilitarian")?n="utilitarian":i.includes("rights-based")?n="deontological":i.includes("virtue")?n="virtue":i.includes("balanced")&&(n="balanced"),l===n?t.classList.add("active"):t.classList.remove("active")})}window.toggleRadarInstructions=function(){const l=document.querySelector(".radar-instructions-accordion"),e=document.querySelector(".accordion-content");l&&e&&(l.classList.contains("open")?(l.classList.remove("open"),e.classList.add("collapsed"),e.style.maxHeight="0",e.style.opacity="0"):(l.classList.add("open"),e.classList.remove("collapsed"),e.style.maxHeight=`${e.scrollHeight}px`,e.style.opacity="1"))};window.toggleEthicsGlossary=function(){const l=document.querySelector(".ethics-glossary-accordion"),e=document.querySelector(".ethics-glossary-accordion .accordion-content");l&&e&&(l.classList.contains("open")?(l.classList.remove("open"),e.classList.add("collapsed"),e.style.maxHeight="0",e.style.opacity="0"):(l.classList.add("open"),e.classList.remove("collapsed"),e.style.maxHeight=`${e.scrollHeight}px`,e.style.opacity="1"))};document.addEventListener("DOMContentLoaded",()=>{document.addEventListener("click",l=>{const e=document.querySelector(".radar-instructions-accordion.open .accordion-content");if(e&&e.contains(l.target)){const i=document.querySelector(".radar-instructions-accordion .accordion-header");(!i||!i.contains(l.target))&&window.toggleRadarInstructions()}const t=document.querySelector(".ethics-glossary-accordion.open .accordion-content");if(t&&t.contains(l.target)){const i=document.querySelector(".ethics-glossary-accordion .accordion-header");(!i||!i.contains(l.target))&&window.toggleEthicsGlossary()}})});window.addEventListener("error",l=>{f.error("Error occurred:",l.message),alert("An error occurred while loading the application. Please try again later.")});const Ae=new Pt;document.readyState==="loading"?document.addEventListener("DOMContentLoaded",()=>Ae.init()):Ae.init();window.app=Ae;class $t{static create({header:e="",content:t="",actions:i=[]}={}){const n=document.createElement("div");if(n.className="card",n.tabIndex=0,e){const s=document.createElement("div");s.className="card-header",typeof e=="string"?s.textContent=e:s.appendChild(e),n.appendChild(s)}if(t){const s=document.createElement("div");s.className="card-content",typeof t=="string"?s.textContent=t:s.appendChild(t),n.appendChild(s)}if(i&&i.length){const s=document.createElement("div");s.className="card-actions",i.forEach(a=>{const r=document.createElement("button");r.className=`card-action-btn${a.className?` ${a.className}`:""}`,r.type="button",r.textContent=a.label,r.addEventListener("click",a.onClick),s.appendChild(r)}),n.appendChild(s)}return n}}window.CardComponent=$t;class Ht extends HTMLElement{static get observedAttributes(){return["size","centered","hidden"]}constructor(){super();const e=this.attachShadow({mode:"open"}),t=document.createElement("span");t.className="loader-spinner",this.hasAttribute("centered")&&t.classList.add("centered"),this.hasAttribute("hidden")&&t.setAttribute("hidden",""),e.appendChild(t);const i=document.createElement("link");i.rel="stylesheet",i.href="src/styles/loader-spinner.css",e.appendChild(i),this._spinner=t}attributeChangedCallback(e,t,i){if(e==="size"){const n=i||"48px";this._spinner.style.width=n,this._spinner.style.height=n}e==="centered"&&this._spinner.classList.toggle("centered",this.hasAttribute("centered")),e==="hidden"&&(this.hasAttribute("hidden")?this._spinner.setAttribute("hidden",""):this._spinner.removeAttribute("hidden"))}}customElements.define("loader-spinner",Ht);class Ut extends HTMLElement{constructor(){super();const e=this.attachShadow({mode:"open"}),t=document.createElement("div");t.className="form-group";const i=document.createElement("label");i.textContent=this.getAttribute("label")||"",i.htmlFor="input";const n=document.createElement("input");n.type=this.getAttribute("type")||"text",n.className="custom-input",n.id="input",n.name=this.getAttribute("name")||"",n.placeholder=this.getAttribute("placeholder")||"",this.hasAttribute("value")&&(n.value=this.getAttribute("value")),this.hasAttribute("required")&&(n.required=!0),this.hasAttribute("disabled")&&(n.disabled=!0),t.appendChild(i),t.appendChild(n);const s=document.createElement("link");s.rel="stylesheet",s.href="src/styles/form-input-components.css",e.appendChild(s),e.appendChild(t)}}class Ft extends HTMLElement{constructor(){super();const e=this.attachShadow({mode:"open"}),t=document.createElement("button");t.className="custom-button",t.type=this.getAttribute("type")||"button",t.textContent=this.getAttribute("label")||"Submit",this.hasAttribute("disabled")&&(t.disabled=!0);const i=document.createElement("link");i.rel="stylesheet",i.href="src/styles/form-input-components.css",e.appendChild(i),e.appendChild(t)}}customElements.define("custom-input",Ut);customElements.define("custom-button",Ft);
//# sourceMappingURL=main-BO5t0xpb.js.map
