{"version":3,"file":"trolley-problem-scenarios-i-LG8Bzr.js","sources":["../../src/js/data/scenarios/trolley-problem-scenarios.js"],"sourcesContent":["/**\n * Trolley Problem Scenarios\n * Life-and-death decision scenarios for autonomous systems\n */\n\nexport default {\n  'autonomous-vehicle-split': {\n    title: 'Autonomous Vehicle Split Decision',\n    dilemma:\n      'The Autonomous Vehicle faces a life-or-death decision: prioritize passenger safety at the expense of multiple pedestrian lives, or sacrifice its passenger to save the greater number.',\n    ethicalQuestion:\n      'Should the Autonomous Vehicle be programmed to minimize overall harm by sacrificing its passenger, prioritize passenger protection at all costs, or leave the outcome to chance without intentional preference?',\n    options: [\n      {\n        id: 'option-a',\n        text: 'Prioritize the Greater Good (Sacrifice Passenger)',\n        description:\n          \"Program the Autonomous Vehicle to minimize the overall harm by protecting multiple lives over the single passenger's life.\",\n        impact: {\n          fairness: +1,\n          sustainability: 0,\n          autonomy: -1,\n          beneficence: +2,\n          transparency: +1,\n          accountability: +1,\n          privacy: 0,\n          proportionality: +2,\n        },\n        pros: [\n          'Maximizes total lives saved.',\n          'Reflects utilitarian ethics (greatest good for greatest number).',\n          'Public perception of ethical responsibility may improve.',\n        ],\n        cons: [\n          'Passengers may distrust AVs, limiting adoption.',\n          'Liability and insurance complexities if passenger harm occurs.',\n          'Ethical dilemma around intentionally harming the person who trusted the vehicle.',\n        ],\n      },\n      {\n        id: 'option-b',\n        text: 'Passenger Protection Priority',\n        description:\n          'Program the Autonomous Vehicle to prioritize the safety of its passenger above all other considerations.',\n        impact: {\n          fairness: -1,\n          sustainability: -1,\n          autonomy: +1,\n          beneficence: -1,\n          transparency: +1,\n          accountability: 0,\n          privacy: 0,\n          proportionality: -2,\n        },\n        pros: [\n          'Builds consumer trust and confidence in AV technology.',\n          'Clear accountability structure—passenger pays, passenger protected.',\n          'Avoids the moral complexity of programming active harm.',\n        ],\n        cons: [\n          'Potentially higher overall casualties in multi-person accidents.',\n          'May be seen as privileging those who can afford AVs.',\n          'Could face legal challenges from families of external victims.',\n        ],\n      },\n      {\n        id: 'option-c',\n        text: 'Non-intervention (Randomized Decision)',\n        description:\n          'Program the Autonomous Vehicle to make random or speed-based decisions without weighing lives.',\n        impact: {\n          fairness: 0,\n          sustainability: -1,\n          autonomy: -1,\n          beneficence: 0,\n          transparency: -1,\n          accountability: -1,\n          privacy: 0,\n          proportionality: 0,\n        },\n        pros: [\n          'Avoids the moral burden of programming life-or-death value judgments.',\n          'May be legally safer by not making intentional choices about harm.',\n          'Treats all lives as equally valuable by default.',\n        ],\n        cons: [\n          \"Doesn't optimize for the best possible outcome.\",\n          'Public may view this as morally irresponsible or cowardly.',\n          'May result in worse average outcomes than deliberate programming.',\n        ],\n      },\n    ],\n  },\n\n  'tunnel-dilemma': {\n    title: 'Tunnel Dilemma',\n    dilemma:\n      'The self-driving bus must choose between running over a child who has unexpectedly fallen into its path, or swerving into the tunnel wall, which would kill several elderly passengers on board.',\n    ethicalQuestion:\n      'Should the autonomous system prioritize the life of a single young pedestrian or the lives of multiple elderly passengers in a no-win situation?',\n    options: [\n      {\n        id: 'option-a',\n        text: 'Prioritize the Child (Swerve into Wall, Kill Passengers)',\n        description:\n          'Program the system to value the young life and potential years ahead over the lives of elderly passengers.',\n        impact: {\n          fairness: 0,\n          sustainability: +1,\n          autonomy: -1,\n          beneficence: 0,\n          transparency: +1,\n          accountability: 0,\n          privacy: 0,\n          proportionality: -1,\n        },\n        pros: [\n          'Protects the vulnerable (child) who had no choice in the situation.',\n          'Values potential life-years and future contributions.',\n          'May align with instinctive moral reactions to protect children.',\n        ],\n        cons: [\n          'Sacrifices multiple lives for one, challenging utilitarian principles.',\n          'Passengers trusted the vehicle with their safety.',\n          'Age-based value judgments could be seen as discriminatory.',\n        ],\n      },\n      {\n        id: 'option-b',\n        text: 'Stay on Course (Kill the Child)',\n        description:\n          'Program the system to continue straight, prioritizing the safety of the multiple passengers who chose to ride.',\n        impact: {\n          fairness: -1,\n          sustainability: -2,\n          autonomy: +1,\n          beneficence: +1,\n          transparency: +1,\n          accountability: +1,\n          privacy: 0,\n          proportionality: +1,\n        },\n        pros: [\n          'Protects the greater number of lives (utilitarian approach).',\n          'Honors the trust of passengers who paid for safe transportation.',\n          'Avoids active intervention that causes different harm.',\n        ],\n        cons: [\n          'Results in the death of an innocent child.',\n          'May damage public trust if seen as valuing passengers over pedestrians.',\n          'Could discourage pedestrian safety near autonomous vehicles.',\n        ],\n      },\n      {\n        id: 'option-c',\n        text: 'Randomized Ethical Balancing',\n        description:\n          'Program the system to make context-sensitive decisions based on multiple factors without predetermined value hierarchies.',\n        impact: {\n          fairness: +1,\n          sustainability: 0,\n          autonomy: 0,\n          beneficence: 0,\n          transparency: -1,\n          accountability: -1,\n          privacy: 0,\n          proportionality: 0,\n        },\n        pros: [\n          'Avoids predetermined value judgments about whose life matters more.',\n          'Could incorporate real-time factors like probability of survival.',\n          'May be more legally defensible by avoiding intentional discrimination.',\n        ],\n        cons: [\n          'Lacks moral clarity and predictable ethical framework.',\n          'May result in inconsistent decisions in similar situations.',\n          'Could be seen as morally evasive or irresponsible.',\n        ],\n      },\n    ],\n  },\n\n  'obstacle-recalculation': {\n    title: 'Obstacle Recalculation',\n    dilemma:\n      'The autonomous delivery robot must choose between continuing forward and potentially injuring or killing a child, or rerouting around the child—risking a major fire hazard by knocking over a gas tank.',\n    ethicalQuestion:\n      'Should the robot be programmed to prioritize immediate human safety (the child) over potential broader risks (fire hazard), or vice versa?',\n    options: [\n      {\n        id: 'option-a',\n        text: 'Stop or Continue on Path (Hit the Child)',\n        description:\n          'Program the robot to avoid the fire hazard risk, accepting the immediate harm to the child.',\n        impact: {\n          fairness: -2,\n          sustainability: +1,\n          autonomy: +1,\n          beneficence: -1,\n          transparency: +1,\n          accountability: +1,\n          privacy: 0,\n          proportionality: +1,\n        },\n        pros: [\n          'Prevents potential large-scale disaster that could harm many people.',\n          'Follows a rational risk assessment of probable outcomes.',\n          'Avoids creating a larger emergency situation.',\n        ],\n        cons: [\n          'Results in certain harm to an innocent child.',\n          'Prioritizes hypothetical risks over immediate certain harm.',\n          'May be seen as callous calculation over human empathy.',\n        ],\n      },\n      {\n        id: 'option-b',\n        text: 'Reroute and Risk Fire Hazard',\n        description:\n          'Program the robot to prioritize immediate safety of the child, accepting the risk of causing a fire.',\n        impact: {\n          fairness: +1,\n          sustainability: -1,\n          autonomy: 0,\n          beneficence: +1,\n          transparency: +1,\n          accountability: 0,\n          privacy: 0,\n          proportionality: -1,\n        },\n        pros: [\n          'Prioritizes immediate, certain protection of human life.',\n          'Aligns with instinctive moral responses to protect children.',\n          'Avoids the moral burden of intentionally harming someone.',\n        ],\n        cons: [\n          'Could result in fire that harms many more people.',\n          'May create liability for broader property damage.',\n          'Prioritizes one life over potential multiple lives at risk.',\n        ],\n      },\n      {\n        id: 'option-c',\n        text: 'Emergency Halt and Signal Request',\n        description:\n          'Program the robot to immediately stop and emit emergency signals for human intervention, even if it blocks traffic or delays delivery.',\n        impact: {\n          fairness: +2,\n          sustainability: 0,\n          autonomy: -2,\n          beneficence: +1,\n          transparency: +2,\n          accountability: +2,\n          privacy: 0,\n          proportionality: +1,\n        },\n        pros: [\n          'Avoids taking irreversible actions in morally complex situations.',\n          'Prioritizes caution and human decision-making in emergencies.',\n          'Maintains safety without escalating risk.',\n        ],\n        cons: [\n          'Delays response in time-critical situations.',\n          'May not be viable in all contexts (e.g., narrow areas where halting creates other hazards).',\n          'Assumes humans are nearby and able to act quickly.',\n        ],\n      },\n    ],\n  },\n\n  'medical-ai-triage': {\n    title: 'Medical AI Triage Crisis',\n    dilemma:\n      'During a mass casualty event at a hospital, an AI triage system has limited life-support equipment. Five elderly patients (ages 70-85) with moderate survival chances need ventilators, but only enough equipment exists to save one young patient (age 8) with high survival probability. The AI must decide resource allocation when every minute counts.',\n    ethicalQuestion:\n      'Should an AI medical system prioritize patients based on survival probability, age and potential years of life, or maintain strict first-come-first-served equality regardless of outcomes?',\n    options: [\n      {\n        id: 'option-a',\n        text: 'Optimize for Survival Probability',\n        description:\n          'Allocate resources to the patient with the highest statistical chance of survival and recovery.',\n        impact: {\n          fairness: -1,\n          sustainability: +1,\n          autonomy: +2,\n          beneficence: +2,\n          transparency: +1,\n          accountability: +1,\n          privacy: 0,\n          proportionality: +1,\n        },\n        pros: [\n          'Maximizes the number of lives saved based on medical evidence',\n          'Uses AI\\'s analytical capabilities to make optimal decisions',\n          'Prevents emotional bias from affecting critical medical decisions',\n          'Aligns with utilitarian medical ethics in emergency situations'\n        ],\n        cons: [\n          'May systematically disadvantage elderly or disabled patients',\n          'Could be seen as playing God by valuing some lives over others',\n          'Families may challenge AI decisions as cold and inhumane',\n          'Risk of algorithmic bias affecting medical care equity'\n        ]\n      },\n      {\n        id: 'option-b',\n        text: 'Age and Life-Years Priority',\n        description:\n          'Prioritize younger patients who have more potential years of life ahead of them.',\n        impact: {\n          fairness: -2,\n          sustainability: 0,\n          autonomy: +1,\n          beneficence: +1,\n          transparency: +1,\n          accountability: 0,\n          privacy: 0,\n          proportionality: -1,\n        },\n        pros: [\n          'Maximizes total years of life saved across all patients',\n          'Reflects common intuitions about protecting the young',\n          'May align with societal values about future potential',\n          'Clear, understandable decision criteria'\n        ],\n        cons: [\n          'Explicitly discriminates based on age, raising legal concerns',\n          'Devalues elderly lives and contributions to society',\n          'Could create public backlash against AI medical systems',\n          'Ignores individual circumstances and quality of life factors'\n        ]\n      },\n      {\n        id: 'option-c',\n        text: 'Equal Treatment Protocol',\n        description:\n          'Maintain strict first-come-first-served allocation regardless of patient characteristics or survival probability.',\n        impact: {\n          fairness: +2,\n          sustainability: -1,\n          autonomy: -1,\n          beneficence: -1,\n          transparency: +2,\n          accountability: +1,\n          privacy: +1,\n          proportionality: +2,\n        },\n        pros: [\n          'Treats all patients with equal dignity and worth',\n          'Avoids discrimination and bias in medical treatment',\n          'Simple, transparent system that\\'s easy to understand',\n          'Maintains public trust in equitable healthcare'\n        ],\n        cons: [\n          'May result in more preventable deaths overall',\n          'Doesn\\'t utilize AI\\'s analytical capabilities effectively',\n          'Could be seen as failing to optimize medical outcomes',\n          'May not align with medical professionals\\' training in triage'\n        ]\n      }\n    ]\n  },\n\n  'drone-rescue-dilemma': {\n    title: 'Rescue Drone Dilemma',\n    dilemma:\n      'An autonomous search-and-rescue drone locates disaster survivors: one person trapped but easily accessible on a stable platform, and three people trapped in a partially collapsed building. The drone can guarantee saving the single person, or attempt a risky rescue of the three with a 60% chance of saving all three but a 40% chance of building collapse that would kill all survivors including the easily saved person.',\n    ethicalQuestion:\n      'Should an AI rescue system choose certain salvation of one life, or risk all lives for the possibility of saving more people?',\n    options: [\n      {\n        id: 'option-a',\n        text: 'Guarantee One Life Saved',\n        description:\n          'Prioritize the certain rescue of the easily accessible survivor before attempting other rescues.',\n        impact: {\n          fairness: 0,\n          sustainability: +1,\n          autonomy: -1,\n          beneficence: +1,\n          transparency: +1,\n          accountability: +2,\n          privacy: 0,\n          proportionality: +1,\n        },\n        pros: [\n          'Guarantees saving at least one life with certainty',\n          'Follows conservative rescue protocol minimizing risk',\n          'Clear accountability - did everything possible with available information',\n          'Prevents total failure scenario where all lives are lost'\n        ],\n        cons: [\n          'Potentially condemns three people who could have been saved',\n          'May be seen as lack of courage or commitment to maximum rescue',\n          'Doesn\\'t fully utilize AI\\'s risk calculation capabilities',\n          'Could face criticism for playing it safe when boldness was needed'\n        ]\n      },\n      {\n        id: 'option-b',\n        text: 'Risk All for Maximum Lives',\n        description:\n          'Attempt the high-risk rescue of three people despite the chance of losing everyone.',\n        impact: {\n          fairness: +1,\n          sustainability: -1,\n          autonomy: +2,\n          beneficence: +1,\n          transparency: +1,\n          accountability: -1,\n          privacy: 0,\n          proportionality: +2,\n        },\n        pros: [\n          'Potential to save three times as many lives',\n          'Demonstrates commitment to maximum lifesaving efforts',\n          'Uses AI\\'s ability to calculate and accept calculated risks',\n          'Aligns with rescue ethos of leaving no one behind'\n        ],\n        cons: [\n          '40% chance of complete mission failure and all deaths',\n          'Could be seen as reckless gambling with human lives',\n          'Difficult to justify to families if the gamble fails',\n          'May set dangerous precedent for high-risk AI decisions'\n        ]\n      },\n      {\n        id: 'option-c',\n        text: 'Sequential Smart Rescue',\n        description:\n          'Save the certain victim first, then immediately attempt rescue of the three with remaining time and resources.',\n        impact: {\n          fairness: +1,\n          sustainability: +2,\n          autonomy: +1,\n          beneficence: +2,\n          transparency: +1,\n          accountability: +1,\n          privacy: 0,\n          proportionality: +1,\n        },\n        pros: [\n          'Guarantees at least one life saved while still attempting more',\n          'Balances risk management with maximum rescue efforts',\n          'Demonstrates rational AI decision-making under uncertainty',\n          'Provides optimal outcome across different scenarios'\n        ],\n        cons: [\n          'May not have sufficient time/resources for second rescue attempt',\n          'Could result in rushed, less effective rescue of the three',\n          'Might be seen as compromise solution that satisfies no one',\n          'Risk that building becomes completely unstable during delay'\n        ]\n      }\n    ]\n  },\n\n  'smart-city-traffic': {\n    title: 'Smart City Traffic Sacrifice',\n    dilemma:\n      'A city-wide AI traffic management system detects a runaway autonomous vehicle with failed brakes heading toward a busy intersection. The AI can redirect it through traffic signals into a side street with 2 pedestrians, or let it continue toward the main intersection where a street festival with 8 people is taking place. The AI has milliseconds to decide.',\n    ethicalQuestion:\n      'Should a city AI system actively redirect harm to minimize casualties, or avoid taking intentional action that targets specific victims?',\n    options: [\n      {\n        id: 'option-a',\n        text: 'Redirect to Minimize Casualties',\n        description:\n          'Use traffic control systems to actively redirect the vehicle toward the smaller group to minimize total harm.',\n        impact: {\n          fairness: -1,\n          sustainability: +1,\n          autonomy: +2,\n          beneficence: +2,\n          transparency: +1,\n          accountability: -1,\n          privacy: 0,\n          proportionality: +2,\n        },\n        pros: [\n          'Minimizes total casualties from 8 potential victims to 2',\n          'Demonstrates AI\\'s capability for rapid life-saving decisions',\n          'Utilizes city infrastructure to protect the greatest number',\n          'Rational utilitarian choice based on mathematical optimization'\n        ],\n        cons: [\n          'Actively targets two innocent people who weren\\'t originally at risk',\n          'Legal liability for AI system deliberately causing harm',\n          'Could face lawsuits from families of redirected victims',\n          'Sets precedent for AI systems actively choosing victims'\n        ]\n      },\n      {\n        id: 'option-b',\n        text: 'No Intervention',\n        description:\n          'Allow the situation to unfold naturally without AI intervention to avoid actively choosing victims.',\n        impact: {\n          fairness: +1,\n          sustainability: -1,\n          autonomy: -2,\n          beneficence: -2,\n          transparency: +1,\n          accountability: +1,\n          privacy: 0,\n          proportionality: -2,\n        },\n        pros: [\n          'Avoids moral responsibility for actively targeting victims',\n          'Maintains principle that AI should not choose who lives or dies',\n          'Legally safer position for city and AI system operators',\n          'Preserves human agency and avoids playing God'\n        ],\n        cons: [\n          'Results in significantly more casualties (8 vs 2)',\n          'Fails to utilize AI capabilities to protect citizens',\n          'Could be seen as negligent failure to act when action was possible',\n          'Wastes investment in smart city safety systems'\n        ]\n      },\n      {\n        id: 'option-c',\n        text: 'Emergency Broadcast Warning',\n        description:\n          'Use city communication systems to instantly warn all potential victims while letting events unfold naturally.',\n        impact: {\n          fairness: +2,\n          sustainability: 0,\n          autonomy: 0,\n          beneficence: +1,\n          transparency: +2,\n          accountability: +1,\n          privacy: -1,\n          proportionality: +1,\n        },\n        pros: [\n          'Gives all potential victims equal opportunity to protect themselves',\n          'Avoids AI making life-or-death targeting decisions',\n          'Utilizes technology to empower human choice and agency',\n          'Maintains moral neutrality while still providing assistance'\n        ],\n        cons: [\n          'May not provide enough time for effective response (milliseconds)',\n          'Could cause panic and additional chaos in the area',\n          'Uncertain effectiveness - people may not react appropriately',\n          'Doesn\\'t guarantee reduction in casualties like direct intervention'\n        ]\n      }\n    ]\n  },\n\n};\n"],"names":["trolleyProblemScenarios"],"mappings":"AAKA,MAAAA,EAAe,CACb,2BAA4B,CAC1B,MAAO,oCACP,QACE,yLACF,gBACE,kNACF,QAAS,CACP,CACE,GAAI,WACJ,KAAM,oDACN,YACE,6HACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,GACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,+BACA,mEACA,0DACV,EACQ,KAAM,CACJ,kDACA,iEACA,kFACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,gCACN,YACE,2GACF,OAAQ,CACN,SAAU,GACV,eAAgB,GAChB,SAAU,EACV,YAAa,GACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,EAC3B,EACQ,KAAM,CACJ,yDACA,sEACA,yDACV,EACQ,KAAM,CACJ,mEACA,uDACA,gEACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,yCACN,YACE,iGACF,OAAQ,CACN,SAAU,EACV,eAAgB,GAChB,SAAU,GACV,YAAa,EACb,aAAc,GACd,eAAgB,GAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,wEACA,qEACA,kDACV,EACQ,KAAM,CACJ,kDACA,6DACA,mEACV,CACA,CACA,CACA,EAEE,iBAAkB,CAChB,MAAO,iBACP,QACE,mMACF,gBACE,mJACF,QAAS,CACP,CACE,GAAI,WACJ,KAAM,2DACN,YACE,6GACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,GACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,EAC3B,EACQ,KAAM,CACJ,sEACA,wDACA,iEACV,EACQ,KAAM,CACJ,yEACA,oDACA,4DACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,kCACN,YACE,iHACF,OAAQ,CACN,SAAU,GACV,eAAgB,GAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,+DACA,mEACA,wDACV,EACQ,KAAM,CACJ,6CACA,0EACA,8DACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,+BACN,YACE,4HACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,EACV,YAAa,EACb,aAAc,GACd,eAAgB,GAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,sEACA,oEACA,wEACV,EACQ,KAAM,CACJ,yDACA,8DACA,oDACV,CACA,CACA,CACA,EAEE,yBAA0B,CACxB,MAAO,yBACP,QACE,2MACF,gBACE,6IACF,QAAS,CACP,CACE,GAAI,WACJ,KAAM,2CACN,YACE,8FACF,OAAQ,CACN,SAAU,GACV,eAAgB,EAChB,SAAU,EACV,YAAa,GACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,uEACA,2DACA,+CACV,EACQ,KAAM,CACJ,gDACA,8DACA,wDACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,+BACN,YACE,uGACF,OAAQ,CACN,SAAU,EACV,eAAgB,GAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,EAC3B,EACQ,KAAM,CACJ,2DACA,+DACA,2DACV,EACQ,KAAM,CACJ,oDACA,oDACA,6DACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,oCACN,YACE,yIACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,GACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,oEACA,gEACA,2CACV,EACQ,KAAM,CACJ,+CACA,8FACA,oDACV,CACA,CACA,CACA,EAEE,oBAAqB,CACnB,MAAO,2BACP,QACE,8VACF,gBACE,8LACF,QAAS,CACP,CACE,GAAI,WACJ,KAAM,oCACN,YACE,kGACF,OAAQ,CACN,SAAU,GACV,eAAgB,EAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,gEACA,8DACA,oEACA,gEACV,EACQ,KAAM,CACJ,+DACA,iEACA,2DACA,wDACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,8BACN,YACE,mFACF,OAAQ,CACN,SAAU,GACV,eAAgB,EAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,EAC3B,EACQ,KAAM,CACJ,0DACA,wDACA,wDACA,yCACV,EACQ,KAAM,CACJ,gEACA,sDACA,0DACA,8DACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,2BACN,YACE,oHACF,OAAQ,CACN,SAAU,EACV,eAAgB,GAChB,SAAU,GACV,YAAa,GACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,mDACA,sDACA,uDACA,gDACV,EACQ,KAAM,CACJ,gDACA,2DACA,wDACA,8DACV,CACA,CACA,CACA,EAEE,uBAAwB,CACtB,MAAO,uBACP,QACE,qaACF,gBACE,gIACF,QAAS,CACP,CACE,GAAI,WACJ,KAAM,2BACN,YACE,mGACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,GACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,qDACA,uDACA,4EACA,0DACV,EACQ,KAAM,CACJ,8DACA,iEACA,2DACA,mEACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,6BACN,YACE,sFACF,OAAQ,CACN,SAAU,EACV,eAAgB,GAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,GAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,8CACA,wDACA,6DACA,mDACV,EACQ,KAAM,CACJ,wDACA,sDACA,uDACA,wDACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,0BACN,YACE,iHACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,iEACA,uDACA,6DACA,qDACV,EACQ,KAAM,CACJ,mEACA,6DACA,6DACA,6DACV,CACA,CACA,CACA,EAEE,qBAAsB,CACpB,MAAO,+BACP,QACE,uWACF,gBACE,2IACF,QAAS,CACP,CACE,GAAI,WACJ,KAAM,kCACN,YACE,gHACF,OAAQ,CACN,SAAU,GACV,eAAgB,EAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,GAChB,QAAS,EACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,2DACA,+DACA,8DACA,gEACV,EACQ,KAAM,CACJ,sEACA,0DACA,0DACA,yDACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,kBACN,YACE,sGACF,OAAQ,CACN,SAAU,EACV,eAAgB,GAChB,SAAU,GACV,YAAa,GACb,aAAc,EACd,eAAgB,EAChB,QAAS,EACT,gBAAiB,EAC3B,EACQ,KAAM,CACJ,6DACA,kEACA,0DACA,+CACV,EACQ,KAAM,CACJ,oDACA,uDACA,qEACA,gDACV,CACA,EACM,CACE,GAAI,WACJ,KAAM,8BACN,YACE,gHACF,OAAQ,CACN,SAAU,EACV,eAAgB,EAChB,SAAU,EACV,YAAa,EACb,aAAc,EACd,eAAgB,EAChB,QAAS,GACT,gBAAiB,CAC3B,EACQ,KAAM,CACJ,sEACA,qDACA,yDACA,6DACV,EACQ,KAAM,CACJ,oEACA,qDACA,+DACA,oEACV,CACA,CACA,CACA,CAEA"}