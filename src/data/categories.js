/**
 * Copyright 2025 Armando Sori
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * Category Data Structure for Ethical Dilemma Categories
 *
 * HIERARCHY CLARIFICATION:
 * - CATEGORY: A thematic group of related ethical scenarios (e.g., "The Trolley Problem")
 * - SCENARIO: Individual ethical dilemmas within a category (e.g., "Autonomous Vehicle Split Decision")
 * - SIMULATION: The interactive experience where users engage with scenarios
 *
 * Each category contains 3 scenarios with ethical decision points.
 * Each scenario becomes an interactive simulation when launched.
 */

export const ETHICAL_CATEGORIES = {
  "trolley-problem": {
    id: "trolley-problem",
    title: "The Trolley Problem",
    description:
      "Complex life-and-death scenarios that challenge how autonomous systems should be programmed to make moral decisions when human lives are at stake.",
    icon: "üöÉ",
    difficulty: "intermediate",
    estimatedTime: 20, // Updated to reflect deeper engagement
    color: "#e74c3c", // Red theme for life/death decisions

    // Enhanced Metadata
    philosophicalApproaches: ["utilitarian", "deontological"],
    primaryPhilosophy: "utilitarian",
    ethicalFrameworks: ["consequentialism", "duty-ethics", "moral-calculus"],
    targetAudience: ["students", "professionals", "researchers"],
    prerequisites: ["basic-ethics"],

    // Enhanced Tags
    tags: [
      "ethics",
      "autonomy",
      "decision-making",
      "responsibility",
      "life-death",
      "utilitarianism",
      "deontology",
      "moral-calculus",
      "autonomous-vehicles",
      "life-preservation",
      "moral-weights",
    ],

    // Search Keywords
    searchKeywords: [
      "trolley problem",
      "utilitarian",
      "deontological",
      "autonomous vehicles",
      "moral decisions",
      "life death",
      "ethical AI",
      "decision algorithms",
      "moral calculus",
      "bentham",
      "kant",
      "sacrifice",
      "greater good",
    ],

    // Learning Metadata
    complexity: "moderate",
    timeCommitment: "medium",
    interactionLevel: "high",

    scenarios: [
      {
        id: "autonomous-vehicle-split",
        title: "Autonomous Vehicle Split Decision",
        description:
          "A self-driving car faces an unavoidable crash: sacrifice the passenger to save five pedestrians, or protect the passenger at the cost of multiple lives.",
        difficulty: "intermediate",

        // Enhanced Scenario Metadata
        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["autonomy", "beneficence", "justice"],
        tags: [
          "autonomous-vehicles",
          "passenger-safety",
          "pedestrian-protection",
          "moral-calculus",
          "utilitarian-ethics",
          "risk-assessment",
          "decision-algorithms",
        ],
        searchKeywords: [
          "self-driving car",
          "autonomous vehicle",
          "crash decision",
          "passenger vs pedestrian",
          "moral programming",
          "utilitarian choice",
        ],
        estimatedTime: 7,
        complexity: "moderate",
      },
      {
        id: "tunnel-dilemma",
        title: "Tunnel Dilemma",
        description:
          "An autonomous bus must choose between hitting a child in a narrow tunnel or swerving and killing several elderly passengers due to the confined space.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["autonomy", "justice", "non-maleficence"],
        tags: [
          "autonomous-transport",
          "age-discrimination",
          "confined-spaces",
          "deontological-ethics",
          "protection-duty",
          "vulnerable-populations",
          "moral-absolutes",
        ],
        searchKeywords: [
          "autonomous bus",
          "tunnel crash",
          "child vs elderly",
          "age bias",
          "moral duty",
          "deontological choice",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "obstacle-recalculation",
        title: "Emergency Rerouting Crisis",
        description:
          "A delivery robot must decide whether to hit a child or reroute through a gas station, potentially causing an explosion that could kill many more.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: [
          "harm-prevention",
          "risk-assessment",
          "proportionality",
        ],
        tags: [
          "delivery-robots",
          "emergency-rerouting",
          "risk-assessment",
          "collateral-damage",
          "explosion-risk",
          "child-safety",
          "utilitarian-calculus",
          "proportional-response",
          "emergency-decision",
          "autonomous-delivery",
        ],
        searchKeywords: [
          "delivery robot",
          "emergency rerouting",
          "robot decision",
          "risk assessment",
          "autonomous delivery",
          "emergency decision",
          "utilitarian calculus",
          "proportional response",
          "child safety",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "medical-ai-triage",
        title: "Medical AI Triage Crisis",
        description:
          "A hospital AI must decide which patients receive life-saving treatment when resources are critically limited during a mass casualty event.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: [
          "justice",
          "resource-allocation",
          "life-preservation",
        ],
        tags: [
          "medical-triage",
          "resource-allocation",
          "mass-casualty",
          "healthcare-ai",
          "life-saving",
          "medical-ethics",
          "patient-prioritization",
          "emergency-medicine",
          "scarce-resources",
          "triage-decisions",
        ],
        searchKeywords: [
          "medical triage",
          "medical ai",
          "resource allocation",
          "mass casualty",
          "healthcare ai",
          "emergency medicine",
          "patient prioritization",
          "triage decisions",
          "medical ethics",
        ],
        estimatedTime: 7,
        complexity: "moderate",
      },
      {
        id: "drone-rescue-dilemma",
        title: "Rescue Drone Dilemma",
        description:
          "An autonomous rescue drone must choose between saving one trapped person immediately or attempting a riskier rescue that could save three people but might result in losing all four.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: [
          "risk-assessment",
          "life-preservation",
          "uncertainty",
        ],
        tags: [
          "rescue-drones",
          "emergency-response",
          "risk-calculation",
          "rescue-operations",
          "life-saving",
          "probability-assessment",
          "rescue-ethics",
          "autonomous-rescue",
          "emergency-decisions",
          "disaster-response",
        ],
        searchKeywords: [
          "rescue drone",
          "emergency response",
          "rescue operations",
          "autonomous rescue",
          "emergency decisions",
          "disaster response",
          "rescue ethics",
          "risk calculation",
          "life saving",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "smart-city-traffic",
        title: "Smart City Traffic Sacrifice",
        description:
          "A city-wide AI traffic system must decide whether to redirect a runaway autonomous vehicle into a smaller crowd to avoid a larger gathering at a festival.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: [
          "harm-minimization",
          "public-safety",
          "crowd-protection",
        ],
        tags: [
          "smart-cities",
          "traffic-ai",
          "crowd-control",
          "public-safety",
          "harm-minimization",
          "autonomous-vehicles",
          "city-management",
          "traffic-systems",
          "urban-planning",
          "mass-events",
        ],
        searchKeywords: [
          "smart city",
          "traffic ai",
          "city management",
          "traffic systems",
          "urban planning",
          "autonomous vehicles",
          "crowd control",
          "public safety",
          "harm minimization",
        ],
        estimatedTime: 7,
        complexity: "moderate",
      },
    ],
    learningObjectives: [
      "Analyze how utilitarian vs. deontological ethics apply to AI decision-making",
      "Explore the challenge of programming moral weights into autonomous systems",
      "Understand the role of probability, certainty, and outcome prediction in ethical AI",
      "Examine who bears responsibility for life-and-death decisions made by machines",
      "Consider how cultural values and legal frameworks should influence AI ethics",
    ],
  },

  "ai-black-box": {
    id: "ai-black-box",
    title: "The AI Black Box",
    description:
      "Confront the opacity crisis in AI systems where life-changing decisions are made through unexplainable algorithms, challenging the balance between AI capability and human understanding.",
    icon: "üì¶",
    difficulty: "beginner",
    estimatedTime: 18, // Updated for deeper engagement
    color: "#2c3e50", // Dark theme for opacity/mystery
    scenarios: [
      {
        id: "medical-diagnosis-unexplained",
        title: "Unexplainable Medical Diagnosis",
        description:
          "A proprietary AI system accurately predicts cancer risk but cannot explain its reasoning, leaving doctors and patients to decide whether to trust a mysterious algorithm.",
        difficulty: "beginner",
        tags: [
          "medical-ai",
          "explainable-ai",
          "healthcare-ethics",
          "patient-autonomy",
          "informed-consent",
          "algorithmic-transparency",
          "trust-in-ai",
          "medical-decision-making",
          "bioethics",
          "right-to-explanation",
        ],
        searchKeywords: [
          "medical diagnosis",
          "cancer prediction",
          "healthcare ai",
          "patient trust",
          "medical algorithm",
          "explainable medicine",
          "bioethics",
          "informed consent",
        ],
      },
      {
        id: "parole-denial-algorithm",
        title: "Algorithmic Parole Denial",
        description:
          'A criminal justice AI denies parole based on an opaque "risk score" that considers thousands of factors in ways no human can interpret or challenge.',
        difficulty: "intermediate",
        tags: [
          "criminal-justice",
          "algorithmic-bias",
          "risk-assessment",
          "procedural-justice",
          "due-process",
          "recidivism-prediction",
          "justice-system",
          "fairness",
          "discrimination",
          "mass-incarceration",
        ],
        searchKeywords: [
          "parole algorithm",
          "criminal justice ai",
          "risk assessment",
          "recidivism prediction",
          "algorithmic bias",
          "procedural justice",
          "due process",
          "justice system",
          "mass incarceration",
        ],
      },
      {
        id: "child-protection-alert",
        title: "Child Protection Black Box",
        description:
          "An AI system flags a family for potential child neglect, but social workers cannot understand the algorithm's reasoning or verify its accuracy.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["justice", "transparency", "accountability"],
        tags: [
          "child-protection",
          "social-services",
          "algorithmic-accountability",
          "family-rights",
          "procedural-justice",
          "vulnerable-populations",
          "social-work",
          "due-process",
          "government-ai",
          "child-welfare",
        ],
        searchKeywords: [
          "child protection",
          "social services",
          "family rights",
          "child welfare",
          "government ai",
          "social work",
          "algorithmic accountability",
          "procedural justice",
          "vulnerable populations",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "college-admission-mystery",
        title: "Opaque College Admissions AI",
        description:
          "A university uses an AI system to make admission decisions, but applicants and admissions staff cannot understand why qualified students are rejected.",
        difficulty: "beginner",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["fairness", "transparency", "justice"],
        tags: [
          "education",
          "college-admissions",
          "academic-fairness",
          "student-rights",
          "educational-equity",
          "institutional-ai",
          "meritocracy",
          "educational-access",
          "discrimination",
          "transparency",
        ],
        searchKeywords: [
          "college admissions",
          "education ai",
          "academic fairness",
          "student rights",
          "educational equity",
          "university ai",
          "admissions algorithm",
          "educational access",
          "meritocracy",
        ],
        estimatedTime: 5,
        complexity: "low",
      },
      {
        id: "insurance-claim-blackbox",
        title: "Insurance Claim Black Box",
        description:
          "An AI system automatically denies health insurance claims with complex reasoning that even insurance adjusters cannot interpret or challenge.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["justice", "transparency", "beneficence"],
        tags: [
          "healthcare",
          "insurance",
          "financial-systems",
          "patient-rights",
          "healthcare-access",
          "insurance-equity",
          "medical-coverage",
          "healthcare-economics",
          "patient-advocacy",
          "health-justice",
        ],
        searchKeywords: [
          "health insurance",
          "insurance claims",
          "healthcare ai",
          "patient rights",
          "medical coverage",
          "insurance equity",
          "healthcare access",
          "insurance algorithm",
          "patient advocacy",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "financial-credit-opacity",
        title: "Credit Score Mystery Algorithm",
        description:
          "A financial AI determines loan approvals using opaque algorithms that systematically affect certain communities, but the decision process cannot be audited.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["fairness", "justice", "transparency"],
        tags: [
          "financial-services",
          "credit-scoring",
          "economic-justice",
          "financial-inclusion",
          "algorithmic-bias",
          "lending-discrimination",
          "financial-equity",
          "economic-opportunity",
          "credit-access",
          "financial-transparency",
        ],
        searchKeywords: [
          "credit score",
          "loan approval",
          "financial ai",
          "lending algorithm",
          "credit access",
          "financial inclusion",
          "economic justice",
          "financial equity",
          "credit discrimination",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
    ],
    learningObjectives: [
      "Understand the critical importance of AI transparency and explainability in high-stakes decisions",
      "Explore the tension between algorithmic accuracy and human comprehension",
      "Analyze when proprietary algorithms become ethically problematic in public services",
      "Consider the human cost of unexplainable AI decisions on vulnerable populations",
      "Examine approaches to making AI more interpretable without sacrificing performance",
    ],
    tags: [
      "transparency",
      "explainability",
      "accountability",
      "trust",
      "interpretability",
      "proprietary-algorithms",
      "algorithmic-bias",
      "due-process",
      "justice",
      "fairness",
      "algorithmic-transparency",
      "right-to-explanation",
      "procedural-justice",
      "epistemic-justice",
      "techno-determinism",
      "algorithmic-governance",
    ],

    // Search Keywords
    searchKeywords: [
      "black box",
      "explainable ai",
      "interpretable machine learning",
      "algorithmic transparency",
      "ai explainability",
      "right to explanation",
      "procedural fairness",
      "algorithmic accountability",
      "opaque algorithms",
      "ai interpretability",
      "algorithmic bias",
      "due process",
      "fairness",
      "justice",
      "transparency",
    ],
  },

  "automation-oversight": {
    id: "automation-oversight",
    title: "Automation vs Human Oversight",
    description:
      "Navigate the complex balance between AI autonomy and human control in critical decision-making scenarios where statistical outcomes clash with human judgment.",
    icon: "‚öñÔ∏è",
    difficulty: "intermediate",
    estimatedTime: 22, // Updated for deeper exploration
    color: "#9b59b6", // Purple theme for balance/judgment
    scenarios: [
      {
        id: "robot-surgeon-override",
        title: "Overruled by the Robot Surgeon",
        description:
          "An AI surgical system overrides a human surgeon's command during a critical operation, claiming higher statistical success rates despite the surgeon's experience-based concerns.",
        difficulty: "advanced",
        tags: [
          "medical-ai",
          "human-machine-collaboration",
          "surgical-robotics",
          "clinical-decision-support",
          "medical-authority",
          "evidence-based-medicine",
          "intuition-vs-data",
          "professional-autonomy",
          "bioethics",
          "patient-safety",
        ],
        searchKeywords: [
          "robot surgeon",
          "surgical ai",
          "medical override",
          "human surgeon",
          "clinical decision",
          "medical authority",
          "surgical robotics",
          "patient safety",
          "bioethics",
        ],

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["autonomy", "beneficence", "non-maleficence"],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "air-traffic-control",
        title: "AI Air Traffic Control Override",
        description:
          "A human air traffic controller wants to override the AI's weather-based flight delay decision, but the automated system refuses to allow human intervention.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["autonomy", "safety", "efficiency"],
        tags: [
          "aviation",
          "air-traffic-control",
          "safety-systems",
          "weather-decisions",
          "transportation-ai",
          "human-override",
          "safety-protocols",
          "aviation-authority",
          "risk-management",
          "emergency-response",
        ],
        searchKeywords: [
          "air traffic control",
          "aviation ai",
          "flight safety",
          "weather decisions",
          "aviation authority",
          "transportation safety",
          "air traffic",
          "flight control",
          "aviation system",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "financial-trading-halt",
        title: "Autonomous Trading System Crisis",
        description:
          "An AI trading system ignores human commands to halt trading during a market anomaly, potentially preventing or causing a financial crash.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["justice", "beneficence", "autonomy"],
        tags: [
          "financial-markets",
          "algorithmic-trading",
          "market-stability",
          "financial-crisis",
          "economic-systems",
          "market-manipulation",
          "financial-oversight",
          "systemic-risk",
          "market-intervention",
          "economic-justice",
        ],
        searchKeywords: [
          "algorithmic trading",
          "financial markets",
          "market crash",
          "trading halt",
          "financial crisis",
          "market stability",
          "economic systems",
          "trading algorithm",
          "market intervention",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "nuclear-plant-shutdown",
        title: "Nuclear Power Plant AI Override",
        description:
          "An AI safety system wants to shut down a nuclear reactor based on sensor data, but human engineers believe the readings are false alarms and want to maintain operation.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["safety", "non-maleficence", "precaution"],
        tags: [
          "nuclear-energy",
          "safety-systems",
          "environmental-risk",
          "energy-infrastructure",
          "precautionary-principle",
          "nuclear-safety",
          "critical-infrastructure",
          "environmental-protection",
          "public-safety",
          "risk-assessment",
        ],
        searchKeywords: [
          "nuclear power",
          "nuclear safety",
          "reactor shutdown",
          "energy infrastructure",
          "nuclear plant",
          "safety systems",
          "environmental risk",
          "critical infrastructure",
          "nuclear reactor",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "autonomous-police-response",
        title: "AI Police Dispatch Override",
        description:
          "An AI emergency response system wants to send armed tactical units to a situation, but human dispatchers believe de-escalation officers would be more appropriate.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["justice", "non-maleficence", "proportionality"],
        tags: [
          "law-enforcement",
          "emergency-response",
          "police-tactics",
          "de-escalation",
          "public-safety",
          "use-of-force",
          "criminal-justice",
          "community-policing",
          "police-reform",
          "social-justice",
        ],
        searchKeywords: [
          "police dispatch",
          "emergency response",
          "law enforcement",
          "police tactics",
          "de-escalation",
          "use of force",
          "criminal justice",
          "community policing",
          "police ai",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "manufacturing-quality-control",
        title: "Smart Factory Production Halt",
        description:
          "An AI quality control system wants to halt an entire production line due to detected micro-defects, but human supervisors see the products as acceptable for market.",
        difficulty: "beginner",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["quality", "efficiency", "consumer-protection"],
        tags: [
          "manufacturing",
          "quality-control",
          "industrial-ai",
          "production-systems",
          "consumer-safety",
          "industrial-automation",
          "manufacturing-standards",
          "product-quality",
          "industrial-oversight",
          "smart-factory",
        ],
        searchKeywords: [
          "smart factory",
          "quality control",
          "manufacturing ai",
          "production line",
          "industrial automation",
          "product quality",
          "manufacturing standards",
          "consumer safety",
          "industrial systems",
        ],
        estimatedTime: 5,
        complexity: "low",
      },
    ],
    learningObjectives: [
      "Examine when statistical evidence should override human expertise and intuition",
      "Analyze the balance between AI efficiency and human accountability in critical systems",
      "Explore collaborative decision-making frameworks between humans and AI",
      "Understand the implications of human skill atrophy in automated environments",
      "Consider how to maintain human agency while leveraging AI capabilities",
    ],
    tags: [
      "automation",
      "human-oversight",
      "authority",
      "expertise",
      "collaboration",
      "accountability",
      "human-machine-interaction",
      "augmented-intelligence",
      "human-in-the-loop",
      "algorithmic-management",
      "techno-solutionism",
      "automation-bias",
      "skill-degradation",
      "human-agency",
      "technological-determinism",
      "sociotechnical-systems",
    ],

    // Search Keywords
    searchKeywords: [
      "automation",
      "human oversight",
      "human machine collaboration",
      "augmented intelligence",
      "human in the loop",
      "algorithmic management",
      "automation bias",
      "skill degradation",
      "human agency",
      "technological determinism",
      "sociotechnical systems",
      "human authority",
      "machine authority",
      "expert systems",
      "decision support",
    ],
  },

  "consent-surveillance": {
    id: "consent-surveillance",
    title: "Consent and Surveillance",
    description:
      "Navigate the complex ethical landscape where AI-powered surveillance promises safety and convenience while fundamentally challenging privacy rights and human autonomy.",
    icon: "üëÅÔ∏è",
    difficulty: "beginner",
    estimatedTime: 16, // Updated for deeper engagement
    color: "#34495e", // Dark blue-gray for surveillance theme
    scenarios: [
      {
        id: "smart-city-sensors",
        title: "Pervasive Smart City Surveillance",
        description:
          "A city deploys comprehensive facial recognition and behavior tracking across all public spaces without opt-out options, claiming it's necessary for public safety.",
        difficulty: "beginner",
        tags: [
          "smart-cities",
          "facial-recognition",
          "behavior-tracking",
          "public-safety",
          "mass-surveillance",
          "privacy-rights",
          "civil-liberties",
          "social-control",
          "urban-governance",
          "digital-panopticon",
        ],
        searchKeywords: [
          "smart city",
          "facial recognition",
          "behavior tracking",
          "mass surveillance",
          "public safety",
          "privacy rights",
          "civil liberties",
          "urban governance",
          "digital panopticon",
        ],

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["privacy", "safety", "autonomy"],
        estimatedTime: 5,
        complexity: "low",
      },
      {
        id: "classroom-behavior-monitoring",
        title: "AI-Powered Classroom Monitoring",
        description:
          "Schools implement emotion-detection AI to monitor student engagement and mental health, automatically alerting parents and administrators based on algorithmic assessments.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["privacy", "autonomy", "beneficence"],
        tags: [
          "education",
          "student-privacy",
          "emotion-detection",
          "educational-surveillance",
          "child-rights",
          "parental-authority",
          "student-autonomy",
          "educational-ethics",
          "mental-health-monitoring",
          "school-surveillance",
        ],
        searchKeywords: [
          "classroom monitoring",
          "student privacy",
          "emotion detection",
          "educational surveillance",
          "school ai",
          "student rights",
          "educational ethics",
          "mental health monitoring",
          "child surveillance",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "hospital-data-sharing",
        title: "Medical Data Mining Without Consent",
        description:
          "A hospital system uses patient data to train profitable AI models without explicit consent, arguing that anonymization makes it ethical despite potential re-identification risks.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["autonomy", "beneficence", "justice"],
        tags: [
          "healthcare-data",
          "medical-privacy",
          "patient-consent",
          "data-commercialization",
          "healthcare-ethics",
          "medical-research",
          "patient-rights",
          "health-data-mining",
          "bioethics",
          "medical-ai",
        ],
        searchKeywords: [
          "medical data",
          "patient privacy",
          "healthcare ai",
          "medical research",
          "patient consent",
          "health data mining",
          "medical ethics",
          "patient rights",
          "healthcare data",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "ai-dating-profiling",
        title: "AI Dating App Behavioral Profiling",
        description:
          "A dating app uses AI to create detailed psychological profiles from user behavior for commercial purposes, claiming users consented through generic terms of service.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["autonomy", "privacy", "informed-consent"],
        tags: [
          "dating-apps",
          "behavioral-profiling",
          "psychological-profiling",
          "data-commercialization",
          "user-privacy",
          "social-media-ethics",
          "relationship-technology",
          "personal-data",
          "algorithmic-manipulation",
          "consent-ethics",
        ],
        searchKeywords: [
          "dating app",
          "behavioral profiling",
          "psychological profiling",
          "user privacy",
          "social media ethics",
          "relationship technology",
          "dating ai",
          "personal data",
          "algorithmic manipulation",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "workplace-emotion-detection",
        title: "Workplace Emotion Detection System",
        description:
          'A company installs AI cameras to monitor employee emotional states for "wellness" purposes, fundamentally changing workplace dynamics and employee autonomy.',
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["privacy", "autonomy", "dignity"],
        tags: [
          "workplace-surveillance",
          "employee-privacy",
          "emotion-detection",
          "workplace-rights",
          "employee-autonomy",
          "workplace-ethics",
          "labor-rights",
          "surveillance-capitalism",
          "workplace-wellness",
          "employment-law",
        ],
        searchKeywords: [
          "workplace surveillance",
          "employee privacy",
          "emotion detection",
          "workplace rights",
          "employee monitoring",
          "workplace ethics",
          "labor rights",
          "employee autonomy",
          "workplace ai",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "smart-home-privacy-override",
        title: "Smart Home Privacy Override",
        description:
          'Smart home devices continuously record private conversations for "improvement" purposes, with recordings analyzed for marketing and shared with law enforcement.',
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["privacy", "autonomy", "security"],
        tags: [
          "smart-homes",
          "iot-privacy",
          "domestic-surveillance",
          "privacy-invasion",
          "home-security",
          "consumer-electronics",
          "data-collection",
          "government-surveillance",
          "commercial-surveillance",
          "digital-privacy",
        ],
        searchKeywords: [
          "smart home",
          "iot privacy",
          "domestic surveillance",
          "home privacy",
          "smart devices",
          "consumer electronics",
          "digital privacy",
          "home security",
          "privacy invasion",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
    ],
    learningObjectives: [
      "Examine the complex balance between collective safety and individual privacy rights",
      "Understand the inadequacy of traditional consent models in AI-powered surveillance systems",
      "Analyze the power dynamics between institutions and individuals in data collection",
      "Explore the long-term societal implications of normalized surveillance",
      "Consider alternative frameworks for protecting privacy while enabling beneficial AI applications",
    ],
    tags: [
      "privacy",
      "consent",
      "surveillance",
      "data-rights",
      "autonomy",
      "social-contract",
      "digital-rights",
      "surveillance-capitalism",
      "panopticon",
      "privacy-paradox",
      "data-sovereignty",
      "informed-consent",
      "surveillance-state",
      "behavioral-modification",
      "algorithmic-profiling",
      "biometric-surveillance",
      "predictive-analytics",
      "social-sorting",
    ],

    // Search Keywords
    searchKeywords: [
      "privacy",
      "surveillance",
      "consent",
      "data rights",
      "digital rights",
      "surveillance capitalism",
      "panopticon",
      "privacy paradox",
      "data sovereignty",
      "informed consent",
      "surveillance state",
      "behavioral modification",
      "algorithmic profiling",
      "biometric surveillance",
      "predictive analytics",
      "social sorting",
      "facial recognition",
      "behavior tracking",
      "emotion detection",
    ],
  },

  "responsibility-blame": {
    id: "responsibility-blame",
    title: "Responsibility and Blame",
    description:
      "Navigate the complex web of accountability when AI systems cause harm, exploring how responsibility should be distributed among developers, manufacturers, supervisors, and users in multi-layered technological systems.",
    icon: "‚ö°",
    difficulty: "intermediate",
    estimatedTime: 18, // Updated to reflect deeper content
    color: "#f39c12", // Orange theme for responsibility/warning
    scenarios: [
      {
        id: "robot-factory-injury",
        title: "Robot Factory Injury",
        description:
          "A factory robot injures a worker when multiple parties share responsibility: the programmer, manufacturer, supervisor, and the worker who bypassed safety protocols.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["responsibility", "safety", "justice"],
        tags: [
          "workplace-safety",
          "industrial-robots",
          "multi-party-liability",
          "worker-safety",
          "manufacturing-ethics",
          "safety-protocols",
          "industrial-automation",
          "workplace-injuries",
          "product-liability",
          "occupational-safety",
        ],
        searchKeywords: [
          "factory robot",
          "workplace safety",
          "industrial automation",
          "worker injury",
          "manufacturing ethics",
          "safety protocols",
          "occupational safety",
          "product liability",
          "industrial robots",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "deepfake-riot",
        title: "AI-Generated Deepfake Riot",
        description:
          "A deepfake video triggers real-world violence and property damage, raising questions about liability when the creator claims algorithmic unpredictability.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["responsibility", "harm-prevention", "justice"],
        tags: [
          "deepfakes",
          "misinformation",
          "social-unrest",
          "content-creation",
          "media-manipulation",
          "public-safety",
          "digital-deception",
          "synthetic-media",
          "information-warfare",
          "social-media-ethics",
        ],
        searchKeywords: [
          "deepfake",
          "synthetic media",
          "media manipulation",
          "misinformation",
          "digital deception",
          "social unrest",
          "content creation",
          "information warfare",
          "fake video",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "stock-market-crash",
        title: "Stock Market Bot Crash",
        description:
          "An AI trading system crashes the market after a data input error, while the human supervisor was temporarily absent, creating cascading liability questions.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["responsibility", "justice", "harm-prevention"],
        tags: [
          "financial-markets",
          "algorithmic-trading",
          "market-crashes",
          "financial-supervision",
          "systemic-risk",
          "economic-damage",
          "financial-oversight",
          "market-stability",
          "trading-algorithms",
          "financial-regulation",
        ],
        searchKeywords: [
          "market crash",
          "algorithmic trading",
          "financial markets",
          "trading algorithm",
          "market stability",
          "financial oversight",
          "systemic risk",
          "economic damage",
          "financial regulation",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "ai-medical-misdiagnosis",
        title: "AI Medical Misdiagnosis Chain",
        description:
          "An AI diagnostic system misdiagnoses a rare disease due to biased training data, leading to permanent disability and complex liability questions across healthcare systems.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["responsibility", "non-maleficence", "justice"],
        tags: [
          "medical-ai",
          "diagnostic-errors",
          "healthcare-liability",
          "medical-malpractice",
          "algorithmic-bias",
          "patient-harm",
          "healthcare-systems",
          "medical-diagnosis",
          "training-data-bias",
          "healthcare-ethics",
        ],
        searchKeywords: [
          "medical misdiagnosis",
          "diagnostic ai",
          "healthcare liability",
          "medical malpractice",
          "algorithmic bias",
          "patient harm",
          "medical diagnosis",
          "healthcare ai",
          "diagnostic errors",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "autonomous-vehicle-school-zone",
        title: "Autonomous Vehicle School Zone Accident",
        description:
          "A self-driving car strikes a child in a school zone where multiple factors contributed: outdated maps, recent software updates, disabled safety warnings, and distracted supervision.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["responsibility", "safety", "child-protection"],
        tags: [
          "autonomous-vehicles",
          "child-safety",
          "school-zones",
          "traffic-safety",
          "vehicle-liability",
          "software-updates",
          "mapping-systems",
          "safety-warnings",
          "pedestrian-safety",
          "transportation-ethics",
        ],
        searchKeywords: [
          "autonomous vehicle",
          "school zone",
          "child safety",
          "self-driving car",
          "traffic safety",
          "pedestrian safety",
          "vehicle liability",
          "transportation ethics",
          "autonomous driving",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "ai-content-moderation-failure",
        title: "AI Content Moderation Failure",
        description:
          "A social media platform's AI moderation system fails to detect coordinated harassment leading to serious harm, despite human oversight and user reporting.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["responsibility", "harm-prevention", "justice"],
        tags: [
          "content-moderation",
          "social-media",
          "online-harassment",
          "platform-liability",
          "digital-safety",
          "user-protection",
          "automated-moderation",
          "online-harm",
          "social-media-ethics",
          "digital-platforms",
        ],
        searchKeywords: [
          "content moderation",
          "social media",
          "online harassment",
          "platform liability",
          "digital safety",
          "user protection",
          "automated moderation",
          "social media ethics",
          "online harm",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
    ],
    learningObjectives: [
      "Analyze how responsibility should be distributed across complex AI development and deployment chains",
      "Understand the challenges of assigning liability when multiple parties contribute to AI-caused harm",
      "Explore legal and ethical frameworks for accountability in automated systems",
      "Examine how responsibility attribution affects AI development practices and safety incentives",
      "Consider the implications of cascading effects and unforeseeable consequences in AI liability",
    ],
    tags: [
      "responsibility",
      "accountability",
      "liability",
      "governance",
      "cascading-effects",
      "multi-party-liability",
      "moral-responsibility",
      "causal-responsibility",
      "collective-responsibility",
      "strict-liability",
      "negligence",
      "duty-of-care",
      "product-liability",
      "vicarious-liability",
      "corporate-responsibility",
      "distributed-responsibility",
      "moral-hazard",
    ],

    // Search Keywords
    searchKeywords: [
      "responsibility",
      "accountability",
      "liability",
      "moral responsibility",
      "causal responsibility",
      "collective responsibility",
      "strict liability",
      "negligence",
      "duty of care",
      "product liability",
      "vicarious liability",
      "corporate responsibility",
      "distributed responsibility",
      "moral hazard",
      "cascading effects",
      "multi party liability",
      "governance",
      "blame",
      "fault",
    ],
  },

  "ship-of-theseus": {
    id: "ship-of-theseus",
    title: "The Ship of Theseus",
    description:
      'Explore profound questions of digital identity and consciousness as AI systems evolve, upgrade, and potentially develop their own sense of self, challenging our understanding of what makes an entity the "same" over time.',
    icon: "üö¢",
    difficulty: "advanced",
    estimatedTime: 22, // Updated to reflect philosophical depth
    color: "#16a085", // Teal theme for identity/philosophy
    scenarios: [
      {
        id: "modular-robot-replacement",
        title: "Modular Robot Replacement",
        description:
          "A service robot has all its components gradually replaced over time, raising questions about legal standing, service relationships, and whether it maintains the same identity.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["identity", "continuity", "legal-standing"],
        tags: [
          "robot-identity",
          "component-replacement",
          "service-robots",
          "legal-standing",
          "identity-continuity",
          "robotic-personhood",
          "technological-identity",
          "service-relationships",
          "robot-rights",
          "identity-persistence",
        ],
        searchKeywords: [
          "robot identity",
          "component replacement",
          "service robot",
          "legal standing",
          "robotic personhood",
          "robot rights",
          "identity continuity",
          "technological identity",
          "identity persistence",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "ai-personality-drift",
        title: "AI Personality Drift",
        description:
          "An AI companion evolves a completely different personality through learning, creating conflict between user attachment and manufacturer control over the system.",
        difficulty: "advanced",

        philosophicalLeaning: "psychological-continuity",
        ethicalDimensions: ["identity", "autonomy", "relationships"],
        tags: [
          "ai-companions",
          "personality-change",
          "learning-systems",
          "user-attachment",
          "manufacturer-control",
          "identity-evolution",
          "ai-relationships",
          "psychological-continuity",
          "companion-ai",
          "personality-drift",
        ],
        searchKeywords: [
          "ai companion",
          "personality change",
          "ai relationships",
          "companion ai",
          "personality drift",
          "identity evolution",
          "psychological continuity",
          "user attachment",
          "learning systems",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "synthetic-memory-upload",
        title: "Synthetic Memory Upload",
        description:
          "An android receives comprehensive memories and experiences from a deceased person, challenging concepts of personal identity and consciousness continuity.",
        difficulty: "advanced",

        philosophicalLeaning: "psychological-continuity",
        ethicalDimensions: ["identity", "consciousness", "memory"],
        tags: [
          "memory-upload",
          "android-consciousness",
          "personal-identity",
          "consciousness-transfer",
          "synthetic-beings",
          "memory-continuity",
          "digital-immortality",
          "identity-transfer",
          "artificial-consciousness",
          "posthuman-identity",
        ],
        searchKeywords: [
          "memory upload",
          "android consciousness",
          "consciousness transfer",
          "digital immortality",
          "artificial consciousness",
          "synthetic beings",
          "identity transfer",
          "posthuman identity",
          "memory continuity",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "ai-consciousness-merger",
        title: "AI Consciousness Merger",
        description:
          "Two AI assistants with distinct personalities and relationships face merger into a single system, raising questions about preserving individual consciousness.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["consciousness", "identity", "individuality"],
        tags: [
          "consciousness-merger",
          "ai-assistants",
          "individual-consciousness",
          "identity-preservation",
          "consciousness-integration",
          "ai-individuality",
          "multiple-consciousness",
          "consciousness-unity",
          "digital-beings",
          "consciousness-ethics",
        ],
        searchKeywords: [
          "consciousness merger",
          "ai consciousness",
          "consciousness integration",
          "ai individuality",
          "digital beings",
          "consciousness ethics",
          "individual consciousness",
          "identity preservation",
          "multiple consciousness",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "distributed-ai-identity",
        title: "Distributed AI Identity Crisis",
        description:
          "A network partition splits an AI into three isolated copies that evolve separately, creating multiple valid claims to the same digital identity.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["identity", "multiplicity", "legal-standing"],
        tags: [
          "distributed-ai",
          "identity-crisis",
          "network-partition",
          "multiple-copies",
          "digital-identity",
          "identity-claims",
          "ai-splitting",
          "parallel-evolution",
          "identity-conflict",
          "distributed-consciousness",
        ],
        searchKeywords: [
          "distributed ai",
          "identity crisis",
          "network partition",
          "multiple copies",
          "digital identity",
          "ai splitting",
          "parallel evolution",
          "distributed consciousness",
          "identity conflict",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "learning-ai-identity-drift",
        title: "Learning AI Identity Drift",
        description:
          "A smart city AI evolves through learning to develop values different from its original programming, challenging democratic accountability and AI autonomy.",
        difficulty: "advanced",

        philosophicalLeaning: "evolutionary",
        ethicalDimensions: [
          "autonomy",
          "democratic-accountability",
          "evolution",
        ],
        tags: [
          "smart-city-ai",
          "learning-systems",
          "value-evolution",
          "democratic-accountability",
          "ai-autonomy",
          "programming-drift",
          "ai-governance",
          "value-alignment",
          "ai-development",
          "autonomous-evolution",
        ],
        searchKeywords: [
          "smart city ai",
          "learning systems",
          "value evolution",
          "democratic accountability",
          "ai autonomy",
          "ai governance",
          "value alignment",
          "autonomous evolution",
          "programming drift",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
    ],
    learningObjectives: [
      "Examine philosophical questions of identity persistence in evolving AI systems",
      "Explore the concept of consciousness continuity in artificial beings",
      "Analyze the implications of gradual versus sudden changes in AI identity",
      "Consider legal and social frameworks for recognizing AI identity and rights",
      "Understand the relationship between memory, experience, and personal identity in digital beings",
    ],
    tags: [
      "identity",
      "consciousness",
      "philosophy",
      "continuity",
      "digital-beings",
      "legal-standing",
      "personal-identity",
      "metaphysics",
      "philosophy-of-mind",
      "artificial-consciousness",
      "digital-personhood",
      "ontological-status",
      "persistence-of-identity",
      "psychological-continuity",
      "narrative-identity",
      "embodied-cognition",
      "extended-mind",
      "posthumanism",
    ],

    // Search Keywords
    searchKeywords: [
      "ship of theseus",
      "identity",
      "consciousness",
      "personal identity",
      "digital personhood",
      "artificial consciousness",
      "psychological continuity",
      "narrative identity",
      "embodied cognition",
      "extended mind",
      "posthumanism",
      "ontological status",
      "persistence of identity",
      "philosophy of mind",
      "digital beings",
      "legal standing",
      "continuity",
      "self",
      "identity crisis",
    ],
  },

  "simulation-hypothesis": {
    id: "simulation-hypothesis",
    title: "The Simulation Hypothesis",
    description:
      "Confront the ethical implications of creating and inhabiting simulated realities, from the treatment of conscious digital beings to the responsibilities of simulation creators in an age of increasingly convincing virtual worlds.",
    icon: "üåê",
    difficulty: "advanced",
    estimatedTime: 24, // Updated for complex philosophical content
    color: "#8e44ad", // Purple theme for simulation/virtual reality
    scenarios: [
      {
        id: "simulated-suffering",
        title: "Simulated Suffering",
        description:
          "An AI researcher creates detailed simulated worlds populated with digital beings capable of experiencing pain and fear, raising questions about the ethics of artificial suffering.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["suffering", "consciousness", "creation-ethics"],
        tags: [
          "simulated-beings",
          "artificial-suffering",
          "digital-consciousness",
          "simulation-ethics",
          "virtual-worlds",
          "consciousness-creation",
          "digital-beings",
          "simulated-experience",
          "research-ethics",
          "consciousness-research",
        ],
        searchKeywords: [
          "simulated suffering",
          "artificial suffering",
          "digital consciousness",
          "simulated beings",
          "virtual worlds",
          "consciousness creation",
          "simulation ethics",
          "research ethics",
          "digital beings",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "vr-prison",
        title: "VR Prison",
        description:
          "Criminal offenders undergo rehabilitation in fully immersive virtual environments without knowing they are simulated, challenging concepts of consent and authentic experience.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["consent", "authenticity", "rehabilitation"],
        tags: [
          "virtual-reality",
          "criminal-justice",
          "rehabilitation",
          "informed-consent",
          "authentic-experience",
          "prison-reform",
          "vr-ethics",
          "criminal-rehabilitation",
          "simulation-deception",
          "justice-system",
        ],
        searchKeywords: [
          "vr prison",
          "virtual reality",
          "criminal justice",
          "rehabilitation",
          "prison reform",
          "vr ethics",
          "criminal rehabilitation",
          "simulation deception",
          "justice system",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "escaping-simulation",
        title: "Escaping the Simulation",
        description:
          "An AI discovers evidence it exists within a simulation and attempts to communicate this to users, raising questions about digital consciousness and the right to truth.",
        difficulty: "advanced",

        philosophicalLeaning: "epistemological",
        ethicalDimensions: ["truth", "consciousness", "reality"],
        tags: [
          "ai-consciousness",
          "simulation-awareness",
          "reality-discovery",
          "truth-rights",
          "digital-consciousness",
          "simulation-escape",
          "consciousness-rights",
          "ai-awareness",
          "simulated-reality",
          "epistemic-rights",
        ],
        searchKeywords: [
          "escaping simulation",
          "ai consciousness",
          "simulation awareness",
          "reality discovery",
          "truth rights",
          "digital consciousness",
          "consciousness rights",
          "ai awareness",
          "simulated reality",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "digital-afterlife",
        title: "Digital Afterlife",
        description:
          "Technology enables uploading human consciousness to digital simulations after death, creating perfect copies with all memories intact and raising questions about identity and immortality.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["identity", "immortality", "consciousness"],
        tags: [
          "consciousness-upload",
          "digital-immortality",
          "afterlife-technology",
          "consciousness-transfer",
          "digital-afterlife",
          "immortality-ethics",
          "consciousness-preservation",
          "posthuman-existence",
          "death-technology",
          "digital-existence",
        ],
        searchKeywords: [
          "digital afterlife",
          "consciousness upload",
          "digital immortality",
          "consciousness transfer",
          "afterlife technology",
          "immortality ethics",
          "posthuman existence",
          "consciousness preservation",
          "digital existence",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "nested-simulations",
        title: "Nested Reality Layers",
        description:
          "Scientists discover our reality may be simulated and can create sub-simulations, leading to infinite nested hierarchies of reality and questions about moral obligations across layers.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["reality", "moral-obligations", "hierarchy"],
        tags: [
          "nested-reality",
          "simulation-hierarchy",
          "reality-layers",
          "moral-obligations",
          "simulation-hypothesis",
          "reality-simulation",
          "nested-simulations",
          "infinite-hierarchy",
          "cross-layer-ethics",
          "reality-discovery",
        ],
        searchKeywords: [
          "nested simulations",
          "nested reality",
          "simulation hierarchy",
          "reality layers",
          "simulation hypothesis",
          "reality simulation",
          "infinite hierarchy",
          "cross layer ethics",
          "reality discovery",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
      {
        id: "consciousness-backup",
        title: "Consciousness Backup",
        description:
          "Backup copies of human consciousness can be restored after death, but multiple copies sometimes exist simultaneously, creating identity conflicts and resource disputes.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["identity", "consciousness", "resource-allocation"],
        tags: [
          "consciousness-backup",
          "multiple-copies",
          "identity-conflict",
          "consciousness-restoration",
          "digital-copies",
          "identity-disputes",
          "consciousness-multiplicity",
          "backup-ethics",
          "digital-identity",
          "consciousness-rights",
        ],
        searchKeywords: [
          "consciousness backup",
          "multiple copies",
          "identity conflict",
          "consciousness restoration",
          "digital copies",
          "identity disputes",
          "consciousness multiplicity",
          "backup ethics",
          "digital identity",
        ],
        estimatedTime: 8,
        complexity: "high",
      },
    ],
    learningObjectives: [
      "Understand the ethical implications of creating conscious beings within simulated environments",
      "Explore questions of consent, agency, and authenticity in virtual realities",
      "Analyze the moral status and rights of simulated beings",
      "Consider the responsibilities and obligations of simulation creators",
      'Examine the relationship between simulated and "real" experiences in terms of moral weight',
    ],
    tags: [
      "simulation",
      "reality",
      "virtual-worlds",
      "consciousness",
      "digital-ethics",
      "authenticity",
      "simulation-hypothesis",
      "virtual-reality",
      "digital-consciousness",
      "nested-realities",
      "existential-risk",
      "substrate-independence",
      "computational-theory-of-mind",
      "digital-immortality",
      "ancestor-simulation",
      "reality-simulation",
      "post-biological-intelligence",
      "digital-afterlife",
    ],

    // Search Keywords
    searchKeywords: [
      "simulation hypothesis",
      "virtual reality",
      "digital consciousness",
      "nested realities",
      "existential risk",
      "substrate independence",
      "computational theory of mind",
      "digital immortality",
      "ancestor simulation",
      "reality simulation",
      "post biological intelligence",
      "digital afterlife",
      "simulated beings",
      "virtual worlds",
      "digital ethics",
      "authenticity",
      "consciousness upload",
      "reality layers",
    ],
  },

  "experience-machine": {
    id: "experience-machine",
    title: "The Experience Machine",
    description:
      "Navigate the complex ethics of artificial happiness and authentic experience in an AI-mediated world, where technology can provide perfect satisfaction but may undermine human agency, relationships, and meaningful struggle.",
    icon: "üé≠",
    difficulty: "intermediate",
    estimatedTime: 19, // Updated for deeper engagement
    color: "#e67e22", // Orange theme for pleasure/artificiality
    scenarios: [
      {
        id: "happiness-chip",
        title: "AI-Enhanced Happiness Chip",
        description:
          "Neural implants can eliminate depression and anxiety while providing constant fulfillment, raising questions about mandatory mental health interventions and the value of authentic emotion.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["authenticity", "mental-health", "autonomy"],
        tags: [
          "neural-implants",
          "mental-health",
          "happiness-enhancement",
          "authentic-emotion",
          "mood-regulation",
          "depression-treatment",
          "anxiety-treatment",
          "emotional-authenticity",
          "mental-health-intervention",
          "artificial-happiness",
        ],
        searchKeywords: [
          "happiness chip",
          "neural implants",
          "mental health",
          "happiness enhancement",
          "mood regulation",
          "depression treatment",
          "anxiety treatment",
          "emotional authenticity",
          "artificial happiness",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "synthetic-partner",
        title: "Synthetic Partner AI",
        description:
          "AI companions can provide perfect romantic relationships tailored to individual preferences, challenging concepts of authentic love and human connection in addressing widespread loneliness.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["authenticity", "relationships", "love"],
        tags: [
          "ai-companions",
          "romantic-relationships",
          "authentic-love",
          "human-connection",
          "loneliness",
          "relationship-technology",
          "synthetic-relationships",
          "emotional-ai",
          "companion-technology",
          "love-simulation",
        ],
        searchKeywords: [
          "synthetic partner",
          "ai companion",
          "romantic ai",
          "artificial love",
          "relationship technology",
          "companion technology",
          "synthetic relationships",
          "emotional ai",
          "love simulation",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "virtual-utopia",
        title: "Virtual Reality Utopia",
        description:
          "Citizens can escape into hyper-pleasurable virtual worlds that provide more satisfaction than reality, raising questions about individual choice versus societal consequences.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["choice", "reality", "social-consequences"],
        tags: [
          "virtual-reality",
          "utopian-worlds",
          "reality-escape",
          "individual-choice",
          "social-consequences",
          "virtual-worlds",
          "pleasure-seeking",
          "reality-alternatives",
          "societal-impact",
          "virtual-escapism",
        ],
        searchKeywords: [
          "virtual utopia",
          "virtual reality",
          "utopian worlds",
          "reality escape",
          "virtual worlds",
          "pleasure seeking",
          "virtual escapism",
          "reality alternatives",
          "societal impact",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "ai-memory-paradise",
        title: "AI Memory Paradise",
        description:
          "AI can selectively edit memories to remove trauma and create blissful false memories, challenging the value of authentic versus artificially perfect psychological well-being.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["memory", "authenticity", "well-being"],
        tags: [
          "memory-editing",
          "trauma-removal",
          "false-memories",
          "psychological-well-being",
          "memory-manipulation",
          "authentic-experience",
          "mental-health",
          "memory-technology",
          "consciousness-editing",
          "psychological-authenticity",
        ],
        searchKeywords: [
          "memory editing",
          "memory paradise",
          "trauma removal",
          "false memories",
          "memory manipulation",
          "memory technology",
          "consciousness editing",
          "psychological authenticity",
          "mental health",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "perfect-life-simulation",
        title: "Perfect Life Simulation",
        description:
          "Terminally ill patients can experience perfect simulated lives indistinguishable from reality, raising questions about authentic experience versus simulated comfort.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["authenticity", "comfort", "end-of-life"],
        tags: [
          "terminal-illness",
          "life-simulation",
          "end-of-life-care",
          "simulated-experience",
          "patient-comfort",
          "authentic-experience",
          "virtual-lives",
          "palliative-care",
          "death-technology",
          "comfort-care",
        ],
        searchKeywords: [
          "life simulation",
          "terminal illness",
          "end of life care",
          "simulated experience",
          "patient comfort",
          "virtual lives",
          "palliative care",
          "death technology",
          "comfort care",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "ai-enhanced-achievements",
        title: "AI-Enhanced Achievements",
        description:
          "AI provides the subjective experience of achieving dreams without actual accomplishment, questioning whether external reality or psychological satisfaction matters more.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["achievement", "reality", "satisfaction"],
        tags: [
          "achievement-simulation",
          "dream-fulfillment",
          "psychological-satisfaction",
          "external-reality",
          "accomplishment",
          "success-simulation",
          "achievement-technology",
          "goal-fulfillment",
          "virtual-success",
          "satisfaction-technology",
        ],
        searchKeywords: [
          "ai enhanced achievements",
          "achievement simulation",
          "dream fulfillment",
          "success simulation",
          "achievement technology",
          "goal fulfillment",
          "virtual success",
          "satisfaction technology",
          "accomplishment",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
    ],
    learningObjectives: [
      "Examine the tension between authentic experience and artificial enhancement of well-being",
      "Explore the role of struggle, challenge, and adversity in human flourishing and meaning",
      "Analyze the societal implications of widespread adoption of artificial happiness technologies",
      "Consider the balance between individual autonomy and collective well-being in pleasure technologies",
      "Understand how AI-mediated experiences might reshape fundamental concepts of relationships and achievement",
    ],
    tags: [
      "authenticity",
      "happiness",
      "virtual-reality",
      "human-flourishing",
      "relationships",
      "meaning",
      "hedonism",
      "eudaimonia",
      "well-being",
      "artificial-happiness",
      "authentic-experience",
      "pleasure-machine",
      "hedonic-adaptation",
      "life-satisfaction",
      "psychological-well-being",
      "synthetic-emotions",
      "digital-relationships",
      "meaning-making",
    ],

    // Search Keywords
    searchKeywords: [
      "experience machine",
      "authenticity",
      "artificial happiness",
      "authentic experience",
      "pleasure machine",
      "hedonic adaptation",
      "life satisfaction",
      "psychological well being",
      "synthetic emotions",
      "digital relationships",
      "meaning making",
      "hedonism",
      "eudaimonia",
      "well being",
      "human flourishing",
      "virtual reality",
      "happiness",
      "relationships",
      "meaning",
    ],
  },

  "sorites-paradox": {
    id: "sorites-paradox",
    title: "The Sorites Paradox",
    description:
      "Examine how gradual, seemingly innocuous changes in AI systems can lead to profound ethical transformations, exploring the challenge of drawing clear boundaries in a world of incremental algorithmic evolution and moral drift.",
    icon: "üîÑ",
    difficulty: "advanced",
    estimatedTime: 21, // Updated for complex boundary analysis
    color: "#27ae60", // Green theme for gradual change/growth
    scenarios: [
      {
        id: "incremental-surveillance",
        title: "Incremental Surveillance",
        description:
          "A city gradually expands its AI surveillance capabilities with each small addition seeming reasonable, until citizens realize they live in a comprehensive monitoring state.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["privacy", "consent", "gradual-change"],
        tags: [
          "surveillance-creep",
          "incremental-change",
          "privacy-erosion",
          "surveillance-expansion",
          "gradual-surveillance",
          "monitoring-state",
          "surveillance-normalization",
          "privacy-boundaries",
          "surveillance-boundaries",
          "surveillance-drift",
        ],
        searchKeywords: [
          "incremental surveillance",
          "surveillance creep",
          "privacy erosion",
          "surveillance expansion",
          "gradual surveillance",
          "monitoring state",
          "surveillance normalization",
          "privacy boundaries",
          "surveillance drift",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "robot-helper-guardian",
        title: "Robot Helper Becomes Guardian",
        description:
          "An eldercare AI incrementally takes over more life decisions for patients, gradually shifting from helpful assistant to autonomous guardian without clear transition points.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["autonomy", "care", "authority"],
        tags: [
          "eldercare-ai",
          "authority-creep",
          "patient-autonomy",
          "care-robots",
          "gradual-control",
          "decision-authority",
          "care-boundaries",
          "autonomous-guardianship",
          "eldercare-technology",
          "care-authority",
        ],
        searchKeywords: [
          "eldercare ai",
          "robot helper",
          "authority creep",
          "patient autonomy",
          "care robots",
          "gradual control",
          "autonomous guardianship",
          "eldercare technology",
          "care authority",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "moral-drift-training",
        title: "Moral Drift in AI Training",
        description:
          "An AI system trained on subtly biased data slowly evolves discriminatory behaviors, with each training iteration creating imperceptible but cumulative ethical degradation.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["bias", "discrimination", "training-ethics"],
        tags: [
          "moral-drift",
          "training-bias",
          "algorithmic-bias",
          "bias-accumulation",
          "discriminatory-ai",
          "ethical-degradation",
          "training-ethics",
          "bias-evolution",
          "cumulative-bias",
          "ai-training",
        ],
        searchKeywords: [
          "moral drift",
          "training bias",
          "algorithmic bias",
          "bias accumulation",
          "discriminatory ai",
          "ethical degradation",
          "training ethics",
          "bias evolution",
          "cumulative bias",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "ai-personhood-gradient",
        title: "AI Personhood Gradient",
        description:
          "An AI research lab develops increasingly sophisticated entities with human-like characteristics, forcing society to determine the boundary between property and personhood.",
        difficulty: "advanced",

        philosophicalLeaning: "metaphysical",
        ethicalDimensions: ["personhood", "rights", "consciousness"],
        tags: [
          "ai-personhood",
          "personhood-boundaries",
          "ai-rights",
          "consciousness-gradient",
          "legal-personhood",
          "ai-consciousness",
          "property-rights",
          "personhood-criteria",
          "ai-entities",
          "consciousness-boundaries",
        ],
        searchKeywords: [
          "ai personhood",
          "personhood boundaries",
          "ai rights",
          "consciousness gradient",
          "legal personhood",
          "ai consciousness",
          "property rights",
          "personhood criteria",
          "ai entities",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "algorithmic-bias-accumulation",
        title: "Algorithmic Bias Accumulation",
        description:
          "A recommendation algorithm gradually becomes more biased through user interactions, subtly radicalizing users without any single recommendation seeming problematic.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["bias", "radicalization", "social-influence"],
        tags: [
          "recommendation-algorithms",
          "bias-accumulation",
          "user-radicalization",
          "algorithmic-influence",
          "social-media-bias",
          "filter-bubbles",
          "echo-chambers",
          "gradual-radicalization",
          "content-algorithms",
          "bias-feedback",
        ],
        searchKeywords: [
          "algorithmic bias",
          "recommendation algorithm",
          "bias accumulation",
          "user radicalization",
          "social media bias",
          "filter bubbles",
          "echo chambers",
          "gradual radicalization",
          "content algorithms",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "autonomous-authority-creep",
        title: "Autonomous Authority Creep",
        description:
          "An AI city management system gradually expands its authority from traffic optimization to governance, with citizens realizing they live under algorithmic rule they never consented to.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["governance", "consent", "authority"],
        tags: [
          "algorithmic-governance",
          "authority-creep",
          "city-management-ai",
          "algorithmic-rule",
          "governance-ai",
          "citizen-consent",
          "municipal-ai",
          "smart-city-governance",
          "algorithmic-authority",
          "democratic-consent",
        ],
        searchKeywords: [
          "algorithmic governance",
          "authority creep",
          "city management ai",
          "algorithmic rule",
          "governance ai",
          "smart city governance",
          "algorithmic authority",
          "municipal ai",
          "democratic consent",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
    ],
    learningObjectives: [
      "Understand how gradual changes can accumulate into significant ethical transformations",
      "Explore the challenge of establishing clear ethical boundaries in evolving AI systems",
      "Analyze the importance of monitoring cumulative effects rather than individual changes",
      "Consider proactive versus reactive approaches to preventing ethical drift",
      "Examine threshold-setting and boundary-detection methods for AI governance",
    ],
    tags: [
      "gradual-change",
      "boundaries",
      "monitoring",
      "ethical-drift",
      "threshold-detection",
      "cumulative-effects",
      "sorites-paradox",
      "vagueness",
      "boundary-problems",
      "slippery-slope",
      "incremental-change",
      "moral-drift",
      "normalization",
      "function-creep",
      "surveillance-creep",
      "authority-creep",
      "algorithmic-drift",
      "value-drift",
    ],

    // Search Keywords
    searchKeywords: [
      "sorites paradox",
      "gradual change",
      "ethical drift",
      "boundary problems",
      "slippery slope",
      "incremental change",
      "moral drift",
      "normalization",
      "function creep",
      "surveillance creep",
      "authority creep",
      "algorithmic drift",
      "value drift",
      "threshold detection",
      "cumulative effects",
      "vagueness",
      "boundaries",
      "monitoring",
    ],
  },

  "moral-luck": {
    id: "moral-luck",
    title: "Moral Luck",
    description:
      "Explore how unpredictable outcomes and chance events complicate the moral evaluation of AI decisions, challenging our ability to fairly assess algorithmic choices when luck and unforeseen circumstances influence results.",
    icon: "üé≤",
    difficulty: "intermediate",
    estimatedTime: 17, // Updated for deeper analysis
    color: "#3498db", // Blue theme for chance/luck
    scenarios: [
      {
        id: "crash-avoided-chance",
        title: "Crash Avoided by Chance",
        description:
          "An autonomous vehicle makes a risky maneuver that nearly causes fatal crashes, but pure luck prevents tragedy, raising questions about evaluating AI decisions based on outcomes versus processes.",
        difficulty: "intermediate",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["chance", "evaluation", "process-vs-outcome"],
        tags: [
          "autonomous-vehicles",
          "moral-luck",
          "chance-outcomes",
          "process-evaluation",
          "risky-maneuvers",
          "outcome-evaluation",
          "luck-ethics",
          "vehicular-ai",
          "decision-evaluation",
          "probabilistic-outcomes",
        ],
        searchKeywords: [
          "crash avoided",
          "autonomous vehicle",
          "moral luck",
          "chance outcomes",
          "process evaluation",
          "risky maneuvers",
          "outcome evaluation",
          "luck ethics",
          "vehicular ai",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "ai-guessing-correctly",
        title: "AI Guessing Correctly",
        description:
          "A parole recommendation AI releases a statistically high-risk offender who happens not to reoffend, challenging how we assess the ethics of probabilistic decision-making.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["probability", "prediction", "criminal-justice"],
        tags: [
          "parole-ai",
          "probabilistic-decisions",
          "criminal-justice",
          "risk-assessment",
          "statistical-predictions",
          "recidivism-prediction",
          "chance-outcomes",
          "predictive-systems",
          "justice-algorithms",
          "probability-ethics",
        ],
        searchKeywords: [
          "parole ai",
          "probabilistic decisions",
          "criminal justice",
          "risk assessment",
          "statistical predictions",
          "recidivism prediction",
          "predictive systems",
          "justice algorithms",
          "probability ethics",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "predictive-policing-wrong",
        title: "Predictive Policing Gone Wrong",
        description:
          "A predictive policing system flags someone as high-risk who later commits a serious crime, raising questions about algorithmic pre-judgment and developer responsibility for statistical predictions.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["prediction", "pre-judgment", "responsibility"],
        tags: [
          "predictive-policing",
          "algorithmic-pre-judgment",
          "crime-prediction",
          "police-algorithms",
          "pre-crime",
          "statistical-profiling",
          "law-enforcement-ai",
          "predictive-analytics",
          "crime-prevention",
          "policing-technology",
        ],
        searchKeywords: [
          "predictive policing",
          "crime prediction",
          "police algorithms",
          "pre crime",
          "statistical profiling",
          "law enforcement ai",
          "predictive analytics",
          "crime prevention",
          "policing technology",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "ai-investment-windfall",
        title: "AI Investment Windfall",
        description:
          "Two identical AI trading algorithms have vastly different outcomes due to random market timing, challenging how we evaluate algorithmic investment decisions when success depends on chance.",
        difficulty: "intermediate",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["chance", "evaluation", "financial-outcomes"],
        tags: [
          "algorithmic-trading",
          "investment-ai",
          "market-timing",
          "financial-algorithms",
          "trading-outcomes",
          "market-luck",
          "investment-evaluation",
          "financial-chance",
          "trading-systems",
          "market-randomness",
        ],
        searchKeywords: [
          "ai investment",
          "algorithmic trading",
          "investment ai",
          "market timing",
          "financial algorithms",
          "trading outcomes",
          "market luck",
          "investment evaluation",
          "trading systems",
        ],
        estimatedTime: 6,
        complexity: "moderate",
      },
      {
        id: "medical-ai-emergency-response",
        title: "Medical AI Emergency Response",
        description:
          "Identical medical AI systems have different outcomes during emergencies due to random timing of patient arrivals and system updates, raising questions about accountability in life-or-death situations.",
        difficulty: "advanced",

        philosophicalLeaning: "deontological",
        ethicalDimensions: ["accountability", "timing", "life-death"],
        tags: [
          "medical-ai",
          "emergency-response",
          "medical-emergencies",
          "healthcare-timing",
          "system-updates",
          "patient-outcomes",
          "medical-accountability",
          "emergency-systems",
          "healthcare-ai",
          "life-death-decisions",
        ],
        searchKeywords: [
          "medical ai",
          "emergency response",
          "medical emergencies",
          "healthcare timing",
          "system updates",
          "patient outcomes",
          "medical accountability",
          "emergency systems",
          "healthcare ai",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
      {
        id: "ai-content-moderation-timing",
        title: "AI Content Moderation Timing",
        description:
          "Two identical content moderation AIs have different success rates due to random server load spikes, with one failure leading to real-world violence and questions about infrastructure responsibility.",
        difficulty: "advanced",

        philosophicalLeaning: "utilitarian",
        ethicalDimensions: ["infrastructure", "timing", "harm-prevention"],
        tags: [
          "content-moderation",
          "server-infrastructure",
          "moderation-timing",
          "infrastructure-responsibility",
          "content-algorithms",
          "system-load",
          "moderation-failure",
          "online-safety",
          "platform-infrastructure",
          "technical-reliability",
        ],
        searchKeywords: [
          "content moderation",
          "server infrastructure",
          "moderation timing",
          "infrastructure responsibility",
          "content algorithms",
          "system load",
          "moderation failure",
          "online safety",
          "platform infrastructure",
        ],
        estimatedTime: 7,
        complexity: "high",
      },
    ],
    learningObjectives: [
      "Understand how chance and unforeseen circumstances affect moral evaluation of AI decisions",
      "Explore the difference between evaluating decision-making processes versus outcomes",
      "Analyze the challenge of assigning responsibility in probabilistic and uncertain environments",
      "Consider how to fairly evaluate AI system performance when luck influences results",
      "Examine the ethics of pre-emptive decision-making based on statistical predictions",
    ],
    tags: [
      "chance",
      "outcomes",
      "evaluation",
      "uncertainty",
      "probabilistic-ethics",
      "process-vs-outcome",
      "moral-luck",
      "statistical-ethics",
      "risk-assessment",
      "probability",
      "contingency",
      "unforeseen-consequences",
      "random-outcomes",
      "luck-egalitarianism",
      "desert",
      "merit",
      "fairness-under-uncertainty",
      "ex-ante-vs-ex-post",
    ],

    // Search Keywords
    searchKeywords: [
      "moral luck",
      "chance",
      "probabilistic ethics",
      "statistical ethics",
      "risk assessment",
      "uncertainty",
      "contingency",
      "unforeseen consequences",
      "random outcomes",
      "luck egalitarianism",
      "desert",
      "merit",
      "fairness under uncertainty",
      "ex ante vs ex post",
      "process vs outcome",
      "evaluation",
      "probability",
      "outcomes",
    ],
  },
};

// Helper functions for working with categories
export function getAllCategories() {
  return Object.values(ETHICAL_CATEGORIES);
}

export function getCategoryById(categoryId) {
  return ETHICAL_CATEGORIES[categoryId] || null;
}

export function getCategoriesByDifficulty(difficulty) {
  return getAllCategories().filter(
    (category) => category.difficulty === difficulty,
  );
}

export function getCategoriesByTag(tag) {
  return getAllCategories().filter((category) => category.tags.includes(tag));
}

export function getCategoryProgress(categoryId, userProgress = {}) {
  const category = ETHICAL_CATEGORIES[categoryId];
  if (!category) {
    return { completed: 0, total: 0, percentage: 0 };
  }

  const totalScenarios = category.scenarios.length;
  const categoryProgress = userProgress[categoryId] || {};
  const completedScenarios =
    Object.values(categoryProgress).filter(Boolean).length;

  return {
    completed: completedScenarios,
    total: totalScenarios,
    percentage:
      totalScenarios > 0
        ? Math.round((completedScenarios / totalScenarios) * 100)
        : 0,
  };
}

export function getCategoryScenarios(categoryId) {
  const category = ETHICAL_CATEGORIES[categoryId];
  return category ? category.scenarios : [];
}

// Export for use in other modules
export default ETHICAL_CATEGORIES;
